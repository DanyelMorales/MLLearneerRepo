{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbtfdWCHQHEK8v8qrS1GjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanyelMorales/MLLearneerRepo/blob/main/02_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgPBM3Z8-WNS",
        "outputId": "a9b7c528-73fc-4c83-d1a3-045c440c5330"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9680k  100 9680k    0     0  8484k      0  0:00:01  0:00:01 --:--:-- 8491k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6qyHHgk-cxD",
        "outputId": "0f6651fc-f16e-46be-e7b9-aa7b7de9fde0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1610k  100 1610k    0     0  2609k      0 --:--:-- --:--:-- --:--:-- 2609k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW5YK1bLiKTr",
        "outputId": "882a2668-3c2a-4e9f-f72a-b647f2014e29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 28881  100 28881    0     0  66038      0 --:--:-- --:--:-- --:--:-- 66089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyqqE8MQizyb",
        "outputId": "f23bb39b-f742-459e-e1d9-04e1ffd025a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4542  100  4542    0     0   9036      0 --:--:-- --:--:-- --:--:--  9047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"mnist.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/mnist.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNFxE90po5WY",
        "outputId": "5dba924a-ce3d-41c5-ec79-0c460e8f00dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1205  100  1205    0     0   2974      0 --:--:-- --:--:-- --:--:--  2975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"digit_classifier.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/digit_classifier.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-pPzdsqj59",
        "outputId": "272c373a-a1d7-4d7c-9b72-679838ce6cc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1481  100  1481    0     0   3181      0 --:--:-- --:--:-- --:--:--  3184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gk-M90M6gpD"
      },
      "outputs": [],
      "source": [
        "from mnist import prepend_bias, load_images, load_labels,one_hot_encode\n",
        "import digit_classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = prepend_bias(load_images(\"train-images-idx3-ubyte.gz\"))\n",
        "X_test = prepend_bias(load_images(\"t10k-images-idx3-ubyte.gz\"))\n",
        "Y_train = one_hot_encode(load_labels(\"train-labels-idx1-ubyte.gz\"))\n",
        "Y_test = (load_labels(\"t10k-labels-idx1-ubyte.gz\"))"
      ],
      "metadata": {
        "id": "Lg1p-3hlkUVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = digit_classifier.train(X_train,Y_train,X_test,Y_test, iterations=200, lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-7u3wmhlYcW",
        "outputId": "66103d99-1ade-4fed-8ec8-98279714cda1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - Loss: 0.6931471805599453, \n",
            " 88.65%\n",
            "1 - Loss: 0.6329712674925422, \n",
            " 88.65%\n",
            "2 - Loss: 0.4041504120613409, \n",
            " 88.65%\n",
            "3 - Loss: 0.20740137552095117, \n",
            " 88.65%\n",
            "4 - Loss: 0.10475739758236242, \n",
            " 88.65%\n",
            "5 - Loss: 0.084065844259969, \n",
            " 88.65%\n",
            "6 - Loss: 0.08017763379914089, \n",
            " 88.65%\n",
            "7 - Loss: 0.07779278786107958, \n",
            " 88.65%\n",
            "8 - Loss: 0.0757192265712811, \n",
            " 88.65%\n",
            "9 - Loss: 0.07385842309425815, \n",
            " 88.65%\n",
            "10 - Loss: 0.07217526698365141, \n",
            " 88.65%\n",
            "11 - Loss: 0.0706439388687286, \n",
            " 88.65%\n",
            "12 - Loss: 0.06924364639852244, \n",
            " 88.65%\n",
            "13 - Loss: 0.06795734081897782, \n",
            " 88.65%\n",
            "14 - Loss: 0.06677088993872657, \n",
            " 88.65%\n",
            "15 - Loss: 0.06567246994486708, \n",
            " 88.65%\n",
            "16 - Loss: 0.06465210531601653, \n",
            " 88.65%\n",
            "17 - Loss: 0.06370131554251553, \n",
            " 88.65%\n",
            "18 - Loss: 0.06281284058480352, \n",
            " 88.65%\n",
            "19 - Loss: 0.061980425227391056, \n",
            " 88.65%\n",
            "20 - Loss: 0.06119864802861201, \n",
            " 88.65%\n",
            "21 - Loss: 0.0604627844122555, \n",
            " 88.65%\n",
            "22 - Loss: 0.059768696163828086, \n",
            " 88.65%\n",
            "23 - Loss: 0.0591127415404373, \n",
            " 88.65%\n",
            "24 - Loss: 0.05849170161493934, \n",
            " 88.65%\n",
            "25 - Loss: 0.0579027195104973, \n",
            " 88.65%\n",
            "26 - Loss: 0.057343249949256575, \n",
            " 88.65%\n",
            "27 - Loss: 0.05681101711337543, \n",
            " 88.65%\n",
            "28 - Loss: 0.05630397925065071, \n",
            " 88.65%\n",
            "29 - Loss: 0.05582029878766446, \n",
            " 88.65%\n",
            "30 - Loss: 0.05535831696739804, \n",
            " 88.65%\n",
            "31 - Loss: 0.05491653222489375, \n",
            " 88.65%\n",
            "32 - Loss: 0.05449358166786551, \n",
            " 88.65%\n",
            "33 - Loss: 0.05408822514953442, \n",
            " 88.65%\n",
            "34 - Loss: 0.05369933151609302, \n",
            " 88.65%\n",
            "35 - Loss: 0.053325866686843526, \n",
            " 88.65%\n",
            "36 - Loss: 0.05296688328556089, \n",
            " 88.65%\n",
            "37 - Loss: 0.05262151159029913, \n",
            " 88.65%\n",
            "38 - Loss: 0.052288951608217886, \n",
            " 88.65%\n",
            "39 - Loss: 0.05196846611399564, \n",
            " 88.65%\n",
            "40 - Loss: 0.05165937451652725, \n",
            " 88.65%\n",
            "41 - Loss: 0.0513610474400442, \n",
            " 88.65%\n",
            "42 - Loss: 0.05107290192347033, \n",
            " 88.65%\n",
            "43 - Loss: 0.05079439715645546, \n",
            " 88.65%\n",
            "44 - Loss: 0.05052503068268931, \n",
            " 88.65%\n",
            "45 - Loss: 0.050264335011244006, \n",
            " 88.65%\n",
            "46 - Loss: 0.05001187458519185, \n",
            " 88.65%\n",
            "47 - Loss: 0.04976724306388816, \n",
            " 88.65%\n",
            "48 - Loss: 0.04953006088133449, \n",
            " 88.65%\n",
            "49 - Loss: 0.04929997304813659, \n",
            " 88.65%\n",
            "50 - Loss: 0.049076647168900686, \n",
            " 88.65%\n",
            "51 - Loss: 0.04885977165059958, \n",
            " 88.65%\n",
            "52 - Loss: 0.04864905408058832, \n",
            " 88.65%\n",
            "53 - Loss: 0.04844421975564811, \n",
            " 88.65%\n",
            "54 - Loss: 0.04824501034575417, \n",
            " 88.65%\n",
            "55 - Loss: 0.04805118267825937, \n",
            " 88.65%\n",
            "56 - Loss: 0.04786250762990911, \n",
            " 88.65%\n",
            "57 - Loss: 0.04767876911559534, \n",
            " 88.65%\n",
            "58 - Loss: 0.047499763164051655, \n",
            " 88.65%\n",
            "59 - Loss: 0.04732529707181842, \n",
            " 88.65%\n",
            "60 - Loss: 0.047155188627788176, \n",
            " 88.65%\n",
            "61 - Loss: 0.046989265401499045, \n",
            " 88.65%\n",
            "62 - Loss: 0.04682736408909542, \n",
            " 88.65%\n",
            "63 - Loss: 0.04666932991153327, \n",
            " 88.65%\n",
            "64 - Loss: 0.046515016060186924, \n",
            " 88.65%\n",
            "65 - Loss: 0.04636428318552405, \n",
            " 88.65%\n",
            "66 - Loss: 0.046216998924965384, \n",
            " 88.65%\n",
            "67 - Loss: 0.046073037466444026, \n",
            " 88.65%\n",
            "68 - Loss: 0.045932279144530644, \n",
            " 88.65%\n",
            "69 - Loss: 0.04579461006630435, \n",
            " 88.65%\n",
            "70 - Loss: 0.04565992176442579, \n",
            " 88.65%\n",
            "71 - Loss: 0.04552811087511654, \n",
            " 88.65%\n",
            "72 - Loss: 0.04539907883896919, \n",
            " 88.65%\n",
            "73 - Loss: 0.04527273162270885, \n",
            " 88.65%\n",
            "74 - Loss: 0.045148979460203006, \n",
            " 88.65%\n",
            "75 - Loss: 0.045027736611173486, \n",
            " 88.65%\n",
            "76 - Loss: 0.04490892113620629, \n",
            " 88.65%\n",
            "77 - Loss: 0.044792454686780725, \n",
            " 88.65%\n",
            "78 - Loss: 0.04467826230915438, \n",
            " 88.65%\n",
            "79 - Loss: 0.04456627226104182, \n",
            " 88.65%\n",
            "80 - Loss: 0.04445641584011847, \n",
            " 88.65%\n",
            "81 - Loss: 0.04434862722346394, \n",
            " 88.65%\n",
            "82 - Loss: 0.04424284331713452, \n",
            " 88.65%\n",
            "83 - Loss: 0.044139003615123115, \n",
            " 88.65%\n",
            "84 - Loss: 0.04403705006702636, \n",
            " 88.65%\n",
            "85 - Loss: 0.04393692695379479, \n",
            " 88.65%\n",
            "86 - Loss: 0.043838580770993056, \n",
            " 88.65%\n",
            "87 - Loss: 0.04374196011904281, \n",
            " 88.65%\n",
            "88 - Loss: 0.04364701559996371, \n",
            " 88.65%\n",
            "89 - Loss: 0.043553699720165574, \n",
            " 88.65%\n",
            "90 - Loss: 0.04346196679888035, \n",
            " 88.65%\n",
            "91 - Loss: 0.04337177288185343, \n",
            " 88.65%\n",
            "92 - Loss: 0.0432830756599443, \n",
            " 88.65%\n",
            "93 - Loss: 0.043195834392311644, \n",
            " 88.65%\n",
            "94 - Loss: 0.043110009833883606, \n",
            " 88.65%\n",
            "95 - Loss: 0.04302556416683543, \n",
            " 88.65%\n",
            "96 - Loss: 0.04294246093581737, \n",
            " 88.65%\n",
            "97 - Loss: 0.042860664986694844, \n",
            " 88.65%\n",
            "98 - Loss: 0.042780142408579344, \n",
            " 88.65%\n",
            "99 - Loss: 0.042700860478945134, \n",
            " 88.65%\n",
            "100 - Loss: 0.04262278761164085, \n",
            " 88.65%\n",
            "101 - Loss: 0.0425458933076189, \n",
            " 88.65%\n",
            "102 - Loss: 0.04247014810821736, \n",
            " 88.65%\n",
            "103 - Loss: 0.04239552355084136, \n",
            " 88.65%\n",
            "104 - Loss: 0.04232199212690031, \n",
            " 88.65%\n",
            "105 - Loss: 0.04224952724186793, \n",
            " 88.65%\n",
            "106 - Loss: 0.042178103177340824, \n",
            " 88.65%\n",
            "107 - Loss: 0.04210769505497905, \n",
            " 88.65%\n",
            "108 - Loss: 0.042038278802220795, \n",
            " 88.65%\n",
            "109 - Loss: 0.04196983111966939, \n",
            " 88.65%\n",
            "110 - Loss: 0.041902329450058194, \n",
            " 88.65%\n",
            "111 - Loss: 0.041835751948704536, \n",
            " 88.65%\n",
            "112 - Loss: 0.04177007745537001, \n",
            " 88.65%\n",
            "113 - Loss: 0.041705285467448984, \n",
            " 88.65%\n",
            "114 - Loss: 0.04164135611441294, \n",
            " 88.65%\n",
            "115 - Loss: 0.041578270133442057, \n",
            " 88.65%\n",
            "116 - Loss: 0.041516008846180084, \n",
            " 88.65%\n",
            "117 - Loss: 0.04145455413655241, \n",
            " 88.65%\n",
            "118 - Loss: 0.04139388842959075, \n",
            " 88.65%\n",
            "119 - Loss: 0.0413339946712115, \n",
            " 88.65%\n",
            "120 - Loss: 0.041274856308897774, \n",
            " 88.65%\n",
            "121 - Loss: 0.04121645727323835, \n",
            " 88.65%\n",
            "122 - Loss: 0.04115878196027928, \n",
            " 88.65%\n",
            "123 - Loss: 0.04110181521464658, \n",
            " 88.65%\n",
            "124 - Loss: 0.04104554231340104, \n",
            " 88.65%\n",
            "125 - Loss: 0.04098994895058806, \n",
            " 88.65%\n",
            "126 - Loss: 0.04093502122244787, \n",
            " 88.65%\n",
            "127 - Loss: 0.04088074561325338, \n",
            " 88.65%\n",
            "128 - Loss: 0.04082710898174461, \n",
            " 88.65%\n",
            "129 - Loss: 0.04077409854813054, \n",
            " 88.65%\n",
            "130 - Loss: 0.040721701881630934, \n",
            " 88.65%\n",
            "131 - Loss: 0.04066990688853193, \n",
            " 88.65%\n",
            "132 - Loss: 0.04061870180073069, \n",
            " 88.65%\n",
            "133 - Loss: 0.040568075164746274, \n",
            " 88.65%\n",
            "134 - Loss: 0.04051801583117411, \n",
            " 88.65%\n",
            "135 - Loss: 0.0404685129445637, \n",
            " 88.65%\n",
            "136 - Loss: 0.04041955593369969, \n",
            " 88.65%\n",
            "137 - Loss: 0.040371134502267446, \n",
            " 88.65%\n",
            "138 - Loss: 0.04032323861988583, \n",
            " 88.65%\n",
            "139 - Loss: 0.04027585851349004, \n",
            " 88.65%\n",
            "140 - Loss: 0.04022898465904883, \n",
            " 88.65%\n",
            "141 - Loss: 0.040182607773600956, \n",
            " 88.65%\n",
            "142 - Loss: 0.040136718807596596, \n",
            " 88.65%\n",
            "143 - Loss: 0.040091308937530074, \n",
            " 88.65%\n",
            "144 - Loss: 0.040046369558851214, \n",
            " 88.65%\n",
            "145 - Loss: 0.04000189227914276, \n",
            " 88.65%\n",
            "146 - Loss: 0.03995786891155265, \n",
            " 88.65%\n",
            "147 - Loss: 0.039914291468469656, \n",
            " 88.65%\n",
            "148 - Loss: 0.03987115215543229, \n",
            " 88.65%\n",
            "149 - Loss: 0.039828443365260646, \n",
            " 88.65%\n",
            "150 - Loss: 0.039786157672401984, \n",
            " 88.65%\n",
            "151 - Loss: 0.039744287827480795, \n",
            " 88.65%\n",
            "152 - Loss: 0.03970282675204485, \n",
            " 88.65%\n",
            "153 - Loss: 0.039661767533498954, \n",
            " 88.65%\n",
            "154 - Loss: 0.039621103420218795, \n",
            " 88.65%\n",
            "155 - Loss: 0.039580827816837166, \n",
            " 88.65%\n",
            "156 - Loss: 0.03954093427969579, \n",
            " 88.65%\n",
            "157 - Loss: 0.0395014165124556, \n",
            " 88.65%\n",
            "158 - Loss: 0.03946226836185967, \n",
            " 88.65%\n",
            "159 - Loss: 0.039423483813641795, \n",
            " 88.65%\n",
            "160 - Loss: 0.039385056988575674, \n",
            " 88.65%\n",
            "161 - Loss: 0.03934698213865862, \n",
            " 88.65%\n",
            "162 - Loss: 0.03930925364342459, \n",
            " 88.65%\n",
            "163 - Loss: 0.03927186600638142, \n",
            " 88.65%\n",
            "164 - Loss: 0.03923481385156753, \n",
            " 88.65%\n",
            "165 - Loss: 0.03919809192022326, \n",
            " 88.65%\n",
            "166 - Loss: 0.039161695067572395, \n",
            " 88.65%\n",
            "167 - Loss: 0.03912561825970986, \n",
            " 88.65%\n",
            "168 - Loss: 0.03908985657059125, \n",
            " 88.65%\n",
            "169 - Loss: 0.039054405179120455, \n",
            " 88.65%\n",
            "170 - Loss: 0.03901925936633168, \n",
            " 88.65%\n",
            "171 - Loss: 0.0389844145126622, \n",
            " 88.65%\n",
            "172 - Loss: 0.03894986609531247, \n",
            " 88.65%\n",
            "173 - Loss: 0.03891560968569054, \n",
            " 88.65%\n",
            "174 - Loss: 0.03888164094693725, \n",
            " 88.65%\n",
            "175 - Loss: 0.038847955631529596, \n",
            " 88.65%\n",
            "176 - Loss: 0.03881454957895922, \n",
            " 88.65%\n",
            "177 - Loss: 0.03878141871348337, \n",
            " 88.65%\n",
            "178 - Loss: 0.038748559041945484, \n",
            " 88.65%\n",
            "179 - Loss: 0.03871596665166327, \n",
            " 88.65%\n",
            "180 - Loss: 0.03868363770838141, \n",
            " 88.65%\n",
            "181 - Loss: 0.03865156845428701, \n",
            " 88.65%\n",
            "182 - Loss: 0.03861975520608518, \n",
            " 88.65%\n",
            "183 - Loss: 0.03858819435313293, \n",
            " 88.65%\n",
            "184 - Loss: 0.03855688235562906, \n",
            " 88.65%\n",
            "185 - Loss: 0.03852581574285839, \n",
            " 88.65%\n",
            "186 - Loss: 0.03849499111148803, \n",
            " 88.65%\n",
            "187 - Loss: 0.038464405123914414, \n",
            " 88.65%\n",
            "188 - Loss: 0.038434054506658724, \n",
            " 88.65%\n",
            "189 - Loss: 0.038403936048809664, \n",
            " 88.65%\n",
            "190 - Loss: 0.038374046600511476, \n",
            " 88.65%\n",
            "191 - Loss: 0.03834438307149599, \n",
            " 88.65%\n",
            "192 - Loss: 0.038314942429656995, \n",
            " 88.65%\n",
            "193 - Loss: 0.03828572169966564, \n",
            " 88.65%\n",
            "194 - Loss: 0.038256717961625455, \n",
            " 88.65%\n",
            "195 - Loss: 0.03822792834976569, \n",
            " 88.65%\n",
            "196 - Loss: 0.038199350051171616, \n",
            " 88.65%\n",
            "197 - Loss: 0.0381709803045507, \n",
            " 88.65%\n",
            "198 - Loss: 0.03814281639903334, \n",
            " 88.65%\n",
            "199 - Loss: 0.03811485567300718, \n",
            " 88.65%\n",
            "200 - Loss: 0.03808709551298378, \n",
            " 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit_classifier.test(X_test, Y_test, w)"
      ],
      "metadata": {
        "id": "af_Vtzu6y6wS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3529c8cc-8d7f-4810-8b1c-c255d0633754"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: 8865/10000 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"img_8.png\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/8_handwritten.png\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-tSbFPTcA-P",
        "outputId": "f10ccb3f-7d7e-489b-a02b-7cada5c199ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 12299  100 12299    0     0  56607      0 --:--:-- --:--:-- --:--:-- 56677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load_image(file):\n",
        "  test_image = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
        "  img_resized = cv2.resize(test_image, (28, 28))\n",
        "  img_resized = cv2.bitwise_not(img_resized)\n",
        "  plt.imshow(img_resized, cmap=\"Greys\")\n",
        "  return img_resized"
      ],
      "metadata": {
        "id": "_QYFYlCLb87F"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: cv2 image to np buffer\n",
        "\n",
        "def cv2_to_np_buffer(img):\n",
        "  np_img = np.asarray(img)\n",
        "  np_img = np.expand_dims(np_img, axis=0)\n",
        "  print(np_img.shape)\n",
        "  return np_img\n"
      ],
      "metadata": {
        "id": "eW0duzsLjuxW"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_8 = cv2_to_np_buffer(load_image(\"./img_8.png\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "UKRlxBPecZS-",
        "outputId": "83544be2-33ab-481c-e898-5a605edab980"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZRElEQVR4nO3df0zU9x3H8df566otHEOEg3k6tFa3WlnqlBFbZysRWGL89Yf9sUQbo9FhM2VdG5dW67aEzSauaeP0n03WpGpnVjU1qYliwXQDF6nGmG1MGJsYAVcT7hDr6eSzP4y3nkL18I43dz4fyTfx7r539/a7b++5r/fli8c55wQAwAAbYj0AAODBRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJYdYD3K6np0cXLlxQWlqaPB6P9TgAgBg559TV1aW8vDwNGdL3cc6gC9CFCxcUCASsxwAA3KfW1laNHTu2z8cHXYDS0tIk3Rw8PT3deBoAQKxCoZACgUDk87wvCQvQtm3b9NZbb6m9vV0FBQV69913NXPmzLs+79Y/u6WnpxMgAEhid/saJSEnIXzwwQeqqKjQpk2b9Nlnn6mgoEAlJSW6ePFiIt4OAJCEEhKgrVu3auXKlXrppZf0rW99Szt27NCoUaP0u9/9LhFvBwBIQnEP0LVr19TQ0KDi4uL/v8mQISouLlZdXd0d64fDYYVCoagFAJD64h6gzz//XDdu3FBOTk7U/Tk5OWpvb79j/crKSvl8vsjCGXAA8GAw/0HUDRs2KBgMRpbW1lbrkQAAAyDuZ8FlZWVp6NCh6ujoiLq/o6NDfr//jvW9Xq+8Xm+8xwAADHJxPwIaMWKEpk+frurq6sh9PT09qq6uVlFRUbzfDgCQpBLyc0AVFRVatmyZvvOd72jmzJl6++231d3drZdeeikRbwcASEIJCdDSpUv1n//8Rxs3blR7e7u+/e1v69ChQ3ecmAAAeHB5nHPOeogvC4VC8vl8CgaDXAkBAJLQvX6Om58FBwB4MBEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNxD9Cbb74pj8cTtUyZMiXebwMASHLDEvGijz/+uI4cOfL/NxmWkLcBACSxhJRh2LBh8vv9iXhpAECKSMh3QGfPnlVeXp4mTJigF198UefOnetz3XA4rFAoFLUAAFJf3ANUWFioqqoqHTp0SNu3b1dLS4uefvppdXV19bp+ZWWlfD5fZAkEAvEeCQAwCHmccy6Rb9DZ2anx48dr69atWrFixR2Ph8NhhcPhyO1QKKRAIKBgMKj09PREjgYASIBQKCSfz3fXz/GEnx2QkZGhxx57TE1NTb0+7vV65fV6Ez0GAGCQSfjPAV2+fFnNzc3Kzc1N9FsBAJJI3AP0yiuvqLa2Vv/617/05z//WYsWLdLQoUP1/PPPx/utAABJLO7/BHf+/Hk9//zzunTpksaMGaOnnnpK9fX1GjNmTLzfCgCQxOIeoD179sT7JQEAKYhrwQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJhL+C+mA++XxeKxHiLsE/yJiIClwBAQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATXA0bAyo3N3dA3mewX216oK7wPdi3Ax5sHAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GCkGVHt7e8zPScULag7U36m/Fz1NxW2OwYcjIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABBcjBVLYtWvXrEcA+sQREADABAECAJiIOUDHjh3T/PnzlZeXJ4/Ho/3790c97pzTxo0blZubq5EjR6q4uFhnz56N17wAgBQRc4C6u7tVUFCgbdu29fr4li1b9M4772jHjh06fvy4Hn74YZWUlOjq1av3PSwAIHXEfBJCWVmZysrKen3MOae3335br7/+uhYsWCBJeu+995STk6P9+/frueeeu79pAQApI67fAbW0tKi9vV3FxcWR+3w+nwoLC1VXV9frc8LhsEKhUNQCAEh9cQ1Qe3u7JCknJyfq/pycnMhjt6usrJTP54ssgUAgniMBAAYp87PgNmzYoGAwGFlaW1utRwIADIC4Bsjv90uSOjo6ou7v6OiIPHY7r9er9PT0qAUAkPriGqD8/Hz5/X5VV1dH7guFQjp+/LiKiori+VYAgCQX81lwly9fVlNTU+R2S0uLTp06pczMTI0bN07r1q3TL37xC02aNEn5+fl64403lJeXp4ULF8ZzbgBAkos5QCdOnNAzzzwTuV1RUSFJWrZsmaqqqvTqq6+qu7tbq1atUmdnp5566ikdOnRIDz30UPymBgAkPY9zzlkP8WWhUEg+n0/BYJDvgyBJ8ng8MT9nkO3WZvqz7SS2H+7PvX6Om58FBwB4MBEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEzL+OARho/bkyc3+vAt0f//jHP2J+zqRJk2J+DlcFR6rhCAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSJGSBvIinE8++WTMzzl58mTMz+HCokg1HAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GCnwJR6PJ+bn/PGPf4z5OYsXL475Of2Z7b///W/Mz5GkoUOH9ut5QCw4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAxUqSk/ly4U5Kcc3GeJH76M1sqbgekDo6AAAAmCBAAwETMATp27Jjmz5+vvLw8eTwe7d+/P+rx5cuXy+PxRC2lpaXxmhcAkCJiDlB3d7cKCgq0bdu2PtcpLS1VW1tbZNm9e/d9DQkASD0xn4RQVlamsrKyr1zH6/XK7/f3eygAQOpLyHdANTU1ys7O1uTJk7VmzRpdunSpz3XD4bBCoVDUAgBIfXEPUGlpqd577z1VV1frV7/6lWpra1VWVqYbN270un5lZaV8Pl9kCQQC8R4JADAIedx9nPDv8Xi0b98+LVy4sM91/vnPf2rixIk6cuSI5s6de8fj4XBY4XA4cjsUCikQCCgYDCo9Pb2/o+EBx8+/3MR2gIVQKCSfz3fXz/GEn4Y9YcIEZWVlqampqdfHvV6v0tPToxYAQOpLeIDOnz+vS5cuKTc3N9FvBQBIIjGfBXf58uWoo5mWlhadOnVKmZmZyszM1ObNm7VkyRL5/X41Nzfr1Vdf1aOPPqqSkpK4Dg4ASG4xB+jEiRN65plnIrcrKiokScuWLdP27dt1+vRp/f73v1dnZ6fy8vI0b948/fznP5fX643f1ACApHdfJyEkwr1+eQV8Fb58vz/92X5sO9wyaE5CAACgNwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAR869jAJLBs88+az0CgLvgCAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSJGSsrOzrUcAcBccAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjzOOWc9xJeFQiH5fD4Fg0Glp6dbj4Mk5fF4+vW8Qfafg5n+bD+2HW65189xjoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPDrAcABpOysrKYn/Pxxx8nYJL44KKsGMw4AgIAmCBAAAATMQWosrJSM2bMUFpamrKzs7Vw4UI1NjZGrXP16lWVl5dr9OjReuSRR7RkyRJ1dHTEdWgAQPKLKUC1tbUqLy9XfX29Dh8+rOvXr2vevHnq7u6OrLN+/Xp99NFH2rt3r2pra3XhwgUtXrw47oMDAJJbTCchHDp0KOp2VVWVsrOz1dDQoNmzZysYDOq3v/2tdu3apWeffVaStHPnTn3zm99UfX29vvvd78ZvcgBAUruv74CCwaAkKTMzU5LU0NCg69evq7i4OLLOlClTNG7cONXV1fX6GuFwWKFQKGoBAKS+fgeop6dH69at06xZszR16lRJUnt7u0aMGKGMjIyodXNyctTe3t7r61RWVsrn80WWQCDQ35EAAEmk3wEqLy/XmTNntGfPnvsaYMOGDQoGg5GltbX1vl4PAJAc+vWDqGvXrtXBgwd17NgxjR07NnK/3+/XtWvX1NnZGXUU1NHRIb/f3+treb1eeb3e/owBAEhiMR0BOee0du1a7du3T0ePHlV+fn7U49OnT9fw4cNVXV0dua+xsVHnzp1TUVFRfCYGAKSEmI6AysvLtWvXLh04cEBpaWmR73V8Pp9Gjhwpn8+nFStWqKKiQpmZmUpPT9fLL7+soqIizoADAESJKUDbt2+XJM2ZMyfq/p07d2r58uWSpF//+tcaMmSIlixZonA4rJKSEv3mN7+Jy7AAgNThcYPsqoOhUEg+n0/BYFDp6enW4wB31d8Lfg6EQfafNx4Q9/o5zrXgAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYKJfvxEVwP9xxWmgfzgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiIKUCVlZWaMWOG0tLSlJ2drYULF6qxsTFqnTlz5sjj8UQtq1evjuvQAIDkF1OAamtrVV5ervr6eh0+fFjXr1/XvHnz1N3dHbXeypUr1dbWFlm2bNkS16EBAMlvWCwrHzp0KOp2VVWVsrOz1dDQoNmzZ0fuHzVqlPx+f3wmBACkpPv6DigYDEqSMjMzo+5///33lZWVpalTp2rDhg26cuVKn68RDocVCoWiFgBA6ovpCOjLenp6tG7dOs2aNUtTp06N3P/CCy9o/PjxysvL0+nTp/Xaa6+psbFRH374Ya+vU1lZqc2bN/d3DABAkvI451x/nrhmzRp9/PHH+vTTTzV27Ng+1zt69Kjmzp2rpqYmTZw48Y7Hw+GwwuFw5HYoFFIgEFAwGFR6enp/RgMAGAqFQvL5fHf9HO/XEdDatWt18OBBHTt27CvjI0mFhYWS1GeAvF6vvF5vf8YAACSxmALknNPLL7+sffv2qaamRvn5+Xd9zqlTpyRJubm5/RoQAJCaYgpQeXm5du3apQMHDigtLU3t7e2SJJ/Pp5EjR6q5uVm7du3S97//fY0ePVqnT5/W+vXrNXv2bE2bNi0hfwEAQHKK6Tsgj8fT6/07d+7U8uXL1draqh/84Ac6c+aMuru7FQgEtGjRIr3++uv3/H3Ovf7bIQBgcErId0B3a1UgEFBtbW0sLwkAeEBxLTgAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlh1gPczjknSQqFQsaTAAD649bn963P874MugB1dXVJkgKBgPEkAID70dXVJZ/P1+fjHne3RA2wnp4eXbhwQWlpafJ4PFGPhUIhBQIBtba2Kj093WhCe2yHm9gON7EdbmI73DQYtoNzTl1dXcrLy9OQIX1/0zPojoCGDBmisWPHfuU66enpD/QOdgvb4Sa2w01sh5vYDjdZb4evOvK5hZMQAAAmCBAAwERSBcjr9WrTpk3yer3Wo5hiO9zEdriJ7XAT2+GmZNoOg+4kBADAgyGpjoAAAKmDAAEATBAgAIAJAgQAMJE0Adq2bZu+8Y1v6KGHHlJhYaH+8pe/WI804N588015PJ6oZcqUKdZjJdyxY8c0f/585eXlyePxaP/+/VGPO+e0ceNG5ebmauTIkSouLtbZs2dthk2gu22H5cuX37F/lJaW2gybIJWVlZoxY4bS0tKUnZ2thQsXqrGxMWqdq1evqry8XKNHj9YjjzyiJUuWqKOjw2jixLiX7TBnzpw79ofVq1cbTdy7pAjQBx98oIqKCm3atEmfffaZCgoKVFJSoosXL1qPNuAef/xxtbW1RZZPP/3UeqSE6+7uVkFBgbZt29br41u2bNE777yjHTt26Pjx43r44YdVUlKiq1evDvCkiXW37SBJpaWlUfvH7t27B3DCxKutrVV5ebnq6+t1+PBhXb9+XfPmzVN3d3dknfXr1+ujjz7S3r17VVtbqwsXLmjx4sWGU8ffvWwHSVq5cmXU/rBlyxajifvgksDMmTNdeXl55PaNGzdcXl6eq6ysNJxq4G3atMkVFBRYj2FKktu3b1/kdk9Pj/P7/e6tt96K3NfZ2em8Xq/bvXu3wYQD4/bt4Jxzy5YtcwsWLDCZx8rFixedJFdbW+ucu/m//fDhw93evXsj6/ztb39zklxdXZ3VmAl3+3Zwzrnvfe977kc/+pHdUPdg0B8BXbt2TQ0NDSouLo7cN2TIEBUXF6uurs5wMhtnz55VXl6eJkyYoBdffFHnzp2zHslUS0uL2tvbo/YPn8+nwsLCB3L/qKmpUXZ2tiZPnqw1a9bo0qVL1iMlVDAYlCRlZmZKkhoaGnT9+vWo/WHKlCkaN25cSu8Pt2+HW95//31lZWVp6tSp2rBhg65cuWIxXp8G3cVIb/f555/rxo0bysnJibo/JydHf//7342mslFYWKiqqipNnjxZbW1t2rx5s55++mmdOXNGaWlp1uOZaG9vl6Re949bjz0oSktLtXjxYuXn56u5uVk//elPVVZWprq6Og0dOtR6vLjr6enRunXrNGvWLE2dOlXSzf1hxIgRysjIiFo3lfeH3raDJL3wwgsaP3688vLydPr0ab322mtqbGzUhx9+aDhttEEfIPxfWVlZ5M/Tpk1TYWGhxo8frz/84Q9asWKF4WQYDJ577rnIn5944glNmzZNEydOVE1NjebOnWs4WWKUl5frzJkzD8T3oF+lr+2watWqyJ+feOIJ5ebmau7cuWpubtbEiRMHesxeDfp/gsvKytLQoUPvOIulo6NDfr/faKrBISMjQ4899piampqsRzFzax9g/7jThAkTlJWVlZL7x9q1a3Xw4EF98sknUb++xe/369q1a+rs7IxaP1X3h762Q28KCwslaVDtD4M+QCNGjND06dNVXV0dua+np0fV1dUqKioynMze5cuX1dzcrNzcXOtRzOTn58vv90ftH6FQSMePH3/g94/z58/r0qVLKbV/OOe0du1a7du3T0ePHlV+fn7U49OnT9fw4cOj9ofGxkadO3cupfaHu22H3pw6dUqSBtf+YH0WxL3Ys2eP83q9rqqqyv31r391q1atchkZGa69vd16tAH14x//2NXU1LiWlhb3pz/9yRUXF7usrCx38eJF69ESqqury508edKdPHnSSXJbt251J0+edP/+97+dc8798pe/dBkZGe7AgQPu9OnTbsGCBS4/P9998cUXxpPH11dth66uLvfKK6+4uro619LS4o4cOeKefPJJN2nSJHf16lXr0eNmzZo1zufzuZqaGtfW1hZZrly5Elln9erVbty4ce7o0aPuxIkTrqioyBUVFRlOHX932w5NTU3uZz/7mTtx4oRraWlxBw4ccBMmTHCzZ882njxaUgTIOefeffddN27cODdixAg3c+ZMV19fbz3SgFu6dKnLzc11I0aMcF//+tfd0qVLXVNTk/VYCffJJ584SXcsy5Ytc87dPBX7jTfecDk5Oc7r9bq5c+e6xsZG26ET4Ku2w5UrV9y8efPcmDFj3PDhw9348ePdypUrU+7/pPX295fkdu7cGVnniy++cD/84Q/d1772NTdq1Ci3aNEi19bWZjd0AtxtO5w7d87Nnj3bZWZmOq/X6x599FH3k5/8xAWDQdvBb8OvYwAAmBj03wEBAFITAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDif3haemu9PAJrAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_8= number_8.reshape(1,28*28)"
      ],
      "metadata": {
        "id": "Z4nMVb-beX8h"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_8.shape"
      ],
      "metadata": {
        "id": "iI5n2i0tKfo8",
        "outputId": "c836ceef-7df4-4651-d5fd-5a6effccc3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit_classifier.classify(number_8, w)"
      ],
      "metadata": {
        "id": "f2BLVvzdJsK0",
        "outputId": "d2df3a8c-92ac-403c-f2f2-dccbe432ffa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 785 is different from 784)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-9c3a66842d7f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdigit_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/digit_classifier.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(X, w)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/digit_classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(X, w)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 785 is different from 784)"
          ]
        }
      ]
    }
  ]
}