{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNacwvkfvwvXLedhCqUMj0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanyelMorales/MLLearneerRepo/blob/main/02_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgPBM3Z8-WNS",
        "outputId": "d7f8cd34-1a39-41ed-feba-12fdb867bdd1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9680k  100 9680k    0     0  17.8M      0 --:--:-- --:--:-- --:--:-- 17.8M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6qyHHgk-cxD",
        "outputId": "31601a09-d397-48b3-ac5a-86e45f7bc96c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1610k  100 1610k    0     0  3882k      0 --:--:-- --:--:-- --:--:-- 3889k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW5YK1bLiKTr",
        "outputId": "97f5a71d-7494-4d05-9f65-982d58fb12f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 28881  100 28881    0     0   104k      0 --:--:-- --:--:-- --:--:--  104k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyqqE8MQizyb",
        "outputId": "8a90b353-141f-4b32-ce48-231579b19ccc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4542  100  4542    0     0  23255      0 --:--:-- --:--:-- --:--:-- 23292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"mnist.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/mnist.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNFxE90po5WY",
        "outputId": "88f9937d-e6a3-4c81-e6f3-d1a70ec1de47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1205  100  1205    0     0   5827      0 --:--:-- --:--:-- --:--:--  5849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"digit_classifier.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/digit_classifier.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-pPzdsqj59",
        "outputId": "fa8ea4e3-5302-49c7-ab96-6a211e76b60d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1478  100  1478    0     0   4481      0 --:--:-- --:--:-- --:--:--  4478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gk-M90M6gpD"
      },
      "outputs": [],
      "source": [
        "from mnist import prepend_bias, load_images, load_labels,encode_fives\n",
        "import digit_classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = prepend_bias(load_images(\"train-images-idx3-ubyte.gz\"))\n",
        "X_test = prepend_bias(load_images(\"t10k-images-idx3-ubyte.gz\"))\n",
        "Y_train = encode_fives(load_labels(\"train-labels-idx1-ubyte.gz\"))\n",
        "Y_test = encode_fives(load_labels(\"t10k-labels-idx1-ubyte.gz\"))"
      ],
      "metadata": {
        "id": "Lg1p-3hlkUVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = digit_classifier.train(X_train,Y_train,X_test,Y_test, iterations=200, lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-7u3wmhlYcW",
        "outputId": "b8505f9d-8a38-46da-d351-7607caae94d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - Loss: 0.6931471805599453,88.65\n",
            "200 - Loss: 0.6329712674925422,88.65\n",
            "1 - Loss: 0.6329712674925422,88.65\n",
            "200 - Loss: 0.4041504120613409,88.65\n",
            "2 - Loss: 0.4041504120613409,88.65\n",
            "200 - Loss: 0.20740137552095117,88.65\n",
            "3 - Loss: 0.20740137552095117,88.65\n",
            "200 - Loss: 0.10475739758236242,88.65\n",
            "4 - Loss: 0.10475739758236242,88.65\n",
            "200 - Loss: 0.084065844259969,88.65\n",
            "5 - Loss: 0.084065844259969,88.65\n",
            "200 - Loss: 0.08017763379914089,88.65\n",
            "6 - Loss: 0.08017763379914089,88.65\n",
            "200 - Loss: 0.07779278786107958,88.65\n",
            "7 - Loss: 0.07779278786107958,88.65\n",
            "200 - Loss: 0.0757192265712811,88.65\n",
            "8 - Loss: 0.0757192265712811,88.65\n",
            "200 - Loss: 0.07385842309425815,88.65\n",
            "9 - Loss: 0.07385842309425815,88.65\n",
            "200 - Loss: 0.07217526698365141,88.65\n",
            "10 - Loss: 0.07217526698365141,88.65\n",
            "200 - Loss: 0.0706439388687286,88.65\n",
            "11 - Loss: 0.0706439388687286,88.65\n",
            "200 - Loss: 0.06924364639852244,88.65\n",
            "12 - Loss: 0.06924364639852244,88.65\n",
            "200 - Loss: 0.06795734081897782,88.65\n",
            "13 - Loss: 0.06795734081897782,88.65\n",
            "200 - Loss: 0.06677088993872657,88.65\n",
            "14 - Loss: 0.06677088993872657,88.65\n",
            "200 - Loss: 0.06567246994486708,88.65\n",
            "15 - Loss: 0.06567246994486708,88.65\n",
            "200 - Loss: 0.06465210531601653,88.65\n",
            "16 - Loss: 0.06465210531601653,88.65\n",
            "200 - Loss: 0.06370131554251553,88.65\n",
            "17 - Loss: 0.06370131554251553,88.65\n",
            "200 - Loss: 0.06281284058480352,88.65\n",
            "18 - Loss: 0.06281284058480352,88.65\n",
            "200 - Loss: 0.061980425227391056,88.65\n",
            "19 - Loss: 0.061980425227391056,88.65\n",
            "200 - Loss: 0.06119864802861201,88.65\n",
            "20 - Loss: 0.06119864802861201,88.65\n",
            "200 - Loss: 0.0604627844122555,88.65\n",
            "21 - Loss: 0.0604627844122555,88.65\n",
            "200 - Loss: 0.059768696163828086,88.65\n",
            "22 - Loss: 0.059768696163828086,88.65\n",
            "200 - Loss: 0.0591127415404373,88.65\n",
            "23 - Loss: 0.0591127415404373,88.65\n",
            "200 - Loss: 0.05849170161493934,88.65\n",
            "24 - Loss: 0.05849170161493934,88.65\n",
            "200 - Loss: 0.0579027195104973,88.65\n",
            "25 - Loss: 0.0579027195104973,88.65\n",
            "200 - Loss: 0.057343249949256575,88.65\n",
            "26 - Loss: 0.057343249949256575,88.65\n",
            "200 - Loss: 0.05681101711337543,88.65\n",
            "27 - Loss: 0.05681101711337543,88.65\n",
            "200 - Loss: 0.05630397925065071,88.65\n",
            "28 - Loss: 0.05630397925065071,88.65\n",
            "200 - Loss: 0.05582029878766446,88.65\n",
            "29 - Loss: 0.05582029878766446,88.65\n",
            "200 - Loss: 0.05535831696739804,88.65\n",
            "30 - Loss: 0.05535831696739804,88.65\n",
            "200 - Loss: 0.05491653222489375,88.65\n",
            "31 - Loss: 0.05491653222489375,88.65\n",
            "200 - Loss: 0.05449358166786551,88.65\n",
            "32 - Loss: 0.05449358166786551,88.65\n",
            "200 - Loss: 0.05408822514953442,88.65\n",
            "33 - Loss: 0.05408822514953442,88.65\n",
            "200 - Loss: 0.05369933151609302,88.65\n",
            "34 - Loss: 0.05369933151609302,88.65\n",
            "200 - Loss: 0.053325866686843526,88.65\n",
            "35 - Loss: 0.053325866686843526,88.65\n",
            "200 - Loss: 0.05296688328556089,88.65\n",
            "36 - Loss: 0.05296688328556089,88.65\n",
            "200 - Loss: 0.05262151159029913,88.65\n",
            "37 - Loss: 0.05262151159029913,88.65\n",
            "200 - Loss: 0.052288951608217886,88.65\n",
            "38 - Loss: 0.052288951608217886,88.65\n",
            "200 - Loss: 0.05196846611399564,88.65\n",
            "39 - Loss: 0.05196846611399564,88.65\n",
            "200 - Loss: 0.05165937451652725,88.65\n",
            "40 - Loss: 0.05165937451652725,88.65\n",
            "200 - Loss: 0.0513610474400442,88.65\n",
            "41 - Loss: 0.0513610474400442,88.65\n",
            "200 - Loss: 0.05107290192347033,88.65\n",
            "42 - Loss: 0.05107290192347033,88.65\n",
            "200 - Loss: 0.05079439715645546,88.65\n",
            "43 - Loss: 0.05079439715645546,88.65\n",
            "200 - Loss: 0.05052503068268931,88.65\n",
            "44 - Loss: 0.05052503068268931,88.65\n",
            "200 - Loss: 0.050264335011244006,88.65\n",
            "45 - Loss: 0.050264335011244006,88.65\n",
            "200 - Loss: 0.05001187458519185,88.65\n",
            "46 - Loss: 0.05001187458519185,88.65\n",
            "200 - Loss: 0.04976724306388816,88.65\n",
            "47 - Loss: 0.04976724306388816,88.65\n",
            "200 - Loss: 0.04953006088133449,88.65\n",
            "48 - Loss: 0.04953006088133449,88.65\n",
            "200 - Loss: 0.04929997304813659,88.65\n",
            "49 - Loss: 0.04929997304813659,88.65\n",
            "200 - Loss: 0.049076647168900686,88.65\n",
            "50 - Loss: 0.049076647168900686,88.65\n",
            "200 - Loss: 0.04885977165059958,88.65\n",
            "51 - Loss: 0.04885977165059958,88.65\n",
            "200 - Loss: 0.04864905408058832,88.65\n",
            "52 - Loss: 0.04864905408058832,88.65\n",
            "200 - Loss: 0.04844421975564811,88.65\n",
            "53 - Loss: 0.04844421975564811,88.65\n",
            "200 - Loss: 0.04824501034575417,88.65\n",
            "54 - Loss: 0.04824501034575417,88.65\n",
            "200 - Loss: 0.04805118267825937,88.65\n",
            "55 - Loss: 0.04805118267825937,88.65\n",
            "200 - Loss: 0.04786250762990911,88.65\n",
            "56 - Loss: 0.04786250762990911,88.65\n",
            "200 - Loss: 0.04767876911559534,88.65\n",
            "57 - Loss: 0.04767876911559534,88.65\n",
            "200 - Loss: 0.047499763164051655,88.65\n",
            "58 - Loss: 0.047499763164051655,88.65\n",
            "200 - Loss: 0.04732529707181842,88.65\n",
            "59 - Loss: 0.04732529707181842,88.65\n",
            "200 - Loss: 0.047155188627788176,88.65\n",
            "60 - Loss: 0.047155188627788176,88.65\n",
            "200 - Loss: 0.046989265401499045,88.65\n",
            "61 - Loss: 0.046989265401499045,88.65\n",
            "200 - Loss: 0.04682736408909542,88.65\n",
            "62 - Loss: 0.04682736408909542,88.65\n",
            "200 - Loss: 0.04666932991153327,88.65\n",
            "63 - Loss: 0.04666932991153327,88.65\n",
            "200 - Loss: 0.046515016060186924,88.65\n",
            "64 - Loss: 0.046515016060186924,88.65\n",
            "200 - Loss: 0.04636428318552405,88.65\n",
            "65 - Loss: 0.04636428318552405,88.65\n",
            "200 - Loss: 0.046216998924965384,88.65\n",
            "66 - Loss: 0.046216998924965384,88.65\n",
            "200 - Loss: 0.046073037466444026,88.65\n",
            "67 - Loss: 0.046073037466444026,88.65\n",
            "200 - Loss: 0.045932279144530644,88.65\n",
            "68 - Loss: 0.045932279144530644,88.65\n",
            "200 - Loss: 0.04579461006630435,88.65\n",
            "69 - Loss: 0.04579461006630435,88.65\n",
            "200 - Loss: 0.04565992176442579,88.65\n",
            "70 - Loss: 0.04565992176442579,88.65\n",
            "200 - Loss: 0.04552811087511654,88.65\n",
            "71 - Loss: 0.04552811087511654,88.65\n",
            "200 - Loss: 0.04539907883896919,88.65\n",
            "72 - Loss: 0.04539907883896919,88.65\n",
            "200 - Loss: 0.04527273162270885,88.65\n",
            "73 - Loss: 0.04527273162270885,88.65\n",
            "200 - Loss: 0.045148979460203006,88.65\n",
            "74 - Loss: 0.045148979460203006,88.65\n",
            "200 - Loss: 0.045027736611173486,88.65\n",
            "75 - Loss: 0.045027736611173486,88.65\n",
            "200 - Loss: 0.04490892113620629,88.65\n",
            "76 - Loss: 0.04490892113620629,88.65\n",
            "200 - Loss: 0.044792454686780725,88.65\n",
            "77 - Loss: 0.044792454686780725,88.65\n",
            "200 - Loss: 0.04467826230915438,88.65\n",
            "78 - Loss: 0.04467826230915438,88.65\n",
            "200 - Loss: 0.04456627226104182,88.65\n",
            "79 - Loss: 0.04456627226104182,88.65\n",
            "200 - Loss: 0.04445641584011847,88.65\n",
            "80 - Loss: 0.04445641584011847,88.65\n",
            "200 - Loss: 0.04434862722346394,88.65\n",
            "81 - Loss: 0.04434862722346394,88.65\n",
            "200 - Loss: 0.04424284331713452,88.65\n",
            "82 - Loss: 0.04424284331713452,88.65\n",
            "200 - Loss: 0.044139003615123115,88.65\n",
            "83 - Loss: 0.044139003615123115,88.65\n",
            "200 - Loss: 0.04403705006702636,88.65\n",
            "84 - Loss: 0.04403705006702636,88.65\n",
            "200 - Loss: 0.04393692695379479,88.65\n",
            "85 - Loss: 0.04393692695379479,88.65\n",
            "200 - Loss: 0.043838580770993056,88.65\n",
            "86 - Loss: 0.043838580770993056,88.65\n",
            "200 - Loss: 0.04374196011904281,88.65\n",
            "87 - Loss: 0.04374196011904281,88.65\n",
            "200 - Loss: 0.04364701559996371,88.65\n",
            "88 - Loss: 0.04364701559996371,88.65\n",
            "200 - Loss: 0.043553699720165574,88.65\n",
            "89 - Loss: 0.043553699720165574,88.65\n",
            "200 - Loss: 0.04346196679888035,88.65\n",
            "90 - Loss: 0.04346196679888035,88.65\n",
            "200 - Loss: 0.04337177288185343,88.65\n",
            "91 - Loss: 0.04337177288185343,88.65\n",
            "200 - Loss: 0.0432830756599443,88.65\n",
            "92 - Loss: 0.0432830756599443,88.65\n",
            "200 - Loss: 0.043195834392311644,88.65\n",
            "93 - Loss: 0.043195834392311644,88.65\n",
            "200 - Loss: 0.043110009833883606,88.65\n",
            "94 - Loss: 0.043110009833883606,88.65\n",
            "200 - Loss: 0.04302556416683543,88.65\n",
            "95 - Loss: 0.04302556416683543,88.65\n",
            "200 - Loss: 0.04294246093581737,88.65\n",
            "96 - Loss: 0.04294246093581737,88.65\n",
            "200 - Loss: 0.042860664986694844,88.65\n",
            "97 - Loss: 0.042860664986694844,88.65\n",
            "200 - Loss: 0.042780142408579344,88.65\n",
            "98 - Loss: 0.042780142408579344,88.65\n",
            "200 - Loss: 0.042700860478945134,88.65\n",
            "99 - Loss: 0.042700860478945134,88.65\n",
            "200 - Loss: 0.04262278761164085,88.65\n",
            "100 - Loss: 0.04262278761164085,88.65\n",
            "200 - Loss: 0.0425458933076189,88.65\n",
            "101 - Loss: 0.0425458933076189,88.65\n",
            "200 - Loss: 0.04247014810821736,88.65\n",
            "102 - Loss: 0.04247014810821736,88.65\n",
            "200 - Loss: 0.04239552355084136,88.65\n",
            "103 - Loss: 0.04239552355084136,88.65\n",
            "200 - Loss: 0.04232199212690031,88.65\n",
            "104 - Loss: 0.04232199212690031,88.65\n",
            "200 - Loss: 0.04224952724186793,88.65\n",
            "105 - Loss: 0.04224952724186793,88.65\n",
            "200 - Loss: 0.042178103177340824,88.65\n",
            "106 - Loss: 0.042178103177340824,88.65\n",
            "200 - Loss: 0.04210769505497905,88.65\n",
            "107 - Loss: 0.04210769505497905,88.65\n",
            "200 - Loss: 0.042038278802220795,88.65\n",
            "108 - Loss: 0.042038278802220795,88.65\n",
            "200 - Loss: 0.04196983111966939,88.65\n",
            "109 - Loss: 0.04196983111966939,88.65\n",
            "200 - Loss: 0.041902329450058194,88.65\n",
            "110 - Loss: 0.041902329450058194,88.65\n",
            "200 - Loss: 0.041835751948704536,88.65\n",
            "111 - Loss: 0.041835751948704536,88.65\n",
            "200 - Loss: 0.04177007745537001,88.65\n",
            "112 - Loss: 0.04177007745537001,88.65\n",
            "200 - Loss: 0.041705285467448984,88.65\n",
            "113 - Loss: 0.041705285467448984,88.65\n",
            "200 - Loss: 0.04164135611441294,88.65\n",
            "114 - Loss: 0.04164135611441294,88.65\n",
            "200 - Loss: 0.041578270133442057,88.65\n",
            "115 - Loss: 0.041578270133442057,88.65\n",
            "200 - Loss: 0.041516008846180084,88.65\n",
            "116 - Loss: 0.041516008846180084,88.65\n",
            "200 - Loss: 0.04145455413655241,88.65\n",
            "117 - Loss: 0.04145455413655241,88.65\n",
            "200 - Loss: 0.04139388842959075,88.65\n",
            "118 - Loss: 0.04139388842959075,88.65\n",
            "200 - Loss: 0.0413339946712115,88.65\n",
            "119 - Loss: 0.0413339946712115,88.65\n",
            "200 - Loss: 0.041274856308897774,88.65\n",
            "120 - Loss: 0.041274856308897774,88.65\n",
            "200 - Loss: 0.04121645727323835,88.65\n",
            "121 - Loss: 0.04121645727323835,88.65\n",
            "200 - Loss: 0.04115878196027928,88.65\n",
            "122 - Loss: 0.04115878196027928,88.65\n",
            "200 - Loss: 0.04110181521464658,88.65\n",
            "123 - Loss: 0.04110181521464658,88.65\n",
            "200 - Loss: 0.04104554231340104,88.65\n",
            "124 - Loss: 0.04104554231340104,88.65\n",
            "200 - Loss: 0.04098994895058806,88.65\n",
            "125 - Loss: 0.04098994895058806,88.65\n",
            "200 - Loss: 0.04093502122244787,88.65\n",
            "126 - Loss: 0.04093502122244787,88.65\n",
            "200 - Loss: 0.04088074561325338,88.65\n",
            "127 - Loss: 0.04088074561325338,88.65\n",
            "200 - Loss: 0.04082710898174461,88.65\n",
            "128 - Loss: 0.04082710898174461,88.65\n",
            "200 - Loss: 0.04077409854813054,88.65\n",
            "129 - Loss: 0.04077409854813054,88.65\n",
            "200 - Loss: 0.040721701881630934,88.65\n",
            "130 - Loss: 0.040721701881630934,88.65\n",
            "200 - Loss: 0.04066990688853193,88.65\n",
            "131 - Loss: 0.04066990688853193,88.65\n",
            "200 - Loss: 0.04061870180073069,88.65\n",
            "132 - Loss: 0.04061870180073069,88.65\n",
            "200 - Loss: 0.040568075164746274,88.65\n",
            "133 - Loss: 0.040568075164746274,88.65\n",
            "200 - Loss: 0.04051801583117411,88.65\n",
            "134 - Loss: 0.04051801583117411,88.65\n",
            "200 - Loss: 0.0404685129445637,88.65\n",
            "135 - Loss: 0.0404685129445637,88.65\n",
            "200 - Loss: 0.04041955593369969,88.65\n",
            "136 - Loss: 0.04041955593369969,88.65\n",
            "200 - Loss: 0.040371134502267446,88.65\n",
            "137 - Loss: 0.040371134502267446,88.65\n",
            "200 - Loss: 0.04032323861988583,88.65\n",
            "138 - Loss: 0.04032323861988583,88.65\n",
            "200 - Loss: 0.04027585851349004,88.65\n",
            "139 - Loss: 0.04027585851349004,88.65\n",
            "200 - Loss: 0.04022898465904883,88.65\n",
            "140 - Loss: 0.04022898465904883,88.65\n",
            "200 - Loss: 0.040182607773600956,88.65\n",
            "141 - Loss: 0.040182607773600956,88.65\n",
            "200 - Loss: 0.040136718807596596,88.65\n",
            "142 - Loss: 0.040136718807596596,88.65\n",
            "200 - Loss: 0.040091308937530074,88.65\n",
            "143 - Loss: 0.040091308937530074,88.65\n",
            "200 - Loss: 0.040046369558851214,88.65\n",
            "144 - Loss: 0.040046369558851214,88.65\n",
            "200 - Loss: 0.04000189227914276,88.65\n",
            "145 - Loss: 0.04000189227914276,88.65\n",
            "200 - Loss: 0.03995786891155265,88.65\n",
            "146 - Loss: 0.03995786891155265,88.65\n",
            "200 - Loss: 0.039914291468469656,88.65\n",
            "147 - Loss: 0.039914291468469656,88.65\n",
            "200 - Loss: 0.03987115215543229,88.65\n",
            "148 - Loss: 0.03987115215543229,88.65\n",
            "200 - Loss: 0.039828443365260646,88.65\n",
            "149 - Loss: 0.039828443365260646,88.65\n",
            "200 - Loss: 0.039786157672401984,88.65\n",
            "150 - Loss: 0.039786157672401984,88.65\n",
            "200 - Loss: 0.039744287827480795,88.65\n",
            "151 - Loss: 0.039744287827480795,88.65\n",
            "200 - Loss: 0.03970282675204485,88.65\n",
            "152 - Loss: 0.03970282675204485,88.65\n",
            "200 - Loss: 0.039661767533498954,88.65\n",
            "153 - Loss: 0.039661767533498954,88.65\n",
            "200 - Loss: 0.039621103420218795,88.65\n",
            "154 - Loss: 0.039621103420218795,88.65\n",
            "200 - Loss: 0.039580827816837166,88.65\n",
            "155 - Loss: 0.039580827816837166,88.65\n",
            "200 - Loss: 0.03954093427969579,88.65\n",
            "156 - Loss: 0.03954093427969579,88.65\n",
            "200 - Loss: 0.0395014165124556,88.65\n",
            "157 - Loss: 0.0395014165124556,88.65\n",
            "200 - Loss: 0.03946226836185967,88.65\n",
            "158 - Loss: 0.03946226836185967,88.65\n",
            "200 - Loss: 0.039423483813641795,88.65\n",
            "159 - Loss: 0.039423483813641795,88.65\n",
            "200 - Loss: 0.039385056988575674,88.65\n",
            "160 - Loss: 0.039385056988575674,88.65\n",
            "200 - Loss: 0.03934698213865862,88.65\n",
            "161 - Loss: 0.03934698213865862,88.65\n",
            "200 - Loss: 0.03930925364342459,88.65\n",
            "162 - Loss: 0.03930925364342459,88.65\n",
            "200 - Loss: 0.03927186600638142,88.65\n",
            "163 - Loss: 0.03927186600638142,88.65\n",
            "200 - Loss: 0.03923481385156753,88.65\n",
            "164 - Loss: 0.03923481385156753,88.65\n",
            "200 - Loss: 0.03919809192022326,88.65\n",
            "165 - Loss: 0.03919809192022326,88.65\n",
            "200 - Loss: 0.039161695067572395,88.65\n",
            "166 - Loss: 0.039161695067572395,88.65\n",
            "200 - Loss: 0.03912561825970986,88.65\n",
            "167 - Loss: 0.03912561825970986,88.65\n",
            "200 - Loss: 0.03908985657059125,88.65\n",
            "168 - Loss: 0.03908985657059125,88.65\n",
            "200 - Loss: 0.039054405179120455,88.65\n",
            "169 - Loss: 0.039054405179120455,88.65\n",
            "200 - Loss: 0.03901925936633168,88.65\n",
            "170 - Loss: 0.03901925936633168,88.65\n",
            "200 - Loss: 0.0389844145126622,88.65\n",
            "171 - Loss: 0.0389844145126622,88.65\n",
            "200 - Loss: 0.03894986609531247,88.65\n",
            "172 - Loss: 0.03894986609531247,88.65\n",
            "200 - Loss: 0.03891560968569054,88.65\n",
            "173 - Loss: 0.03891560968569054,88.65\n",
            "200 - Loss: 0.03888164094693725,88.65\n",
            "174 - Loss: 0.03888164094693725,88.65\n",
            "200 - Loss: 0.038847955631529596,88.65\n",
            "175 - Loss: 0.038847955631529596,88.65\n",
            "200 - Loss: 0.03881454957895922,88.65\n",
            "176 - Loss: 0.03881454957895922,88.65\n",
            "200 - Loss: 0.03878141871348337,88.65\n",
            "177 - Loss: 0.03878141871348337,88.65\n",
            "200 - Loss: 0.038748559041945484,88.65\n",
            "178 - Loss: 0.038748559041945484,88.65\n",
            "200 - Loss: 0.03871596665166327,88.65\n",
            "179 - Loss: 0.03871596665166327,88.65\n",
            "200 - Loss: 0.03868363770838141,88.65\n",
            "180 - Loss: 0.03868363770838141,88.65\n",
            "200 - Loss: 0.03865156845428701,88.65\n",
            "181 - Loss: 0.03865156845428701,88.65\n",
            "200 - Loss: 0.03861975520608518,88.65\n",
            "182 - Loss: 0.03861975520608518,88.65\n",
            "200 - Loss: 0.03858819435313293,88.65\n",
            "183 - Loss: 0.03858819435313293,88.65\n",
            "200 - Loss: 0.03855688235562906,88.65\n",
            "184 - Loss: 0.03855688235562906,88.65\n",
            "200 - Loss: 0.03852581574285839,88.65\n",
            "185 - Loss: 0.03852581574285839,88.65\n",
            "200 - Loss: 0.03849499111148803,88.65\n",
            "186 - Loss: 0.03849499111148803,88.65\n",
            "200 - Loss: 0.038464405123914414,88.65\n",
            "187 - Loss: 0.038464405123914414,88.65\n",
            "200 - Loss: 0.038434054506658724,88.65\n",
            "188 - Loss: 0.038434054506658724,88.65\n",
            "200 - Loss: 0.038403936048809664,88.65\n",
            "189 - Loss: 0.038403936048809664,88.65\n",
            "200 - Loss: 0.038374046600511476,88.65\n",
            "190 - Loss: 0.038374046600511476,88.65\n",
            "200 - Loss: 0.03834438307149599,88.65\n",
            "191 - Loss: 0.03834438307149599,88.65\n",
            "200 - Loss: 0.038314942429656995,88.65\n",
            "192 - Loss: 0.038314942429656995,88.65\n",
            "200 - Loss: 0.03828572169966564,88.65\n",
            "193 - Loss: 0.03828572169966564,88.65\n",
            "200 - Loss: 0.038256717961625455,88.65\n",
            "194 - Loss: 0.038256717961625455,88.65\n",
            "200 - Loss: 0.03822792834976569,88.65\n",
            "195 - Loss: 0.03822792834976569,88.65\n",
            "200 - Loss: 0.038199350051171616,88.65\n",
            "196 - Loss: 0.038199350051171616,88.65\n",
            "200 - Loss: 0.0381709803045507,88.65\n",
            "197 - Loss: 0.0381709803045507,88.65\n",
            "200 - Loss: 0.03814281639903334,88.65\n",
            "198 - Loss: 0.03814281639903334,88.65\n",
            "200 - Loss: 0.03811485567300718,88.65\n",
            "199 - Loss: 0.03811485567300718,88.65\n",
            "200 - Loss: 0.03808709551298378,88.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit_classifier.test(X_test, Y_test, w)"
      ],
      "metadata": {
        "id": "af_Vtzu6y6wS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}