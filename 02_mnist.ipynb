{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9avLHRikU2LwN0b/0ohMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanyelMorales/MLLearneerRepo/blob/main/02_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgPBM3Z8-WNS",
        "outputId": "a9b7c528-73fc-4c83-d1a3-045c440c5330"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9680k  100 9680k    0     0  8484k      0  0:00:01  0:00:01 --:--:-- 8491k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-images-idx3-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-images-idx3-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6qyHHgk-cxD",
        "outputId": "0f6651fc-f16e-46be-e7b9-aa7b7de9fde0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1610k  100 1610k    0     0  2609k      0 --:--:-- --:--:-- --:--:-- 2609k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"train-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/train-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW5YK1bLiKTr",
        "outputId": "882a2668-3c2a-4e9f-f72a-b647f2014e29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 28881  100 28881    0     0  66038      0 --:--:-- --:--:-- --:--:-- 66089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"t10k-labels-idx1-ubyte.gz\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/t10k-labels-idx1-ubyte.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyqqE8MQizyb",
        "outputId": "f23bb39b-f742-459e-e1d9-04e1ffd025a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4542  100  4542    0     0   9036      0 --:--:-- --:--:-- --:--:--  9047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"mnist.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/mnist.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNFxE90po5WY",
        "outputId": "5dba924a-ce3d-41c5-ec79-0c460e8f00dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1205  100  1205    0     0   2974      0 --:--:-- --:--:-- --:--:--  2975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"digit_classifier.py\" \"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/lib/digit_classifier.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB-pPzdsqj59",
        "outputId": "272c373a-a1d7-4d7c-9b72-679838ce6cc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1481  100  1481    0     0   3181      0 --:--:-- --:--:-- --:--:--  3184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gk-M90M6gpD"
      },
      "outputs": [],
      "source": [
        "from mnist import prepend_bias, load_images, load_labels,encode_fives\n",
        "import digit_classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train = prepend_bias(load_images(\"train-images-idx3-ubyte.gz\"))\n",
        "X_test = prepend_bias(load_images(\"t10k-images-idx3-ubyte.gz\"))\n",
        "Y_train = encode_fives(load_labels(\"train-labels-idx1-ubyte.gz\"))\n",
        "Y_test = encode_fives(load_labels(\"t10k-labels-idx1-ubyte.gz\"))"
      ],
      "metadata": {
        "id": "Lg1p-3hlkUVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = digit_classifier.train(X_train,Y_train,X_test,Y_test, iterations=200, lr=1e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-7u3wmhlYcW",
        "outputId": "66103d99-1ade-4fed-8ec8-98279714cda1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - Loss: 0.6931471805599453, \n",
            " 88.65%\n",
            "1 - Loss: 0.6329712674925422, \n",
            " 88.65%\n",
            "2 - Loss: 0.4041504120613409, \n",
            " 88.65%\n",
            "3 - Loss: 0.20740137552095117, \n",
            " 88.65%\n",
            "4 - Loss: 0.10475739758236242, \n",
            " 88.65%\n",
            "5 - Loss: 0.084065844259969, \n",
            " 88.65%\n",
            "6 - Loss: 0.08017763379914089, \n",
            " 88.65%\n",
            "7 - Loss: 0.07779278786107958, \n",
            " 88.65%\n",
            "8 - Loss: 0.0757192265712811, \n",
            " 88.65%\n",
            "9 - Loss: 0.07385842309425815, \n",
            " 88.65%\n",
            "10 - Loss: 0.07217526698365141, \n",
            " 88.65%\n",
            "11 - Loss: 0.0706439388687286, \n",
            " 88.65%\n",
            "12 - Loss: 0.06924364639852244, \n",
            " 88.65%\n",
            "13 - Loss: 0.06795734081897782, \n",
            " 88.65%\n",
            "14 - Loss: 0.06677088993872657, \n",
            " 88.65%\n",
            "15 - Loss: 0.06567246994486708, \n",
            " 88.65%\n",
            "16 - Loss: 0.06465210531601653, \n",
            " 88.65%\n",
            "17 - Loss: 0.06370131554251553, \n",
            " 88.65%\n",
            "18 - Loss: 0.06281284058480352, \n",
            " 88.65%\n",
            "19 - Loss: 0.061980425227391056, \n",
            " 88.65%\n",
            "20 - Loss: 0.06119864802861201, \n",
            " 88.65%\n",
            "21 - Loss: 0.0604627844122555, \n",
            " 88.65%\n",
            "22 - Loss: 0.059768696163828086, \n",
            " 88.65%\n",
            "23 - Loss: 0.0591127415404373, \n",
            " 88.65%\n",
            "24 - Loss: 0.05849170161493934, \n",
            " 88.65%\n",
            "25 - Loss: 0.0579027195104973, \n",
            " 88.65%\n",
            "26 - Loss: 0.057343249949256575, \n",
            " 88.65%\n",
            "27 - Loss: 0.05681101711337543, \n",
            " 88.65%\n",
            "28 - Loss: 0.05630397925065071, \n",
            " 88.65%\n",
            "29 - Loss: 0.05582029878766446, \n",
            " 88.65%\n",
            "30 - Loss: 0.05535831696739804, \n",
            " 88.65%\n",
            "31 - Loss: 0.05491653222489375, \n",
            " 88.65%\n",
            "32 - Loss: 0.05449358166786551, \n",
            " 88.65%\n",
            "33 - Loss: 0.05408822514953442, \n",
            " 88.65%\n",
            "34 - Loss: 0.05369933151609302, \n",
            " 88.65%\n",
            "35 - Loss: 0.053325866686843526, \n",
            " 88.65%\n",
            "36 - Loss: 0.05296688328556089, \n",
            " 88.65%\n",
            "37 - Loss: 0.05262151159029913, \n",
            " 88.65%\n",
            "38 - Loss: 0.052288951608217886, \n",
            " 88.65%\n",
            "39 - Loss: 0.05196846611399564, \n",
            " 88.65%\n",
            "40 - Loss: 0.05165937451652725, \n",
            " 88.65%\n",
            "41 - Loss: 0.0513610474400442, \n",
            " 88.65%\n",
            "42 - Loss: 0.05107290192347033, \n",
            " 88.65%\n",
            "43 - Loss: 0.05079439715645546, \n",
            " 88.65%\n",
            "44 - Loss: 0.05052503068268931, \n",
            " 88.65%\n",
            "45 - Loss: 0.050264335011244006, \n",
            " 88.65%\n",
            "46 - Loss: 0.05001187458519185, \n",
            " 88.65%\n",
            "47 - Loss: 0.04976724306388816, \n",
            " 88.65%\n",
            "48 - Loss: 0.04953006088133449, \n",
            " 88.65%\n",
            "49 - Loss: 0.04929997304813659, \n",
            " 88.65%\n",
            "50 - Loss: 0.049076647168900686, \n",
            " 88.65%\n",
            "51 - Loss: 0.04885977165059958, \n",
            " 88.65%\n",
            "52 - Loss: 0.04864905408058832, \n",
            " 88.65%\n",
            "53 - Loss: 0.04844421975564811, \n",
            " 88.65%\n",
            "54 - Loss: 0.04824501034575417, \n",
            " 88.65%\n",
            "55 - Loss: 0.04805118267825937, \n",
            " 88.65%\n",
            "56 - Loss: 0.04786250762990911, \n",
            " 88.65%\n",
            "57 - Loss: 0.04767876911559534, \n",
            " 88.65%\n",
            "58 - Loss: 0.047499763164051655, \n",
            " 88.65%\n",
            "59 - Loss: 0.04732529707181842, \n",
            " 88.65%\n",
            "60 - Loss: 0.047155188627788176, \n",
            " 88.65%\n",
            "61 - Loss: 0.046989265401499045, \n",
            " 88.65%\n",
            "62 - Loss: 0.04682736408909542, \n",
            " 88.65%\n",
            "63 - Loss: 0.04666932991153327, \n",
            " 88.65%\n",
            "64 - Loss: 0.046515016060186924, \n",
            " 88.65%\n",
            "65 - Loss: 0.04636428318552405, \n",
            " 88.65%\n",
            "66 - Loss: 0.046216998924965384, \n",
            " 88.65%\n",
            "67 - Loss: 0.046073037466444026, \n",
            " 88.65%\n",
            "68 - Loss: 0.045932279144530644, \n",
            " 88.65%\n",
            "69 - Loss: 0.04579461006630435, \n",
            " 88.65%\n",
            "70 - Loss: 0.04565992176442579, \n",
            " 88.65%\n",
            "71 - Loss: 0.04552811087511654, \n",
            " 88.65%\n",
            "72 - Loss: 0.04539907883896919, \n",
            " 88.65%\n",
            "73 - Loss: 0.04527273162270885, \n",
            " 88.65%\n",
            "74 - Loss: 0.045148979460203006, \n",
            " 88.65%\n",
            "75 - Loss: 0.045027736611173486, \n",
            " 88.65%\n",
            "76 - Loss: 0.04490892113620629, \n",
            " 88.65%\n",
            "77 - Loss: 0.044792454686780725, \n",
            " 88.65%\n",
            "78 - Loss: 0.04467826230915438, \n",
            " 88.65%\n",
            "79 - Loss: 0.04456627226104182, \n",
            " 88.65%\n",
            "80 - Loss: 0.04445641584011847, \n",
            " 88.65%\n",
            "81 - Loss: 0.04434862722346394, \n",
            " 88.65%\n",
            "82 - Loss: 0.04424284331713452, \n",
            " 88.65%\n",
            "83 - Loss: 0.044139003615123115, \n",
            " 88.65%\n",
            "84 - Loss: 0.04403705006702636, \n",
            " 88.65%\n",
            "85 - Loss: 0.04393692695379479, \n",
            " 88.65%\n",
            "86 - Loss: 0.043838580770993056, \n",
            " 88.65%\n",
            "87 - Loss: 0.04374196011904281, \n",
            " 88.65%\n",
            "88 - Loss: 0.04364701559996371, \n",
            " 88.65%\n",
            "89 - Loss: 0.043553699720165574, \n",
            " 88.65%\n",
            "90 - Loss: 0.04346196679888035, \n",
            " 88.65%\n",
            "91 - Loss: 0.04337177288185343, \n",
            " 88.65%\n",
            "92 - Loss: 0.0432830756599443, \n",
            " 88.65%\n",
            "93 - Loss: 0.043195834392311644, \n",
            " 88.65%\n",
            "94 - Loss: 0.043110009833883606, \n",
            " 88.65%\n",
            "95 - Loss: 0.04302556416683543, \n",
            " 88.65%\n",
            "96 - Loss: 0.04294246093581737, \n",
            " 88.65%\n",
            "97 - Loss: 0.042860664986694844, \n",
            " 88.65%\n",
            "98 - Loss: 0.042780142408579344, \n",
            " 88.65%\n",
            "99 - Loss: 0.042700860478945134, \n",
            " 88.65%\n",
            "100 - Loss: 0.04262278761164085, \n",
            " 88.65%\n",
            "101 - Loss: 0.0425458933076189, \n",
            " 88.65%\n",
            "102 - Loss: 0.04247014810821736, \n",
            " 88.65%\n",
            "103 - Loss: 0.04239552355084136, \n",
            " 88.65%\n",
            "104 - Loss: 0.04232199212690031, \n",
            " 88.65%\n",
            "105 - Loss: 0.04224952724186793, \n",
            " 88.65%\n",
            "106 - Loss: 0.042178103177340824, \n",
            " 88.65%\n",
            "107 - Loss: 0.04210769505497905, \n",
            " 88.65%\n",
            "108 - Loss: 0.042038278802220795, \n",
            " 88.65%\n",
            "109 - Loss: 0.04196983111966939, \n",
            " 88.65%\n",
            "110 - Loss: 0.041902329450058194, \n",
            " 88.65%\n",
            "111 - Loss: 0.041835751948704536, \n",
            " 88.65%\n",
            "112 - Loss: 0.04177007745537001, \n",
            " 88.65%\n",
            "113 - Loss: 0.041705285467448984, \n",
            " 88.65%\n",
            "114 - Loss: 0.04164135611441294, \n",
            " 88.65%\n",
            "115 - Loss: 0.041578270133442057, \n",
            " 88.65%\n",
            "116 - Loss: 0.041516008846180084, \n",
            " 88.65%\n",
            "117 - Loss: 0.04145455413655241, \n",
            " 88.65%\n",
            "118 - Loss: 0.04139388842959075, \n",
            " 88.65%\n",
            "119 - Loss: 0.0413339946712115, \n",
            " 88.65%\n",
            "120 - Loss: 0.041274856308897774, \n",
            " 88.65%\n",
            "121 - Loss: 0.04121645727323835, \n",
            " 88.65%\n",
            "122 - Loss: 0.04115878196027928, \n",
            " 88.65%\n",
            "123 - Loss: 0.04110181521464658, \n",
            " 88.65%\n",
            "124 - Loss: 0.04104554231340104, \n",
            " 88.65%\n",
            "125 - Loss: 0.04098994895058806, \n",
            " 88.65%\n",
            "126 - Loss: 0.04093502122244787, \n",
            " 88.65%\n",
            "127 - Loss: 0.04088074561325338, \n",
            " 88.65%\n",
            "128 - Loss: 0.04082710898174461, \n",
            " 88.65%\n",
            "129 - Loss: 0.04077409854813054, \n",
            " 88.65%\n",
            "130 - Loss: 0.040721701881630934, \n",
            " 88.65%\n",
            "131 - Loss: 0.04066990688853193, \n",
            " 88.65%\n",
            "132 - Loss: 0.04061870180073069, \n",
            " 88.65%\n",
            "133 - Loss: 0.040568075164746274, \n",
            " 88.65%\n",
            "134 - Loss: 0.04051801583117411, \n",
            " 88.65%\n",
            "135 - Loss: 0.0404685129445637, \n",
            " 88.65%\n",
            "136 - Loss: 0.04041955593369969, \n",
            " 88.65%\n",
            "137 - Loss: 0.040371134502267446, \n",
            " 88.65%\n",
            "138 - Loss: 0.04032323861988583, \n",
            " 88.65%\n",
            "139 - Loss: 0.04027585851349004, \n",
            " 88.65%\n",
            "140 - Loss: 0.04022898465904883, \n",
            " 88.65%\n",
            "141 - Loss: 0.040182607773600956, \n",
            " 88.65%\n",
            "142 - Loss: 0.040136718807596596, \n",
            " 88.65%\n",
            "143 - Loss: 0.040091308937530074, \n",
            " 88.65%\n",
            "144 - Loss: 0.040046369558851214, \n",
            " 88.65%\n",
            "145 - Loss: 0.04000189227914276, \n",
            " 88.65%\n",
            "146 - Loss: 0.03995786891155265, \n",
            " 88.65%\n",
            "147 - Loss: 0.039914291468469656, \n",
            " 88.65%\n",
            "148 - Loss: 0.03987115215543229, \n",
            " 88.65%\n",
            "149 - Loss: 0.039828443365260646, \n",
            " 88.65%\n",
            "150 - Loss: 0.039786157672401984, \n",
            " 88.65%\n",
            "151 - Loss: 0.039744287827480795, \n",
            " 88.65%\n",
            "152 - Loss: 0.03970282675204485, \n",
            " 88.65%\n",
            "153 - Loss: 0.039661767533498954, \n",
            " 88.65%\n",
            "154 - Loss: 0.039621103420218795, \n",
            " 88.65%\n",
            "155 - Loss: 0.039580827816837166, \n",
            " 88.65%\n",
            "156 - Loss: 0.03954093427969579, \n",
            " 88.65%\n",
            "157 - Loss: 0.0395014165124556, \n",
            " 88.65%\n",
            "158 - Loss: 0.03946226836185967, \n",
            " 88.65%\n",
            "159 - Loss: 0.039423483813641795, \n",
            " 88.65%\n",
            "160 - Loss: 0.039385056988575674, \n",
            " 88.65%\n",
            "161 - Loss: 0.03934698213865862, \n",
            " 88.65%\n",
            "162 - Loss: 0.03930925364342459, \n",
            " 88.65%\n",
            "163 - Loss: 0.03927186600638142, \n",
            " 88.65%\n",
            "164 - Loss: 0.03923481385156753, \n",
            " 88.65%\n",
            "165 - Loss: 0.03919809192022326, \n",
            " 88.65%\n",
            "166 - Loss: 0.039161695067572395, \n",
            " 88.65%\n",
            "167 - Loss: 0.03912561825970986, \n",
            " 88.65%\n",
            "168 - Loss: 0.03908985657059125, \n",
            " 88.65%\n",
            "169 - Loss: 0.039054405179120455, \n",
            " 88.65%\n",
            "170 - Loss: 0.03901925936633168, \n",
            " 88.65%\n",
            "171 - Loss: 0.0389844145126622, \n",
            " 88.65%\n",
            "172 - Loss: 0.03894986609531247, \n",
            " 88.65%\n",
            "173 - Loss: 0.03891560968569054, \n",
            " 88.65%\n",
            "174 - Loss: 0.03888164094693725, \n",
            " 88.65%\n",
            "175 - Loss: 0.038847955631529596, \n",
            " 88.65%\n",
            "176 - Loss: 0.03881454957895922, \n",
            " 88.65%\n",
            "177 - Loss: 0.03878141871348337, \n",
            " 88.65%\n",
            "178 - Loss: 0.038748559041945484, \n",
            " 88.65%\n",
            "179 - Loss: 0.03871596665166327, \n",
            " 88.65%\n",
            "180 - Loss: 0.03868363770838141, \n",
            " 88.65%\n",
            "181 - Loss: 0.03865156845428701, \n",
            " 88.65%\n",
            "182 - Loss: 0.03861975520608518, \n",
            " 88.65%\n",
            "183 - Loss: 0.03858819435313293, \n",
            " 88.65%\n",
            "184 - Loss: 0.03855688235562906, \n",
            " 88.65%\n",
            "185 - Loss: 0.03852581574285839, \n",
            " 88.65%\n",
            "186 - Loss: 0.03849499111148803, \n",
            " 88.65%\n",
            "187 - Loss: 0.038464405123914414, \n",
            " 88.65%\n",
            "188 - Loss: 0.038434054506658724, \n",
            " 88.65%\n",
            "189 - Loss: 0.038403936048809664, \n",
            " 88.65%\n",
            "190 - Loss: 0.038374046600511476, \n",
            " 88.65%\n",
            "191 - Loss: 0.03834438307149599, \n",
            " 88.65%\n",
            "192 - Loss: 0.038314942429656995, \n",
            " 88.65%\n",
            "193 - Loss: 0.03828572169966564, \n",
            " 88.65%\n",
            "194 - Loss: 0.038256717961625455, \n",
            " 88.65%\n",
            "195 - Loss: 0.03822792834976569, \n",
            " 88.65%\n",
            "196 - Loss: 0.038199350051171616, \n",
            " 88.65%\n",
            "197 - Loss: 0.0381709803045507, \n",
            " 88.65%\n",
            "198 - Loss: 0.03814281639903334, \n",
            " 88.65%\n",
            "199 - Loss: 0.03811485567300718, \n",
            " 88.65%\n",
            "200 - Loss: 0.03808709551298378, \n",
            " 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digit_classifier.test(X_test, Y_test, w)"
      ],
      "metadata": {
        "id": "af_Vtzu6y6wS",
        "outputId": "3529c8cc-8d7f-4810-8b1c-c255d0633754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: 8865/10000 88.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o \"img_8.png\" \"https://github.com/DanyelMorales/MLLearneerRepo/blob/main/dataset/8_handwritten.png?raw=true\""
      ],
      "metadata": {
        "id": "q-tSbFPTcA-P",
        "outputId": "73d16595-42a1-4138-ff24-5a695161ef5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def load_image(file):\n",
        "  test_image = cv2.imread(file)\n",
        "  plt.imshow(test_image)\n",
        "\n",
        "  img_resized = cv2.resize(test_image, (28, 28))\n",
        "  img_resized = cv2.bitwise_not(img_resized)\n",
        "  plt.imshow(img_resized, cmap='gray')\n",
        "  return img_resized"
      ],
      "metadata": {
        "id": "_QYFYlCLb87F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_image(\"./img_8.png\")"
      ],
      "metadata": {
        "id": "UKRlxBPecZS-",
        "outputId": "e1df6819-870b-4396-8844-6a0afa1d861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Image data of dtype object cannot be converted to float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-806214625beb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./img_8.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-8de61de836cc>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mimg_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0minterpolation_stage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         resample=None, url=None, data=None, **kwargs):\n\u001b[0;32m-> 2695\u001b[0;31m     __ret = gca().imshow(\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5663\u001b[0m                               **kwargs)\n\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    699\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    700\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 701\u001b[0;31m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[1;32m    702\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}