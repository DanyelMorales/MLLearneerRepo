{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0hos6abMVdVZlzm9L2Ehc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanyelMorales/MLLearneerRepo/blob/main/caves_LinearRegressionWithAnimation_bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "blepHTTmuPmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "0a50dec0-8b26-43c4-d356-65a950de9e2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "xLabel = \"Cave Temperature (°C)\"\n",
        "yLabel = \"Depth of Cave (m)\"\n",
        "\n",
        "plt.ion()\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "X,Y =np.loadtxt(\"https://raw.githubusercontent.com/DanyelMorales/MLLearneerRepo/main/dataset/caves.txt\",skiprows=1, unpack=True)\n",
        "plt.xlabel(xLabel, fontsize=30)\n",
        "plt.ylabel(yLabel,fontsize=30)\n",
        "ax.plot(X,Y, \"bo\")\n",
        "\n",
        "def graph(X1,Y1, id):\n",
        "    ax.set_xlim(0, id)\n",
        "    ax.cla()\n",
        "    ax.plot(X1,Y1, \"bo\")\n",
        "    line1, = ax.plot(X1,X1, 'b-')\n",
        "    display(fig)\n",
        "    clear_output(wait = True)\n",
        "    plt.pause(0.5)\n",
        "    return line1\n",
        "\n",
        "\n",
        "def updateLine(X1,Y1,theLine):\n",
        "    plt.xlabel(xLabel, fontsize=30)\n",
        "    plt.ylabel(yLabel,fontsize=30)\n",
        "    theLine.set_ydata(Y1)\n",
        "    theLine.set_xdata(X1)\n",
        "    display(fig)\n",
        "    clear_output(wait = True)\n",
        "    #plt.pause(0.5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MsXmVcG-0kHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showHistory(X,Y,historyW, step=2):\n",
        "  theLine=graph(X,Y,1)\n",
        "  updateLineL = lambda w :  updateLine(X,predict(X,w[0],w[1]),theLine)\n",
        "  for i in range(0,len(historyW),step):\n",
        "    w=historyW[i]\n",
        "    updateLineL(w)\n",
        "  updateLineL(historyW[-1])\n",
        "\n",
        "def predict(X, w,b):\n",
        "  return X * w + b\n",
        "\n",
        "def loss(X,Y,w,b):\n",
        "  error = predict(X,w,b)-Y\n",
        "  squared_error = error ** 2\n",
        "  return np.average(squared_error)\n",
        "\n",
        "def train(iterations, X,Y, lr):\n",
        "  w=b=0\n",
        "  historyW=[]\n",
        "  for i in range(iterations):\n",
        "    historyW.append([w,b])\n",
        "    tmpLoss=loss(X,Y,w,b)\n",
        "    print(f\"\\n iteration={i} bias={b} loss={tmpLoss}\")\n",
        "    if(loss(X,Y,w+lr,b)<tmpLoss):\n",
        "      w+=lr\n",
        "    elif(loss(X,Y,w-lr,b)<tmpLoss):\n",
        "      w-=lr\n",
        "    elif(loss(X,Y,w,b+lr)<tmpLoss):\n",
        "      b+=lr\n",
        "    elif(loss(X,Y,w,b-lr)<tmpLoss):\n",
        "      b-=lr\n",
        "    else:\n",
        "      return [w,b, historyW]\n",
        "  raise Exception(f\"cannot convey after {iterations} iterations\")\n",
        "\n",
        "w,b, history =train(20000, X,Y, 0.01)\n",
        "print(f\"\\nw={w}, b={b}\")\n",
        "print(f\"Prediction: x=8, Y=>{predict(8, w,b)}\")\n"
      ],
      "metadata": {
        "id": "8PAq5GGAQvqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e248243f-6fc0-4ef4-ee69-5e17cc1a94b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " iteration=3390 bias=27.460000000001493 loss=97.70226666665371\n",
            "\n",
            " iteration=3391 bias=27.470000000001495 loss=97.61556666665372\n",
            "\n",
            " iteration=3392 bias=27.480000000001496 loss=97.52906666665375\n",
            "\n",
            " iteration=3393 bias=27.490000000001498 loss=97.44276666665375\n",
            "\n",
            " iteration=3394 bias=27.5000000000015 loss=97.35666666665377\n",
            "\n",
            " iteration=3395 bias=27.5100000000015 loss=97.2707666666538\n",
            "\n",
            " iteration=3396 bias=27.5100000000015 loss=97.27076666665357\n",
            "\n",
            " iteration=3397 bias=27.520000000001502 loss=97.18366666665356\n",
            "\n",
            " iteration=3398 bias=27.530000000001504 loss=97.0967666666536\n",
            "\n",
            " iteration=3399 bias=27.540000000001505 loss=97.0100666666536\n",
            "\n",
            " iteration=3400 bias=27.550000000001507 loss=96.92356666665364\n",
            "\n",
            " iteration=3401 bias=27.56000000000151 loss=96.83726666665365\n",
            "\n",
            " iteration=3402 bias=27.57000000000151 loss=96.75116666665367\n",
            "\n",
            " iteration=3403 bias=27.58000000000151 loss=96.66526666665368\n",
            "\n",
            " iteration=3404 bias=27.590000000001513 loss=96.5795666666537\n",
            "\n",
            " iteration=3405 bias=27.600000000001515 loss=96.49406666665372\n",
            "\n",
            " iteration=3406 bias=27.600000000001515 loss=96.49359999998684\n",
            "\n",
            " iteration=3407 bias=27.610000000001516 loss=96.40689999998686\n",
            "\n",
            " iteration=3408 bias=27.620000000001518 loss=96.32039999998688\n",
            "\n",
            " iteration=3409 bias=27.63000000000152 loss=96.2340999999869\n",
            "\n",
            " iteration=3410 bias=27.64000000000152 loss=96.14799999998691\n",
            "\n",
            " iteration=3411 bias=27.650000000001523 loss=96.06209999998693\n",
            "\n",
            " iteration=3412 bias=27.660000000001524 loss=95.97639999998695\n",
            "\n",
            " iteration=3413 bias=27.670000000001526 loss=95.89089999998697\n",
            "\n",
            " iteration=3414 bias=27.680000000001527 loss=95.805599999987\n",
            "\n",
            " iteration=3415 bias=27.69000000000153 loss=95.720499999987\n",
            "\n",
            " iteration=3416 bias=27.69000000000153 loss=95.71956666665346\n",
            "\n",
            " iteration=3417 bias=27.70000000000153 loss=95.63326666665347\n",
            "\n",
            " iteration=3418 bias=27.710000000001532 loss=95.54716666665348\n",
            "\n",
            " iteration=3419 bias=27.720000000001534 loss=95.4612666666535\n",
            "\n",
            " iteration=3420 bias=27.730000000001535 loss=95.37556666665353\n",
            "\n",
            " iteration=3421 bias=27.740000000001537 loss=95.29006666665354\n",
            "\n",
            " iteration=3422 bias=27.75000000000154 loss=95.20476666665355\n",
            "\n",
            " iteration=3423 bias=27.76000000000154 loss=95.11966666665357\n",
            "\n",
            " iteration=3424 bias=27.77000000000154 loss=95.0347666666536\n",
            "\n",
            " iteration=3425 bias=27.77000000000154 loss=95.03476666665335\n",
            "\n",
            " iteration=3426 bias=27.780000000001543 loss=94.94866666665338\n",
            "\n",
            " iteration=3427 bias=27.790000000001545 loss=94.8627666666534\n",
            "\n",
            " iteration=3428 bias=27.800000000001546 loss=94.77706666665341\n",
            "\n",
            " iteration=3429 bias=27.810000000001548 loss=94.69156666665344\n",
            "\n",
            " iteration=3430 bias=27.82000000000155 loss=94.60626666665344\n",
            "\n",
            " iteration=3431 bias=27.83000000000155 loss=94.52116666665347\n",
            "\n",
            " iteration=3432 bias=27.840000000001552 loss=94.43626666665348\n",
            "\n",
            " iteration=3433 bias=27.850000000001554 loss=94.35156666665353\n",
            "\n",
            " iteration=3434 bias=27.860000000001556 loss=94.26706666665352\n",
            "\n",
            " iteration=3435 bias=27.860000000001556 loss=94.26659999998667\n",
            "\n",
            " iteration=3436 bias=27.870000000001557 loss=94.18089999998669\n",
            "\n",
            " iteration=3437 bias=27.88000000000156 loss=94.0953999999867\n",
            "\n",
            " iteration=3438 bias=27.89000000000156 loss=94.0100999999867\n",
            "\n",
            " iteration=3439 bias=27.90000000000156 loss=93.92499999998672\n",
            "\n",
            " iteration=3440 bias=27.910000000001563 loss=93.84009999998676\n",
            "\n",
            " iteration=3441 bias=27.920000000001565 loss=93.75539999998678\n",
            "\n",
            " iteration=3442 bias=27.930000000001566 loss=93.67089999998679\n",
            "\n",
            " iteration=3443 bias=27.940000000001568 loss=93.58659999998683\n",
            "\n",
            " iteration=3444 bias=27.95000000000157 loss=93.50249999998682\n",
            "\n",
            " iteration=3445 bias=27.95000000000157 loss=93.50156666665328\n",
            "\n",
            " iteration=3446 bias=27.96000000000157 loss=93.41626666665327\n",
            "\n",
            " iteration=3447 bias=27.970000000001573 loss=93.3311666666533\n",
            "\n",
            " iteration=3448 bias=27.980000000001574 loss=93.24626666665331\n",
            "\n",
            " iteration=3449 bias=27.990000000001576 loss=93.16156666665334\n",
            "\n",
            " iteration=3450 bias=28.000000000001577 loss=93.07706666665335\n",
            "\n",
            " iteration=3451 bias=28.01000000000158 loss=92.99276666665337\n",
            "\n",
            " iteration=3452 bias=28.02000000000158 loss=92.9086666666534\n",
            "\n",
            " iteration=3453 bias=28.030000000001582 loss=92.82476666665342\n",
            "\n",
            " iteration=3454 bias=28.030000000001582 loss=92.82476666665319\n",
            "\n",
            " iteration=3455 bias=28.040000000001584 loss=92.7396666666532\n",
            "\n",
            " iteration=3456 bias=28.050000000001585 loss=92.65476666665323\n",
            "\n",
            " iteration=3457 bias=28.060000000001587 loss=92.57006666665325\n",
            "\n",
            " iteration=3458 bias=28.07000000000159 loss=92.48556666665327\n",
            "\n",
            " iteration=3459 bias=28.08000000000159 loss=92.40126666665329\n",
            "\n",
            " iteration=3460 bias=28.09000000000159 loss=92.31716666665329\n",
            "\n",
            " iteration=3461 bias=28.100000000001593 loss=92.23326666665332\n",
            "\n",
            " iteration=3462 bias=28.110000000001595 loss=92.14956666665334\n",
            "\n",
            " iteration=3463 bias=28.120000000001596 loss=92.06606666665334\n",
            "\n",
            " iteration=3464 bias=28.120000000001596 loss=92.06559999998647\n",
            "\n",
            " iteration=3465 bias=28.130000000001598 loss=91.98089999998649\n",
            "\n",
            " iteration=3466 bias=28.1400000000016 loss=91.8963999999865\n",
            "\n",
            " iteration=3467 bias=28.1500000000016 loss=91.81209999998653\n",
            "\n",
            " iteration=3468 bias=28.160000000001602 loss=91.72799999998654\n",
            "\n",
            " iteration=3469 bias=28.170000000001604 loss=91.64409999998657\n",
            "\n",
            " iteration=3470 bias=28.180000000001606 loss=91.56039999998659\n",
            "\n",
            " iteration=3471 bias=28.190000000001607 loss=91.47689999998659\n",
            "\n",
            " iteration=3472 bias=28.20000000000161 loss=91.39359999998662\n",
            "\n",
            " iteration=3473 bias=28.21000000000161 loss=91.31049999998663\n",
            "\n",
            " iteration=3474 bias=28.21000000000161 loss=91.30956666665308\n",
            "\n",
            " iteration=3475 bias=28.220000000001612 loss=91.2252666666531\n",
            "\n",
            " iteration=3476 bias=28.230000000001613 loss=91.14116666665309\n",
            "\n",
            " iteration=3477 bias=28.240000000001615 loss=91.05726666665312\n",
            "\n",
            " iteration=3478 bias=28.250000000001616 loss=90.97356666665316\n",
            "\n",
            " iteration=3479 bias=28.260000000001618 loss=90.89006666665317\n",
            "\n",
            " iteration=3480 bias=28.27000000000162 loss=90.80676666665319\n",
            "\n",
            " iteration=3481 bias=28.28000000000162 loss=90.72366666665322\n",
            "\n",
            " iteration=3482 bias=28.290000000001623 loss=90.64076666665324\n",
            "\n",
            " iteration=3483 bias=28.290000000001623 loss=90.64076666665301\n",
            "\n",
            " iteration=3484 bias=28.300000000001624 loss=90.55666666665302\n",
            "\n",
            " iteration=3485 bias=28.310000000001626 loss=90.47276666665304\n",
            "\n",
            " iteration=3486 bias=28.320000000001627 loss=90.38906666665305\n",
            "\n",
            " iteration=3487 bias=28.33000000000163 loss=90.30556666665308\n",
            "\n",
            " iteration=3488 bias=28.34000000000163 loss=90.22226666665308\n",
            "\n",
            " iteration=3489 bias=28.350000000001632 loss=90.13916666665311\n",
            "\n",
            " iteration=3490 bias=28.360000000001634 loss=90.05626666665313\n",
            "\n",
            " iteration=3491 bias=28.370000000001635 loss=89.97356666665314\n",
            "\n",
            " iteration=3492 bias=28.380000000001637 loss=89.89106666665317\n",
            "\n",
            " iteration=3493 bias=28.380000000001637 loss=89.89059999998629\n",
            "\n",
            " iteration=3494 bias=28.39000000000164 loss=89.8068999999863\n",
            "\n",
            " iteration=3495 bias=28.40000000000164 loss=89.72339999998633\n",
            "\n",
            " iteration=3496 bias=28.41000000000164 loss=89.64009999998636\n",
            "\n",
            " iteration=3497 bias=28.420000000001643 loss=89.55699999998637\n",
            "\n",
            " iteration=3498 bias=28.430000000001645 loss=89.47409999998638\n",
            "\n",
            " iteration=3499 bias=28.440000000001646 loss=89.3913999999864\n",
            "\n",
            " iteration=3500 bias=28.450000000001648 loss=89.30889999998642\n",
            "\n",
            " iteration=3501 bias=28.46000000000165 loss=89.22659999998643\n",
            "\n",
            " iteration=3502 bias=28.47000000000165 loss=89.14449999998646\n",
            "\n",
            " iteration=3503 bias=28.47000000000165 loss=89.14356666665292\n",
            "\n",
            " iteration=3504 bias=28.480000000001652 loss=89.06026666665292\n",
            "\n",
            " iteration=3505 bias=28.490000000001654 loss=88.97716666665293\n",
            "\n",
            " iteration=3506 bias=28.500000000001656 loss=88.89426666665297\n",
            "\n",
            " iteration=3507 bias=28.510000000001657 loss=88.81156666665298\n",
            "\n",
            " iteration=3508 bias=28.52000000000166 loss=88.729066666653\n",
            "\n",
            " iteration=3509 bias=28.53000000000166 loss=88.64676666665302\n",
            "\n",
            " iteration=3510 bias=28.540000000001662 loss=88.56466666665305\n",
            "\n",
            " iteration=3511 bias=28.550000000001663 loss=88.48276666665306\n",
            "\n",
            " iteration=3512 bias=28.550000000001663 loss=88.48276666665284\n",
            "\n",
            " iteration=3513 bias=28.560000000001665 loss=88.39966666665286\n",
            "\n",
            " iteration=3514 bias=28.570000000001667 loss=88.31676666665288\n",
            "\n",
            " iteration=3515 bias=28.580000000001668 loss=88.2340666666529\n",
            "\n",
            " iteration=3516 bias=28.59000000000167 loss=88.15156666665291\n",
            "\n",
            " iteration=3517 bias=28.60000000000167 loss=88.06926666665294\n",
            "\n",
            " iteration=3518 bias=28.610000000001673 loss=87.98716666665297\n",
            "\n",
            " iteration=3519 bias=28.620000000001674 loss=87.90526666665296\n",
            "\n",
            " iteration=3520 bias=28.630000000001676 loss=87.82356666665301\n",
            "\n",
            " iteration=3521 bias=28.640000000001677 loss=87.74206666665303\n",
            "\n",
            " iteration=3522 bias=28.640000000001677 loss=87.74159999998612\n",
            "\n",
            " iteration=3523 bias=28.65000000000168 loss=87.65889999998615\n",
            "\n",
            " iteration=3524 bias=28.66000000000168 loss=87.57639999998617\n",
            "\n",
            " iteration=3525 bias=28.670000000001682 loss=87.49409999998618\n",
            "\n",
            " iteration=3526 bias=28.680000000001684 loss=87.41199999998621\n",
            "\n",
            " iteration=3527 bias=28.690000000001685 loss=87.33009999998622\n",
            "\n",
            " iteration=3528 bias=28.700000000001687 loss=87.24839999998623\n",
            "\n",
            " iteration=3529 bias=28.71000000000169 loss=87.16689999998626\n",
            "\n",
            " iteration=3530 bias=28.72000000000169 loss=87.08559999998629\n",
            "\n",
            " iteration=3531 bias=28.73000000000169 loss=87.0044999999863\n",
            "\n",
            " iteration=3532 bias=28.73000000000169 loss=87.00356666665273\n",
            "\n",
            " iteration=3533 bias=28.740000000001693 loss=86.92126666665276\n",
            "\n",
            " iteration=3534 bias=28.750000000001695 loss=86.83916666665277\n",
            "\n",
            " iteration=3535 bias=28.760000000001696 loss=86.7572666666528\n",
            "\n",
            " iteration=3536 bias=28.770000000001698 loss=86.67556666665281\n",
            "\n",
            " iteration=3537 bias=28.7800000000017 loss=86.59406666665284\n",
            "\n",
            " iteration=3538 bias=28.7900000000017 loss=86.51276666665285\n",
            "\n",
            " iteration=3539 bias=28.800000000001702 loss=86.43166666665287\n",
            "\n",
            " iteration=3540 bias=28.810000000001704 loss=86.35076666665289\n",
            "\n",
            " iteration=3541 bias=28.810000000001704 loss=86.35076666665266\n",
            "\n",
            " iteration=3542 bias=28.820000000001706 loss=86.26866666665269\n",
            "\n",
            " iteration=3543 bias=28.830000000001707 loss=86.18676666665272\n",
            "\n",
            " iteration=3544 bias=28.84000000000171 loss=86.10506666665275\n",
            "\n",
            " iteration=3545 bias=28.85000000000171 loss=86.02356666665275\n",
            "\n",
            " iteration=3546 bias=28.860000000001712 loss=85.94226666665277\n",
            "\n",
            " iteration=3547 bias=28.870000000001713 loss=85.8611666666528\n",
            "\n",
            " iteration=3548 bias=28.880000000001715 loss=85.78026666665282\n",
            "\n",
            " iteration=3549 bias=28.890000000001717 loss=85.69956666665284\n",
            "\n",
            " iteration=3550 bias=28.900000000001718 loss=85.61906666665287\n",
            "\n",
            " iteration=3551 bias=28.900000000001718 loss=85.61859999998596\n",
            "\n",
            " iteration=3552 bias=28.91000000000172 loss=85.53689999998596\n",
            "\n",
            " iteration=3553 bias=28.92000000000172 loss=85.455399999986\n",
            "\n",
            " iteration=3554 bias=28.930000000001723 loss=85.37409999998602\n",
            "\n",
            " iteration=3555 bias=28.940000000001724 loss=85.29299999998604\n",
            "\n",
            " iteration=3556 bias=28.950000000001726 loss=85.21209999998605\n",
            "\n",
            " iteration=3557 bias=28.960000000001727 loss=85.13139999998607\n",
            "\n",
            " iteration=3558 bias=28.97000000000173 loss=85.0508999999861\n",
            "\n",
            " iteration=3559 bias=28.98000000000173 loss=84.97059999998612\n",
            "\n",
            " iteration=3560 bias=28.990000000001732 loss=84.89049999998615\n",
            "\n",
            " iteration=3561 bias=28.990000000001732 loss=84.88956666665256\n",
            "\n",
            " iteration=3562 bias=29.000000000001734 loss=84.80826666665257\n",
            "\n",
            " iteration=3563 bias=29.010000000001735 loss=84.7271666666526\n",
            "\n",
            " iteration=3564 bias=29.020000000001737 loss=84.64626666665262\n",
            "\n",
            " iteration=3565 bias=29.03000000000174 loss=84.56556666665266\n",
            "\n",
            " iteration=3566 bias=29.04000000000174 loss=84.48506666665266\n",
            "\n",
            " iteration=3567 bias=29.05000000000174 loss=84.40476666665269\n",
            "\n",
            " iteration=3568 bias=29.060000000001743 loss=84.3246666666527\n",
            "\n",
            " iteration=3569 bias=29.070000000001745 loss=84.24476666665272\n",
            "\n",
            " iteration=3570 bias=29.070000000001745 loss=84.24476666665252\n",
            "\n",
            " iteration=3571 bias=29.080000000001746 loss=84.1636666666525\n",
            "\n",
            " iteration=3572 bias=29.090000000001748 loss=84.08276666665255\n",
            "\n",
            " iteration=3573 bias=29.10000000000175 loss=84.00206666665255\n",
            "\n",
            " iteration=3574 bias=29.11000000000175 loss=83.9215666666526\n",
            "\n",
            " iteration=3575 bias=29.120000000001752 loss=83.8412666666526\n",
            "\n",
            " iteration=3576 bias=29.130000000001754 loss=83.76116666665264\n",
            "\n",
            " iteration=3577 bias=29.140000000001756 loss=83.68126666665265\n",
            "\n",
            " iteration=3578 bias=29.150000000001757 loss=83.60156666665269\n",
            "\n",
            " iteration=3579 bias=29.16000000000176 loss=83.52206666665269\n",
            "\n",
            " iteration=3580 bias=29.16000000000176 loss=83.52159999998578\n",
            "\n",
            " iteration=3581 bias=29.17000000000176 loss=83.4408999999858\n",
            "\n",
            " iteration=3582 bias=29.180000000001762 loss=83.36039999998583\n",
            "\n",
            " iteration=3583 bias=29.190000000001763 loss=83.28009999998585\n",
            "\n",
            " iteration=3584 bias=29.200000000001765 loss=83.19999999998588\n",
            "\n",
            " iteration=3585 bias=29.210000000001767 loss=83.1200999999859\n",
            "\n",
            " iteration=3586 bias=29.220000000001768 loss=83.04039999998592\n",
            "\n",
            " iteration=3587 bias=29.23000000000177 loss=82.96089999998594\n",
            "\n",
            " iteration=3588 bias=29.24000000000177 loss=82.88159999998597\n",
            "\n",
            " iteration=3589 bias=29.250000000001773 loss=82.80249999998598\n",
            "\n",
            " iteration=3590 bias=29.250000000001773 loss=82.80156666665239\n",
            "\n",
            " iteration=3591 bias=29.260000000001774 loss=82.72126666665243\n",
            "\n",
            " iteration=3592 bias=29.270000000001776 loss=82.64116666665244\n",
            "\n",
            " iteration=3593 bias=29.280000000001777 loss=82.56126666665247\n",
            "\n",
            " iteration=3594 bias=29.29000000000178 loss=82.4815666666525\n",
            "\n",
            " iteration=3595 bias=29.30000000000178 loss=82.40206666665252\n",
            "\n",
            " iteration=3596 bias=29.310000000001782 loss=82.32276666665256\n",
            "\n",
            " iteration=3597 bias=29.320000000001784 loss=82.24366666665257\n",
            "\n",
            " iteration=3598 bias=29.330000000001785 loss=82.1647666666526\n",
            "\n",
            " iteration=3599 bias=29.330000000001785 loss=82.16476666665234\n",
            "\n",
            " iteration=3600 bias=29.340000000001787 loss=82.08466666665237\n",
            "\n",
            " iteration=3601 bias=29.35000000000179 loss=82.0047666666524\n",
            "\n",
            " iteration=3602 bias=29.36000000000179 loss=81.92506666665243\n",
            "\n",
            " iteration=3603 bias=29.37000000000179 loss=81.84556666665245\n",
            "\n",
            " iteration=3604 bias=29.380000000001793 loss=81.76626666665247\n",
            "\n",
            " iteration=3605 bias=29.390000000001795 loss=81.68716666665249\n",
            "\n",
            " iteration=3606 bias=29.400000000001796 loss=81.60826666665251\n",
            "\n",
            " iteration=3607 bias=29.410000000001798 loss=81.52956666665254\n",
            "\n",
            " iteration=3608 bias=29.4200000000018 loss=81.45106666665255\n",
            "\n",
            " iteration=3609 bias=29.4200000000018 loss=81.45059999998564\n",
            "\n",
            " iteration=3610 bias=29.4300000000018 loss=81.37089999998567\n",
            "\n",
            " iteration=3611 bias=29.440000000001803 loss=81.29139999998569\n",
            "\n",
            " iteration=3612 bias=29.450000000001804 loss=81.21209999998571\n",
            "\n",
            " iteration=3613 bias=29.460000000001806 loss=81.13299999998573\n",
            "\n",
            " iteration=3614 bias=29.470000000001807 loss=81.05409999998575\n",
            "\n",
            " iteration=3615 bias=29.48000000000181 loss=80.97539999998578\n",
            "\n",
            " iteration=3616 bias=29.49000000000181 loss=80.8968999999858\n",
            "\n",
            " iteration=3617 bias=29.500000000001812 loss=80.81859999998584\n",
            "\n",
            " iteration=3618 bias=29.510000000001813 loss=80.74049999998586\n",
            "\n",
            " iteration=3619 bias=29.510000000001813 loss=80.73956666665228\n",
            "\n",
            " iteration=3620 bias=29.520000000001815 loss=80.6602666666523\n",
            "\n",
            " iteration=3621 bias=29.530000000001817 loss=80.58116666665232\n",
            "\n",
            " iteration=3622 bias=29.540000000001818 loss=80.50226666665235\n",
            "\n",
            " iteration=3623 bias=29.55000000000182 loss=80.42356666665238\n",
            "\n",
            " iteration=3624 bias=29.56000000000182 loss=80.34506666665239\n",
            "\n",
            " iteration=3625 bias=29.570000000001823 loss=80.26676666665243\n",
            "\n",
            " iteration=3626 bias=29.580000000001824 loss=80.18866666665245\n",
            "\n",
            " iteration=3627 bias=29.590000000001826 loss=80.11076666665248\n",
            "\n",
            " iteration=3628 bias=29.590000000001826 loss=80.1107666666522\n",
            "\n",
            " iteration=3629 bias=29.600000000001828 loss=80.03166666665221\n",
            "\n",
            " iteration=3630 bias=29.61000000000183 loss=79.95276666665227\n",
            "\n",
            " iteration=3631 bias=29.62000000000183 loss=79.87406666665228\n",
            "\n",
            " iteration=3632 bias=29.630000000001832 loss=79.7955666666523\n",
            "\n",
            " iteration=3633 bias=29.640000000001834 loss=79.71726666665234\n",
            "\n",
            " iteration=3634 bias=29.650000000001835 loss=79.63916666665234\n",
            "\n",
            " iteration=3635 bias=29.660000000001837 loss=79.56126666665237\n",
            "\n",
            " iteration=3636 bias=29.67000000000184 loss=79.4835666666524\n",
            "\n",
            " iteration=3637 bias=29.68000000000184 loss=79.40606666665242\n",
            "\n",
            " iteration=3638 bias=29.68000000000184 loss=79.4055999999855\n",
            "\n",
            " iteration=3639 bias=29.69000000000184 loss=79.32689999998551\n",
            "\n",
            " iteration=3640 bias=29.700000000001843 loss=79.24839999998555\n",
            "\n",
            " iteration=3641 bias=29.710000000001845 loss=79.17009999998557\n",
            "\n",
            " iteration=3642 bias=29.720000000001846 loss=79.09199999998559\n",
            "\n",
            " iteration=3643 bias=29.730000000001848 loss=79.01409999998562\n",
            "\n",
            " iteration=3644 bias=29.74000000000185 loss=78.93639999998564\n",
            "\n",
            " iteration=3645 bias=29.75000000000185 loss=78.85889999998567\n",
            "\n",
            " iteration=3646 bias=29.760000000001853 loss=78.78159999998569\n",
            "\n",
            " iteration=3647 bias=29.770000000001854 loss=78.70449999998571\n",
            "\n",
            " iteration=3648 bias=29.770000000001854 loss=78.70356666665212\n",
            "\n",
            " iteration=3649 bias=29.780000000001856 loss=78.62526666665214\n",
            "\n",
            " iteration=3650 bias=29.790000000001857 loss=78.54716666665217\n",
            "\n",
            " iteration=3651 bias=29.80000000000186 loss=78.46926666665222\n",
            "\n",
            " iteration=3652 bias=29.81000000000186 loss=78.39156666665224\n",
            "\n",
            " iteration=3653 bias=29.820000000001862 loss=78.31406666665225\n",
            "\n",
            " iteration=3654 bias=29.830000000001863 loss=78.23676666665227\n",
            "\n",
            " iteration=3655 bias=29.840000000001865 loss=78.1596666666523\n",
            "\n",
            " iteration=3656 bias=29.850000000001867 loss=78.08276666665233\n",
            "\n",
            " iteration=3657 bias=29.850000000001867 loss=78.08276666665206\n",
            "\n",
            " iteration=3658 bias=29.860000000001868 loss=78.00466666665208\n",
            "\n",
            " iteration=3659 bias=29.87000000000187 loss=77.92676666665211\n",
            "\n",
            " iteration=3660 bias=29.88000000000187 loss=77.84906666665215\n",
            "\n",
            " iteration=3661 bias=29.890000000001873 loss=77.77156666665216\n",
            "\n",
            " iteration=3662 bias=29.900000000001874 loss=77.6942666666522\n",
            "\n",
            " iteration=3663 bias=29.910000000001876 loss=77.61716666665221\n",
            "\n",
            " iteration=3664 bias=29.920000000001878 loss=77.54026666665224\n",
            "\n",
            " iteration=3665 bias=29.93000000000188 loss=77.46356666665227\n",
            "\n",
            " iteration=3666 bias=29.94000000000188 loss=77.3870666666523\n",
            "\n",
            " iteration=3667 bias=29.94000000000188 loss=77.38659999998536\n",
            "\n",
            " iteration=3668 bias=29.950000000001882 loss=77.30889999998539\n",
            "\n",
            " iteration=3669 bias=29.960000000001884 loss=77.23139999998541\n",
            "\n",
            " iteration=3670 bias=29.970000000001885 loss=77.15409999998543\n",
            "\n",
            " iteration=3671 bias=29.980000000001887 loss=77.07699999998546\n",
            "\n",
            " iteration=3672 bias=29.99000000000189 loss=77.00009999998548\n",
            "\n",
            " iteration=3673 bias=30.00000000000189 loss=76.9233999999855\n",
            "\n",
            " iteration=3674 bias=30.01000000000189 loss=76.84689999998552\n",
            "\n",
            " iteration=3675 bias=30.020000000001893 loss=76.77059999998556\n",
            "\n",
            " iteration=3676 bias=30.030000000001895 loss=76.69449999998558\n",
            "\n",
            " iteration=3677 bias=30.030000000001895 loss=76.69356666665202\n",
            "\n",
            " iteration=3678 bias=30.040000000001896 loss=76.61626666665204\n",
            "\n",
            " iteration=3679 bias=30.050000000001898 loss=76.53916666665206\n",
            "\n",
            " iteration=3680 bias=30.0600000000019 loss=76.46226666665207\n",
            "\n",
            " iteration=3681 bias=30.0700000000019 loss=76.38556666665211\n",
            "\n",
            " iteration=3682 bias=30.080000000001903 loss=76.30906666665213\n",
            "\n",
            " iteration=3683 bias=30.090000000001904 loss=76.23276666665217\n",
            "\n",
            " iteration=3684 bias=30.100000000001906 loss=76.15666666665219\n",
            "\n",
            " iteration=3685 bias=30.110000000001907 loss=76.08076666665222\n",
            "\n",
            " iteration=3686 bias=30.110000000001907 loss=76.08076666665194\n",
            "\n",
            " iteration=3687 bias=30.12000000000191 loss=76.00366666665197\n",
            "\n",
            " iteration=3688 bias=30.13000000000191 loss=75.926766666652\n",
            "\n",
            " iteration=3689 bias=30.140000000001912 loss=75.85006666665203\n",
            "\n",
            " iteration=3690 bias=30.150000000001913 loss=75.77356666665206\n",
            "\n",
            " iteration=3691 bias=30.160000000001915 loss=75.69726666665207\n",
            "\n",
            " iteration=3692 bias=30.170000000001917 loss=75.6211666666521\n",
            "\n",
            " iteration=3693 bias=30.180000000001918 loss=75.54526666665213\n",
            "\n",
            " iteration=3694 bias=30.19000000000192 loss=75.46956666665214\n",
            "\n",
            " iteration=3695 bias=30.20000000000192 loss=75.39406666665218\n",
            "\n",
            " iteration=3696 bias=30.20000000000192 loss=75.39359999998526\n",
            "\n",
            " iteration=3697 bias=30.210000000001923 loss=75.3168999999853\n",
            "\n",
            " iteration=3698 bias=30.220000000001924 loss=75.2403999999853\n",
            "\n",
            " iteration=3699 bias=30.230000000001926 loss=75.16409999998534\n",
            "\n",
            " iteration=3700 bias=30.240000000001928 loss=75.08799999998536\n",
            "\n",
            " iteration=3701 bias=30.25000000000193 loss=75.01209999998538\n",
            "\n",
            " iteration=3702 bias=30.26000000000193 loss=74.9363999999854\n",
            "\n",
            " iteration=3703 bias=30.270000000001932 loss=74.86089999998545\n",
            "\n",
            " iteration=3704 bias=30.280000000001934 loss=74.78559999998545\n",
            "\n",
            " iteration=3705 bias=30.290000000001935 loss=74.71049999998549\n",
            "\n",
            " iteration=3706 bias=30.290000000001935 loss=74.70956666665188\n",
            "\n",
            " iteration=3707 bias=30.300000000001937 loss=74.6332666666519\n",
            "\n",
            " iteration=3708 bias=30.31000000000194 loss=74.55716666665194\n",
            "\n",
            " iteration=3709 bias=30.32000000000194 loss=74.48126666665196\n",
            "\n",
            " iteration=3710 bias=30.33000000000194 loss=74.40556666665199\n",
            "\n",
            " iteration=3711 bias=30.340000000001943 loss=74.33006666665203\n",
            "\n",
            " iteration=3712 bias=30.350000000001945 loss=74.25476666665205\n",
            "\n",
            " iteration=3713 bias=30.360000000001946 loss=74.17966666665207\n",
            "\n",
            " iteration=3714 bias=30.370000000001948 loss=74.1047666666521\n",
            "\n",
            " iteration=3715 bias=30.370000000001948 loss=74.10476666665181\n",
            "\n",
            " iteration=3716 bias=30.38000000000195 loss=74.02866666665186\n",
            "\n",
            " iteration=3717 bias=30.39000000000195 loss=73.95276666665187\n",
            "\n",
            " iteration=3718 bias=30.400000000001953 loss=73.8770666666519\n",
            "\n",
            " iteration=3719 bias=30.410000000001954 loss=73.80156666665192\n",
            "\n",
            " iteration=3720 bias=30.420000000001956 loss=73.72626666665195\n",
            "\n",
            " iteration=3721 bias=30.430000000001957 loss=73.65116666665197\n",
            "\n",
            " iteration=3722 bias=30.44000000000196 loss=73.57626666665202\n",
            "\n",
            " iteration=3723 bias=30.45000000000196 loss=73.50156666665204\n",
            "\n",
            " iteration=3724 bias=30.460000000001962 loss=73.42706666665207\n",
            "\n",
            " iteration=3725 bias=30.460000000001962 loss=73.42659999998513\n",
            "\n",
            " iteration=3726 bias=30.470000000001964 loss=73.35089999998515\n",
            "\n",
            " iteration=3727 bias=30.480000000001965 loss=73.27539999998518\n",
            "\n",
            " iteration=3728 bias=30.490000000001967 loss=73.2000999999852\n",
            "\n",
            " iteration=3729 bias=30.500000000001968 loss=73.12499999998523\n",
            "\n",
            " iteration=3730 bias=30.51000000000197 loss=73.05009999998526\n",
            "\n",
            " iteration=3731 bias=30.52000000000197 loss=72.97539999998529\n",
            "\n",
            " iteration=3732 bias=30.530000000001973 loss=72.90089999998531\n",
            "\n",
            " iteration=3733 bias=30.540000000001974 loss=72.82659999998535\n",
            "\n",
            " iteration=3734 bias=30.550000000001976 loss=72.75249999998537\n",
            "\n",
            " iteration=3735 bias=30.550000000001976 loss=72.75156666665175\n",
            "\n",
            " iteration=3736 bias=30.560000000001978 loss=72.67626666665178\n",
            "\n",
            " iteration=3737 bias=30.57000000000198 loss=72.60116666665182\n",
            "\n",
            " iteration=3738 bias=30.58000000000198 loss=72.52626666665185\n",
            "\n",
            " iteration=3739 bias=30.590000000001982 loss=72.45156666665189\n",
            "\n",
            " iteration=3740 bias=30.600000000001984 loss=72.3770666666519\n",
            "\n",
            " iteration=3741 bias=30.610000000001985 loss=72.30276666665193\n",
            "\n",
            " iteration=3742 bias=30.620000000001987 loss=72.22866666665196\n",
            "\n",
            " iteration=3743 bias=30.63000000000199 loss=72.154766666652\n",
            "\n",
            " iteration=3744 bias=30.63000000000199 loss=72.1547666666517\n",
            "\n",
            " iteration=3745 bias=30.64000000000199 loss=72.07966666665173\n",
            "\n",
            " iteration=3746 bias=30.65000000000199 loss=72.00476666665176\n",
            "\n",
            " iteration=3747 bias=30.660000000001993 loss=71.93006666665178\n",
            "\n",
            " iteration=3748 bias=30.670000000001995 loss=71.85556666665181\n",
            "\n",
            " iteration=3749 bias=30.680000000001996 loss=71.78126666665185\n",
            "\n",
            " iteration=3750 bias=30.690000000001998 loss=71.70716666665187\n",
            "\n",
            " iteration=3751 bias=30.700000000002 loss=71.63326666665189\n",
            "\n",
            " iteration=3752 bias=30.710000000002 loss=71.55956666665192\n",
            "\n",
            " iteration=3753 bias=30.720000000002003 loss=71.48606666665195\n",
            "\n",
            " iteration=3754 bias=30.720000000002003 loss=71.48559999998503\n",
            "\n",
            " iteration=3755 bias=30.730000000002004 loss=71.41089999998506\n",
            "\n",
            " iteration=3756 bias=30.740000000002006 loss=71.33639999998508\n",
            "\n",
            " iteration=3757 bias=30.750000000002007 loss=71.26209999998513\n",
            "\n",
            " iteration=3758 bias=30.76000000000201 loss=71.18799999998514\n",
            "\n",
            " iteration=3759 bias=30.77000000000201 loss=71.11409999998517\n",
            "\n",
            " iteration=3760 bias=30.780000000002012 loss=71.0403999999852\n",
            "\n",
            " iteration=3761 bias=30.790000000002014 loss=70.96689999998523\n",
            "\n",
            " iteration=3762 bias=30.800000000002015 loss=70.89359999998526\n",
            "\n",
            " iteration=3763 bias=30.810000000002017 loss=70.8204999999853\n",
            "\n",
            " iteration=3764 bias=30.810000000002017 loss=70.81956666665165\n",
            "\n",
            " iteration=3765 bias=30.82000000000202 loss=70.74526666665169\n",
            "\n",
            " iteration=3766 bias=30.83000000000202 loss=70.67116666665173\n",
            "\n",
            " iteration=3767 bias=30.84000000000202 loss=70.59726666665175\n",
            "\n",
            " iteration=3768 bias=30.850000000002023 loss=70.52356666665177\n",
            "\n",
            " iteration=3769 bias=30.860000000002024 loss=70.45006666665181\n",
            "\n",
            " iteration=3770 bias=30.870000000002026 loss=70.37676666665185\n",
            "\n",
            " iteration=3771 bias=30.880000000002028 loss=70.30366666665186\n",
            "\n",
            " iteration=3772 bias=30.89000000000203 loss=70.23076666665189\n",
            "\n",
            " iteration=3773 bias=30.89000000000203 loss=70.23076666665162\n",
            "\n",
            " iteration=3774 bias=30.90000000000203 loss=70.15666666665165\n",
            "\n",
            " iteration=3775 bias=30.910000000002032 loss=70.08276666665166\n",
            "\n",
            " iteration=3776 bias=30.920000000002034 loss=70.0090666666517\n",
            "\n",
            " iteration=3777 bias=30.930000000002035 loss=69.93556666665172\n",
            "\n",
            " iteration=3778 bias=30.940000000002037 loss=69.86226666665176\n",
            "\n",
            " iteration=3779 bias=30.95000000000204 loss=69.78916666665178\n",
            "\n",
            " iteration=3780 bias=30.96000000000204 loss=69.71626666665183\n",
            "\n",
            " iteration=3781 bias=30.97000000000204 loss=69.64356666665185\n",
            "\n",
            " iteration=3782 bias=30.980000000002043 loss=69.57106666665189\n",
            "\n",
            " iteration=3783 bias=30.980000000002043 loss=69.5705999999849\n",
            "\n",
            " iteration=3784 bias=30.990000000002045 loss=69.49689999998495\n",
            "\n",
            " iteration=3785 bias=31.000000000002046 loss=69.42339999998498\n",
            "\n",
            " iteration=3786 bias=31.010000000002048 loss=69.350099999985\n",
            "\n",
            " iteration=3787 bias=31.02000000000205 loss=69.27699999998504\n",
            "\n",
            " iteration=3788 bias=31.03000000000205 loss=69.20409999998506\n",
            "\n",
            " iteration=3789 bias=31.040000000002053 loss=69.1313999999851\n",
            "\n",
            " iteration=3790 bias=31.050000000002054 loss=69.05889999998512\n",
            "\n",
            " iteration=3791 bias=31.060000000002056 loss=68.98659999998516\n",
            "\n",
            " iteration=3792 bias=31.070000000002057 loss=68.91449999998518\n",
            "\n",
            " iteration=3793 bias=31.070000000002057 loss=68.91356666665156\n",
            "\n",
            " iteration=3794 bias=31.08000000000206 loss=68.8402666666516\n",
            "\n",
            " iteration=3795 bias=31.09000000000206 loss=68.76716666665162\n",
            "\n",
            " iteration=3796 bias=31.100000000002062 loss=68.69426666665166\n",
            "\n",
            " iteration=3797 bias=31.110000000002064 loss=68.62156666665167\n",
            "\n",
            " iteration=3798 bias=31.120000000002065 loss=68.54906666665171\n",
            "\n",
            " iteration=3799 bias=31.130000000002067 loss=68.47676666665173\n",
            "\n",
            " iteration=3800 bias=31.14000000000207 loss=68.40466666665178\n",
            "\n",
            " iteration=3801 bias=31.15000000000207 loss=68.3327666666518\n",
            "\n",
            " iteration=3802 bias=31.15000000000207 loss=68.33276666665152\n",
            "\n",
            " iteration=3803 bias=31.16000000000207 loss=68.25966666665154\n",
            "\n",
            " iteration=3804 bias=31.170000000002073 loss=68.18676666665156\n",
            "\n",
            " iteration=3805 bias=31.180000000002075 loss=68.1140666666516\n",
            "\n",
            " iteration=3806 bias=31.190000000002076 loss=68.04156666665163\n",
            "\n",
            " iteration=3807 bias=31.200000000002078 loss=67.96926666665166\n",
            "\n",
            " iteration=3808 bias=31.21000000000208 loss=67.8971666666517\n",
            "\n",
            " iteration=3809 bias=31.22000000000208 loss=67.82526666665173\n",
            "\n",
            " iteration=3810 bias=31.230000000002082 loss=67.75356666665175\n",
            "\n",
            " iteration=3811 bias=31.240000000002084 loss=67.68206666665178\n",
            "\n",
            " iteration=3812 bias=31.240000000002084 loss=67.68159999998483\n",
            "\n",
            " iteration=3813 bias=31.250000000002085 loss=67.60889999998486\n",
            "\n",
            " iteration=3814 bias=31.260000000002087 loss=67.53639999998488\n",
            "\n",
            " iteration=3815 bias=31.27000000000209 loss=67.46409999998492\n",
            "\n",
            " iteration=3816 bias=31.28000000000209 loss=67.39199999998495\n",
            "\n",
            " iteration=3817 bias=31.29000000000209 loss=67.32009999998498\n",
            "\n",
            " iteration=3818 bias=31.300000000002093 loss=67.24839999998501\n",
            "\n",
            " iteration=3819 bias=31.310000000002095 loss=67.17689999998504\n",
            "\n",
            " iteration=3820 bias=31.320000000002096 loss=67.10559999998507\n",
            "\n",
            " iteration=3821 bias=31.330000000002098 loss=67.0344999999851\n",
            "\n",
            " iteration=3822 bias=31.330000000002098 loss=67.03356666665147\n",
            "\n",
            " iteration=3823 bias=31.3400000000021 loss=66.9612666666515\n",
            "\n",
            " iteration=3824 bias=31.3500000000021 loss=66.88916666665153\n",
            "\n",
            " iteration=3825 bias=31.360000000002103 loss=66.81726666665156\n",
            "\n",
            " iteration=3826 bias=31.370000000002104 loss=66.7455666666516\n",
            "\n",
            " iteration=3827 bias=31.380000000002106 loss=66.67406666665163\n",
            "\n",
            " iteration=3828 bias=31.390000000002107 loss=66.60276666665165\n",
            "\n",
            " iteration=3829 bias=31.40000000000211 loss=66.53166666665169\n",
            "\n",
            " iteration=3830 bias=31.41000000000211 loss=66.46076666665171\n",
            "\n",
            " iteration=3831 bias=31.41000000000211 loss=66.46076666665144\n",
            "\n",
            " iteration=3832 bias=31.420000000002112 loss=66.38866666665147\n",
            "\n",
            " iteration=3833 bias=31.430000000002114 loss=66.3167666666515\n",
            "\n",
            " iteration=3834 bias=31.440000000002115 loss=66.24506666665152\n",
            "\n",
            " iteration=3835 bias=31.450000000002117 loss=66.17356666665155\n",
            "\n",
            " iteration=3836 bias=31.46000000000212 loss=66.10226666665159\n",
            "\n",
            " iteration=3837 bias=31.47000000000212 loss=66.03116666665163\n",
            "\n",
            " iteration=3838 bias=31.48000000000212 loss=65.96026666665165\n",
            "\n",
            " iteration=3839 bias=31.490000000002123 loss=65.88956666665169\n",
            "\n",
            " iteration=3840 bias=31.500000000002125 loss=65.81906666665172\n",
            "\n",
            " iteration=3841 bias=31.500000000002125 loss=65.81859999998476\n",
            "\n",
            " iteration=3842 bias=31.510000000002126 loss=65.74689999998478\n",
            "\n",
            " iteration=3843 bias=31.520000000002128 loss=65.6753999999848\n",
            "\n",
            " iteration=3844 bias=31.53000000000213 loss=65.60409999998484\n",
            "\n",
            " iteration=3845 bias=31.54000000000213 loss=65.53299999998488\n",
            "\n",
            " iteration=3846 bias=31.550000000002132 loss=65.4620999999849\n",
            "\n",
            " iteration=3847 bias=31.560000000002134 loss=65.39139999998493\n",
            "\n",
            " iteration=3848 bias=31.570000000002135 loss=65.32089999998497\n",
            "\n",
            " iteration=3849 bias=31.580000000002137 loss=65.250599999985\n",
            "\n",
            " iteration=3850 bias=31.59000000000214 loss=65.18049999998503\n",
            "\n",
            " iteration=3851 bias=31.59000000000214 loss=65.17956666665141\n",
            "\n",
            " iteration=3852 bias=31.60000000000214 loss=65.10826666665143\n",
            "\n",
            " iteration=3853 bias=31.61000000000214 loss=65.03716666665147\n",
            "\n",
            " iteration=3854 bias=31.620000000002143 loss=64.96626666665149\n",
            "\n",
            " iteration=3855 bias=31.630000000002145 loss=64.89556666665153\n",
            "\n",
            " iteration=3856 bias=31.640000000002146 loss=64.82506666665157\n",
            "\n",
            " iteration=3857 bias=31.650000000002148 loss=64.7547666666516\n",
            "\n",
            " iteration=3858 bias=31.66000000000215 loss=64.68466666665164\n",
            "\n",
            " iteration=3859 bias=31.67000000000215 loss=64.61476666665168\n",
            "\n",
            " iteration=3860 bias=31.67000000000215 loss=64.61476666665135\n",
            "\n",
            " iteration=3861 bias=31.680000000002153 loss=64.54366666665139\n",
            "\n",
            " iteration=3862 bias=31.690000000002154 loss=64.47276666665141\n",
            "\n",
            " iteration=3863 bias=31.700000000002156 loss=64.40206666665144\n",
            "\n",
            " iteration=3864 bias=31.710000000002157 loss=64.33156666665148\n",
            "\n",
            " iteration=3865 bias=31.72000000000216 loss=64.26126666665151\n",
            "\n",
            " iteration=3866 bias=31.73000000000216 loss=64.19116666665154\n",
            "\n",
            " iteration=3867 bias=31.740000000002162 loss=64.12126666665158\n",
            "\n",
            " iteration=3868 bias=31.750000000002164 loss=64.05156666665161\n",
            "\n",
            " iteration=3869 bias=31.760000000002165 loss=63.98206666665163\n",
            "\n",
            " iteration=3870 bias=31.760000000002165 loss=63.98159999998467\n",
            "\n",
            " iteration=3871 bias=31.770000000002167 loss=63.9108999999847\n",
            "\n",
            " iteration=3872 bias=31.78000000000217 loss=63.84039999998473\n",
            "\n",
            " iteration=3873 bias=31.79000000000217 loss=63.77009999998476\n",
            "\n",
            " iteration=3874 bias=31.80000000000217 loss=63.699999999984804\n",
            "\n",
            " iteration=3875 bias=31.810000000002173 loss=63.63009999998482\n",
            "\n",
            " iteration=3876 bias=31.820000000002175 loss=63.56039999998486\n",
            "\n",
            " iteration=3877 bias=31.830000000002176 loss=63.49089999998489\n",
            "\n",
            " iteration=3878 bias=31.840000000002178 loss=63.42159999998493\n",
            "\n",
            " iteration=3879 bias=31.85000000000218 loss=63.35249999998496\n",
            "\n",
            " iteration=3880 bias=31.85000000000218 loss=63.35156666665133\n",
            "\n",
            " iteration=3881 bias=31.86000000000218 loss=63.281266666651355\n",
            "\n",
            " iteration=3882 bias=31.870000000002182 loss=63.21116666665139\n",
            "\n",
            " iteration=3883 bias=31.880000000002184 loss=63.141266666651426\n",
            "\n",
            " iteration=3884 bias=31.890000000002185 loss=63.07156666665145\n",
            "\n",
            " iteration=3885 bias=31.900000000002187 loss=63.00206666665148\n",
            "\n",
            " iteration=3886 bias=31.91000000000219 loss=62.932766666651524\n",
            "\n",
            " iteration=3887 bias=31.92000000000219 loss=62.86366666665155\n",
            "\n",
            " iteration=3888 bias=31.93000000000219 loss=62.79476666665158\n",
            "\n",
            " iteration=3889 bias=31.93000000000219 loss=62.79476666665128\n",
            "\n",
            " iteration=3890 bias=31.940000000002193 loss=62.72466666665131\n",
            "\n",
            " iteration=3891 bias=31.950000000002195 loss=62.65476666665135\n",
            "\n",
            " iteration=3892 bias=31.960000000002196 loss=62.58506666665138\n",
            "\n",
            " iteration=3893 bias=31.970000000002198 loss=62.51556666665141\n",
            "\n",
            " iteration=3894 bias=31.9800000000022 loss=62.44626666665144\n",
            "\n",
            " iteration=3895 bias=31.9900000000022 loss=62.377166666651476\n",
            "\n",
            " iteration=3896 bias=32.0000000000022 loss=62.30826666665151\n",
            "\n",
            " iteration=3897 bias=32.0100000000022 loss=62.23956666665157\n",
            "\n",
            " iteration=3898 bias=32.0200000000022 loss=62.171066666651626\n",
            "\n",
            " iteration=3899 bias=32.0200000000022 loss=62.17059999998465\n",
            "\n",
            " iteration=3900 bias=32.0300000000022 loss=62.100899999984705\n",
            "\n",
            " iteration=3901 bias=32.040000000002195 loss=62.031399999984764\n",
            "\n",
            " iteration=3902 bias=32.05000000000219 loss=61.962099999984815\n",
            "\n",
            " iteration=3903 bias=32.06000000000219 loss=61.89299999998487\n",
            "\n",
            " iteration=3904 bias=32.07000000000219 loss=61.82409999998493\n",
            "\n",
            " iteration=3905 bias=32.08000000000219 loss=61.75539999998498\n",
            "\n",
            " iteration=3906 bias=32.090000000002185 loss=61.68689999998505\n",
            "\n",
            " iteration=3907 bias=32.10000000000218 loss=61.6185999999851\n",
            "\n",
            " iteration=3908 bias=32.11000000000218 loss=61.55049999998516\n",
            "\n",
            " iteration=3909 bias=32.11000000000218 loss=61.549566666651536\n",
            "\n",
            " iteration=3910 bias=32.12000000000218 loss=61.480266666651595\n",
            "\n",
            " iteration=3911 bias=32.13000000000218 loss=61.411166666651646\n",
            "\n",
            " iteration=3912 bias=32.140000000002175 loss=61.34226666665171\n",
            "\n",
            " iteration=3913 bias=32.15000000000217 loss=61.27356666665177\n",
            "\n",
            " iteration=3914 bias=32.16000000000217 loss=61.20506666665182\n",
            "\n",
            " iteration=3915 bias=32.17000000000217 loss=61.13676666665187\n",
            "\n",
            " iteration=3916 bias=32.18000000000217 loss=61.06866666665193\n",
            "\n",
            " iteration=3917 bias=32.190000000002165 loss=61.00076666665199\n",
            "\n",
            " iteration=3918 bias=32.190000000002165 loss=61.000766666651685\n",
            "\n",
            " iteration=3919 bias=32.20000000000216 loss=60.93166666665174\n",
            "\n",
            " iteration=3920 bias=32.21000000000216 loss=60.862766666651794\n",
            "\n",
            " iteration=3921 bias=32.22000000000216 loss=60.79406666665185\n",
            "\n",
            " iteration=3922 bias=32.23000000000216 loss=60.72556666665192\n",
            "\n",
            " iteration=3923 bias=32.240000000002155 loss=60.65726666665197\n",
            "\n",
            " iteration=3924 bias=32.25000000000215 loss=60.58916666665203\n",
            "\n",
            " iteration=3925 bias=32.26000000000215 loss=60.52126666665208\n",
            "\n",
            " iteration=3926 bias=32.27000000000215 loss=60.45356666665214\n",
            "\n",
            " iteration=3927 bias=32.28000000000215 loss=60.3860666666522\n",
            "\n",
            " iteration=3928 bias=32.28000000000215 loss=60.38559999998523\n",
            "\n",
            " iteration=3929 bias=32.290000000002145 loss=60.31689999998529\n",
            "\n",
            " iteration=3930 bias=32.30000000000214 loss=60.24839999998536\n",
            "\n",
            " iteration=3931 bias=32.31000000000214 loss=60.18009999998541\n",
            "\n",
            " iteration=3932 bias=32.32000000000214 loss=60.111999999985464\n",
            "\n",
            " iteration=3933 bias=32.33000000000214 loss=60.04409999998552\n",
            "\n",
            " iteration=3934 bias=32.340000000002135 loss=59.976399999985574\n",
            "\n",
            " iteration=3935 bias=32.35000000000213 loss=59.908899999985636\n",
            "\n",
            " iteration=3936 bias=32.36000000000213 loss=59.84159999998568\n",
            "\n",
            " iteration=3937 bias=32.37000000000213 loss=59.77449999998574\n",
            "\n",
            " iteration=3938 bias=32.37000000000213 loss=59.7735666666521\n",
            "\n",
            " iteration=3939 bias=32.38000000000213 loss=59.705266666652165\n",
            "\n",
            " iteration=3940 bias=32.390000000002125 loss=59.63716666665221\n",
            "\n",
            " iteration=3941 bias=32.40000000000212 loss=59.569266666652275\n",
            "\n",
            " iteration=3942 bias=32.41000000000212 loss=59.50156666665233\n",
            "\n",
            " iteration=3943 bias=32.42000000000212 loss=59.43406666665239\n",
            "\n",
            " iteration=3944 bias=32.43000000000212 loss=59.36676666665244\n",
            "\n",
            " iteration=3945 bias=32.440000000002115 loss=59.29966666665249\n",
            "\n",
            " iteration=3946 bias=32.45000000000211 loss=59.232766666652545\n",
            "\n",
            " iteration=3947 bias=32.45000000000211 loss=59.23276666665225\n",
            "\n",
            " iteration=3948 bias=32.46000000000211 loss=59.164666666652316\n",
            "\n",
            " iteration=3949 bias=32.47000000000211 loss=59.096766666652364\n",
            "\n",
            " iteration=3950 bias=32.48000000000211 loss=59.02906666665242\n",
            "\n",
            " iteration=3951 bias=32.490000000002105 loss=58.96156666665248\n",
            "\n",
            " iteration=3952 bias=32.5000000000021 loss=58.89426666665253\n",
            "\n",
            " iteration=3953 bias=32.5100000000021 loss=58.82716666665258\n",
            "\n",
            " iteration=3954 bias=32.5200000000021 loss=58.76026666665265\n",
            "\n",
            " iteration=3955 bias=32.5300000000021 loss=58.69356666665269\n",
            "\n",
            " iteration=3956 bias=32.540000000002095 loss=58.62706666665275\n",
            "\n",
            " iteration=3957 bias=32.540000000002095 loss=58.626599999985785\n",
            "\n",
            " iteration=3958 bias=32.55000000000209 loss=58.55889999998584\n",
            "\n",
            " iteration=3959 bias=32.56000000000209 loss=58.4913999999859\n",
            "\n",
            " iteration=3960 bias=32.57000000000209 loss=58.42409999998595\n",
            "\n",
            " iteration=3961 bias=32.58000000000209 loss=58.35699999998601\n",
            "\n",
            " iteration=3962 bias=32.590000000002085 loss=58.29009999998607\n",
            "\n",
            " iteration=3963 bias=32.60000000000208 loss=58.22339999998612\n",
            "\n",
            " iteration=3964 bias=32.61000000000208 loss=58.15689999998617\n",
            "\n",
            " iteration=3965 bias=32.62000000000208 loss=58.09059999998623\n",
            "\n",
            " iteration=3966 bias=32.63000000000208 loss=58.02449999998629\n",
            "\n",
            " iteration=3967 bias=32.63000000000208 loss=58.02356666665266\n",
            "\n",
            " iteration=3968 bias=32.640000000002075 loss=57.956266666652716\n",
            "\n",
            " iteration=3969 bias=32.65000000000207 loss=57.88916666665276\n",
            "\n",
            " iteration=3970 bias=32.66000000000207 loss=57.82226666665283\n",
            "\n",
            " iteration=3971 bias=32.67000000000207 loss=57.755566666652875\n",
            "\n",
            " iteration=3972 bias=32.68000000000207 loss=57.689066666652934\n",
            "\n",
            " iteration=3973 bias=32.690000000002065 loss=57.622766666652986\n",
            "\n",
            " iteration=3974 bias=32.70000000000206 loss=57.55666666665305\n",
            "\n",
            " iteration=3975 bias=32.71000000000206 loss=57.490766666653094\n",
            "\n",
            " iteration=3976 bias=32.71000000000206 loss=57.49076666665281\n",
            "\n",
            " iteration=3977 bias=32.72000000000206 loss=57.42366666665287\n",
            "\n",
            " iteration=3978 bias=32.73000000000206 loss=57.35676666665292\n",
            "\n",
            " iteration=3979 bias=32.740000000002055 loss=57.29006666665297\n",
            "\n",
            " iteration=3980 bias=32.75000000000205 loss=57.22356666665303\n",
            "\n",
            " iteration=3981 bias=32.76000000000205 loss=57.15726666665309\n",
            "\n",
            " iteration=3982 bias=32.77000000000205 loss=57.091166666653145\n",
            "\n",
            " iteration=3983 bias=32.78000000000205 loss=57.02526666665319\n",
            "\n",
            " iteration=3984 bias=32.790000000002046 loss=56.959566666653245\n",
            "\n",
            " iteration=3985 bias=32.80000000000204 loss=56.894066666653295\n",
            "\n",
            " iteration=3986 bias=32.80000000000204 loss=56.89359999998635\n",
            "\n",
            " iteration=3987 bias=32.81000000000204 loss=56.8268999999864\n",
            "\n",
            " iteration=3988 bias=32.82000000000204 loss=56.760399999986454\n",
            "\n",
            " iteration=3989 bias=32.83000000000204 loss=56.69409999998652\n",
            "\n",
            " iteration=3990 bias=32.840000000002036 loss=56.62799999998657\n",
            "\n",
            " iteration=3991 bias=32.850000000002034 loss=56.56209999998662\n",
            "\n",
            " iteration=3992 bias=32.86000000000203 loss=56.49639999998667\n",
            "\n",
            " iteration=3993 bias=32.87000000000203 loss=56.43089999998673\n",
            "\n",
            " iteration=3994 bias=32.88000000000203 loss=56.365599999986784\n",
            "\n",
            " iteration=3995 bias=32.890000000002026 loss=56.30049999998684\n",
            "\n",
            " iteration=3996 bias=32.890000000002026 loss=56.29956666665322\n",
            "\n",
            " iteration=3997 bias=32.900000000002024 loss=56.233266666653265\n",
            "\n",
            " iteration=3998 bias=32.91000000000202 loss=56.16716666665334\n",
            "\n",
            " iteration=3999 bias=32.92000000000202 loss=56.10126666665337\n",
            "\n",
            " iteration=4000 bias=32.93000000000202 loss=56.03556666665344\n",
            "\n",
            " iteration=4001 bias=32.940000000002016 loss=55.97006666665349\n",
            "\n",
            " iteration=4002 bias=32.950000000002014 loss=55.90476666665355\n",
            "\n",
            " iteration=4003 bias=32.96000000000201 loss=55.83966666665359\n",
            "\n",
            " iteration=4004 bias=32.97000000000201 loss=55.77476666665365\n",
            "\n",
            " iteration=4005 bias=32.97000000000201 loss=55.77476666665336\n",
            "\n",
            " iteration=4006 bias=32.98000000000201 loss=55.708666666653414\n",
            "\n",
            " iteration=4007 bias=32.990000000002006 loss=55.64276666665347\n",
            "\n",
            " iteration=4008 bias=33.000000000002004 loss=55.57706666665353\n",
            "\n",
            " iteration=4009 bias=33.010000000002 loss=55.51156666665358\n",
            "\n",
            " iteration=4010 bias=33.020000000002 loss=55.44626666665363\n",
            "\n",
            " iteration=4011 bias=33.030000000002 loss=55.381166666653684\n",
            "\n",
            " iteration=4012 bias=33.040000000001996 loss=55.31626666665374\n",
            "\n",
            " iteration=4013 bias=33.050000000001994 loss=55.25156666665379\n",
            "\n",
            " iteration=4014 bias=33.06000000000199 loss=55.18706666665384\n",
            "\n",
            " iteration=4015 bias=33.06000000000199 loss=55.18659999998689\n",
            "\n",
            " iteration=4016 bias=33.07000000000199 loss=55.12089999998695\n",
            "\n",
            " iteration=4017 bias=33.08000000000199 loss=55.055399999987\n",
            "\n",
            " iteration=4018 bias=33.090000000001986 loss=54.99009999998705\n",
            "\n",
            " iteration=4019 bias=33.100000000001984 loss=54.92499999998711\n",
            "\n",
            " iteration=4020 bias=33.11000000000198 loss=54.86009999998716\n",
            "\n",
            " iteration=4021 bias=33.12000000000198 loss=54.79539999998721\n",
            "\n",
            " iteration=4022 bias=33.13000000000198 loss=54.730899999987265\n",
            "\n",
            " iteration=4023 bias=33.140000000001976 loss=54.66659999998731\n",
            "\n",
            " iteration=4024 bias=33.150000000001974 loss=54.602499999987366\n",
            "\n",
            " iteration=4025 bias=33.150000000001974 loss=54.601566666653774\n",
            "\n",
            " iteration=4026 bias=33.16000000000197 loss=54.53626666665383\n",
            "\n",
            " iteration=4027 bias=33.17000000000197 loss=54.47116666665388\n",
            "\n",
            " iteration=4028 bias=33.18000000000197 loss=54.40626666665393\n",
            "\n",
            " iteration=4029 bias=33.190000000001966 loss=54.34156666665398\n",
            "\n",
            " iteration=4030 bias=33.200000000001964 loss=54.27706666665404\n",
            "\n",
            " iteration=4031 bias=33.21000000000196 loss=54.21276666665409\n",
            "\n",
            " iteration=4032 bias=33.22000000000196 loss=54.148666666654144\n",
            "\n",
            " iteration=4033 bias=33.23000000000196 loss=54.08476666665418\n",
            "\n",
            " iteration=4034 bias=33.23000000000196 loss=54.084766666653884\n",
            "\n",
            " iteration=4035 bias=33.240000000001956 loss=54.01966666665394\n",
            "\n",
            " iteration=4036 bias=33.250000000001954 loss=53.954766666653995\n",
            "\n",
            " iteration=4037 bias=33.26000000000195 loss=53.89006666665406\n",
            "\n",
            " iteration=4038 bias=33.27000000000195 loss=53.825566666654105\n",
            "\n",
            " iteration=4039 bias=33.28000000000195 loss=53.761266666654144\n",
            "\n",
            " iteration=4040 bias=33.290000000001946 loss=53.697166666654205\n",
            "\n",
            " iteration=4041 bias=33.300000000001944 loss=53.633266666654244\n",
            "\n",
            " iteration=4042 bias=33.31000000000194 loss=53.5695666666543\n",
            "\n",
            " iteration=4043 bias=33.32000000000194 loss=53.50606666665436\n",
            "\n",
            " iteration=4044 bias=33.32000000000194 loss=53.505599999987446\n",
            "\n",
            " iteration=4045 bias=33.33000000000194 loss=53.440899999987494\n",
            "\n",
            " iteration=4046 bias=33.340000000001936 loss=53.37639999998754\n",
            "\n",
            " iteration=4047 bias=33.350000000001934 loss=53.312099999987595\n",
            "\n",
            " iteration=4048 bias=33.36000000000193 loss=53.247999999987655\n",
            "\n",
            " iteration=4049 bias=33.37000000000193 loss=53.1840999999877\n",
            "\n",
            " iteration=4050 bias=33.38000000000193 loss=53.12039999998775\n",
            "\n",
            " iteration=4051 bias=33.390000000001926 loss=53.0568999999878\n",
            "\n",
            " iteration=4052 bias=33.400000000001924 loss=52.99359999998785\n",
            "\n",
            " iteration=4053 bias=33.41000000000192 loss=52.93049999998791\n",
            "\n",
            " iteration=4054 bias=33.41000000000192 loss=52.92956666665429\n",
            "\n",
            " iteration=4055 bias=33.42000000000192 loss=52.86526666665434\n",
            "\n",
            " iteration=4056 bias=33.43000000000192 loss=52.80116666665439\n",
            "\n",
            " iteration=4057 bias=33.440000000001916 loss=52.73726666665444\n",
            "\n",
            " iteration=4058 bias=33.450000000001914 loss=52.673566666654494\n",
            "\n",
            " iteration=4059 bias=33.46000000000191 loss=52.61006666665454\n",
            "\n",
            " iteration=4060 bias=33.47000000000191 loss=52.546766666654584\n",
            "\n",
            " iteration=4061 bias=33.48000000000191 loss=52.48366666665464\n",
            "\n",
            " iteration=4062 bias=33.490000000001906 loss=52.42076666665469\n",
            "\n",
            " iteration=4063 bias=33.490000000001906 loss=52.42076666665443\n",
            "\n",
            " iteration=4064 bias=33.500000000001904 loss=52.35666666665448\n",
            "\n",
            " iteration=4065 bias=33.5100000000019 loss=52.29276666665453\n",
            "\n",
            " iteration=4066 bias=33.5200000000019 loss=52.22906666665458\n",
            "\n",
            " iteration=4067 bias=33.5300000000019 loss=52.16556666665463\n",
            "\n",
            " iteration=4068 bias=33.540000000001896 loss=52.10226666665468\n",
            "\n",
            " iteration=4069 bias=33.550000000001894 loss=52.03916666665473\n",
            "\n",
            " iteration=4070 bias=33.56000000000189 loss=51.97626666665477\n",
            "\n",
            " iteration=4071 bias=33.57000000000189 loss=51.91356666665484\n",
            "\n",
            " iteration=4072 bias=33.58000000000189 loss=51.85106666665488\n",
            "\n",
            " iteration=4073 bias=33.58000000000189 loss=51.850599999987935\n",
            "\n",
            " iteration=4074 bias=33.590000000001886 loss=51.78689999998799\n",
            "\n",
            " iteration=4075 bias=33.600000000001884 loss=51.72339999998803\n",
            "\n",
            " iteration=4076 bias=33.61000000000188 loss=51.66009999998809\n",
            "\n",
            " iteration=4077 bias=33.62000000000188 loss=51.596999999988135\n",
            "\n",
            " iteration=4078 bias=33.63000000000188 loss=51.53409999998818\n",
            "\n",
            " iteration=4079 bias=33.640000000001876 loss=51.47139999998824\n",
            "\n",
            " iteration=4080 bias=33.650000000001874 loss=51.408899999988286\n",
            "\n",
            " iteration=4081 bias=33.66000000000187 loss=51.346599999988335\n",
            "\n",
            " iteration=4082 bias=33.67000000000187 loss=51.284499999988384\n",
            "\n",
            " iteration=4083 bias=33.67000000000187 loss=51.28356666665482\n",
            "\n",
            " iteration=4084 bias=33.68000000000187 loss=51.22026666665487\n",
            "\n",
            " iteration=4085 bias=33.69000000000187 loss=51.157166666654916\n",
            "\n",
            " iteration=4086 bias=33.700000000001864 loss=51.09426666665497\n",
            "\n",
            " iteration=4087 bias=33.71000000000186 loss=51.03156666665502\n",
            "\n",
            " iteration=4088 bias=33.72000000000186 loss=50.96906666665507\n",
            "\n",
            " iteration=4089 bias=33.73000000000186 loss=50.90676666665511\n",
            "\n",
            " iteration=4090 bias=33.74000000000186 loss=50.844666666655165\n",
            "\n",
            " iteration=4091 bias=33.750000000001855 loss=50.78276666665522\n",
            "\n",
            " iteration=4092 bias=33.750000000001855 loss=50.782766666654936\n",
            "\n",
            " iteration=4093 bias=33.76000000000185 loss=50.71966666665498\n",
            "\n",
            " iteration=4094 bias=33.77000000000185 loss=50.65676666665504\n",
            "\n",
            " iteration=4095 bias=33.78000000000185 loss=50.594066666655074\n",
            "\n",
            " iteration=4096 bias=33.79000000000185 loss=50.53156666665513\n",
            "\n",
            " iteration=4097 bias=33.800000000001845 loss=50.46926666665518\n",
            "\n",
            " iteration=4098 bias=33.81000000000184 loss=50.40716666665523\n",
            "\n",
            " iteration=4099 bias=33.82000000000184 loss=50.34526666665528\n",
            "\n",
            " iteration=4100 bias=33.83000000000184 loss=50.283566666655325\n",
            "\n",
            " iteration=4101 bias=33.84000000000184 loss=50.22206666665537\n",
            "\n",
            " iteration=4102 bias=33.84000000000184 loss=50.22159999998846\n",
            "\n",
            " iteration=4103 bias=33.850000000001835 loss=50.15889999998851\n",
            "\n",
            " iteration=4104 bias=33.86000000000183 loss=50.09639999998856\n",
            "\n",
            " iteration=4105 bias=33.87000000000183 loss=50.03409999998862\n",
            "\n",
            " iteration=4106 bias=33.88000000000183 loss=49.97199999998867\n",
            "\n",
            " iteration=4107 bias=33.89000000000183 loss=49.91009999998871\n",
            "\n",
            " iteration=4108 bias=33.900000000001825 loss=49.84839999998875\n",
            "\n",
            " iteration=4109 bias=33.91000000000182 loss=49.78689999998881\n",
            "\n",
            " iteration=4110 bias=33.92000000000182 loss=49.725599999988866\n",
            "\n",
            " iteration=4111 bias=33.93000000000182 loss=49.66449999998891\n",
            "\n",
            " iteration=4112 bias=33.93000000000182 loss=49.66356666665533\n",
            "\n",
            " iteration=4113 bias=33.94000000000182 loss=49.601266666655384\n",
            "\n",
            " iteration=4114 bias=33.950000000001815 loss=49.53916666665543\n",
            "\n",
            " iteration=4115 bias=33.96000000000181 loss=49.477266666655474\n",
            "\n",
            " iteration=4116 bias=33.97000000000181 loss=49.41556666665553\n",
            "\n",
            " iteration=4117 bias=33.98000000000181 loss=49.35406666665557\n",
            "\n",
            " iteration=4118 bias=33.99000000000181 loss=49.292766666655616\n",
            "\n",
            " iteration=4119 bias=34.000000000001805 loss=49.23166666665568\n",
            "\n",
            " iteration=4120 bias=34.0100000000018 loss=49.170766666655716\n",
            "\n",
            " iteration=4121 bias=34.0100000000018 loss=49.170766666655446\n",
            "\n",
            " iteration=4122 bias=34.0200000000018 loss=49.108666666655495\n",
            "\n",
            " iteration=4123 bias=34.0300000000018 loss=49.04676666665555\n",
            "\n",
            " iteration=4124 bias=34.0400000000018 loss=48.9850666666556\n",
            "\n",
            " iteration=4125 bias=34.050000000001795 loss=48.92356666665564\n",
            "\n",
            " iteration=4126 bias=34.06000000000179 loss=48.86226666665569\n",
            "\n",
            " iteration=4127 bias=34.07000000000179 loss=48.80116666665574\n",
            "\n",
            " iteration=4128 bias=34.08000000000179 loss=48.74026666665579\n",
            "\n",
            " iteration=4129 bias=34.09000000000179 loss=48.67956666665583\n",
            "\n",
            " iteration=4130 bias=34.100000000001785 loss=48.619066666655876\n",
            "\n",
            " iteration=4131 bias=34.100000000001785 loss=48.61859999998899\n",
            "\n",
            " iteration=4132 bias=34.11000000000178 loss=48.556899999989035\n",
            "\n",
            " iteration=4133 bias=34.12000000000178 loss=48.495399999989075\n",
            "\n",
            " iteration=4134 bias=34.13000000000178 loss=48.43409999998912\n",
            "\n",
            " iteration=4135 bias=34.14000000000178 loss=48.37299999998917\n",
            "\n",
            " iteration=4136 bias=34.150000000001775 loss=48.31209999998922\n",
            "\n",
            " iteration=4137 bias=34.16000000000177 loss=48.25139999998927\n",
            "\n",
            " iteration=4138 bias=34.17000000000177 loss=48.19089999998931\n",
            "\n",
            " iteration=4139 bias=34.18000000000177 loss=48.130599999989364\n",
            "\n",
            " iteration=4140 bias=34.19000000000177 loss=48.07049999998941\n",
            "\n",
            " iteration=4141 bias=34.19000000000177 loss=48.06956666665581\n",
            "\n",
            " iteration=4142 bias=34.200000000001765 loss=48.00826666665585\n",
            "\n",
            " iteration=4143 bias=34.21000000000176 loss=47.9471666666559\n",
            "\n",
            " iteration=4144 bias=34.22000000000176 loss=47.88626666665595\n",
            "\n",
            " iteration=4145 bias=34.23000000000176 loss=47.825566666655995\n",
            "\n",
            " iteration=4146 bias=34.24000000000176 loss=47.76506666665603\n",
            "\n",
            " iteration=4147 bias=34.250000000001755 loss=47.70476666665608\n",
            "\n",
            " iteration=4148 bias=34.26000000000175 loss=47.64466666665613\n",
            "\n",
            " iteration=4149 bias=34.27000000000175 loss=47.58476666665618\n",
            "\n",
            " iteration=4150 bias=34.27000000000175 loss=47.58476666665595\n",
            "\n",
            " iteration=4151 bias=34.28000000000175 loss=47.523666666656\n",
            "\n",
            " iteration=4152 bias=34.29000000000175 loss=47.462766666656044\n",
            "\n",
            " iteration=4153 bias=34.300000000001745 loss=47.402066666656104\n",
            "\n",
            " iteration=4154 bias=34.31000000000174 loss=47.34156666665615\n",
            "\n",
            " iteration=4155 bias=34.32000000000174 loss=47.28126666665619\n",
            "\n",
            " iteration=4156 bias=34.33000000000174 loss=47.22116666665624\n",
            "\n",
            " iteration=4157 bias=34.34000000000174 loss=47.161266666656275\n",
            "\n",
            " iteration=4158 bias=34.350000000001735 loss=47.10156666665633\n",
            "\n",
            " iteration=4159 bias=34.36000000000173 loss=47.042066666656375\n",
            "\n",
            " iteration=4160 bias=34.36000000000173 loss=47.041599999989444\n",
            "\n",
            " iteration=4161 bias=34.37000000000173 loss=46.9808999999895\n",
            "\n",
            " iteration=4162 bias=34.38000000000173 loss=46.92039999998955\n",
            "\n",
            " iteration=4163 bias=34.39000000000173 loss=46.86009999998959\n",
            "\n",
            " iteration=4164 bias=34.400000000001725 loss=46.79999999998964\n",
            "\n",
            " iteration=4165 bias=34.41000000000172 loss=46.740099999989674\n",
            "\n",
            " iteration=4166 bias=34.42000000000172 loss=46.68039999998973\n",
            "\n",
            " iteration=4167 bias=34.43000000000172 loss=46.620899999989774\n",
            "\n",
            " iteration=4168 bias=34.44000000000172 loss=46.561599999989824\n",
            "\n",
            " iteration=4169 bias=34.450000000001715 loss=46.50249999998987\n",
            "\n",
            " iteration=4170 bias=34.450000000001715 loss=46.50156666665631\n",
            "\n",
            " iteration=4171 bias=34.46000000000171 loss=46.441266666656354\n",
            "\n",
            " iteration=4172 bias=34.47000000000171 loss=46.381166666656405\n",
            "\n",
            " iteration=4173 bias=34.48000000000171 loss=46.32126666665645\n",
            "\n",
            " iteration=4174 bias=34.49000000000171 loss=46.261566666656485\n",
            "\n",
            " iteration=4175 bias=34.500000000001705 loss=46.20206666665654\n",
            "\n",
            " iteration=4176 bias=34.5100000000017 loss=46.14276666665658\n",
            "\n",
            " iteration=4177 bias=34.5200000000017 loss=46.083666666656626\n",
            "\n",
            " iteration=4178 bias=34.5300000000017 loss=46.02476666665668\n",
            "\n",
            " iteration=4179 bias=34.5300000000017 loss=46.024766666656454\n",
            "\n",
            " iteration=4180 bias=34.5400000000017 loss=45.96466666665649\n",
            "\n",
            " iteration=4181 bias=34.550000000001695 loss=45.90476666665654\n",
            "\n",
            " iteration=4182 bias=34.56000000000169 loss=45.845066666656585\n",
            "\n",
            " iteration=4183 bias=34.57000000000169 loss=45.78556666665664\n",
            "\n",
            " iteration=4184 bias=34.58000000000169 loss=45.72626666665668\n",
            "\n",
            " iteration=4185 bias=34.59000000000169 loss=45.667166666656726\n",
            "\n",
            " iteration=4186 bias=34.600000000001685 loss=45.60826666665677\n",
            "\n",
            " iteration=4187 bias=34.61000000000168 loss=45.54956666665682\n",
            "\n",
            " iteration=4188 bias=34.62000000000168 loss=45.491066666656856\n",
            "\n",
            " iteration=4189 bias=34.62000000000168 loss=45.49059999998993\n",
            "\n",
            " iteration=4190 bias=34.63000000000168 loss=45.43089999998998\n",
            "\n",
            " iteration=4191 bias=34.64000000000168 loss=45.371399999990025\n",
            "\n",
            " iteration=4192 bias=34.650000000001675 loss=45.312099999990075\n",
            "\n",
            " iteration=4193 bias=34.66000000000167 loss=45.25299999999012\n",
            "\n",
            " iteration=4194 bias=34.67000000000167 loss=45.19409999999016\n",
            "\n",
            " iteration=4195 bias=34.68000000000167 loss=45.135399999990206\n",
            "\n",
            " iteration=4196 bias=34.69000000000167 loss=45.07689999999025\n",
            "\n",
            " iteration=4197 bias=34.700000000001666 loss=45.01859999999029\n",
            "\n",
            " iteration=4198 bias=34.71000000000166 loss=44.96049999999034\n",
            "\n",
            " iteration=4199 bias=34.71000000000166 loss=44.9595666666568\n",
            "\n",
            " iteration=4200 bias=34.72000000000166 loss=44.90026666665684\n",
            "\n",
            " iteration=4201 bias=34.73000000000166 loss=44.841166666656896\n",
            "\n",
            " iteration=4202 bias=34.74000000000166 loss=44.78226666665694\n",
            "\n",
            " iteration=4203 bias=34.750000000001656 loss=44.72356666665698\n",
            "\n",
            " iteration=4204 bias=34.760000000001654 loss=44.665066666657026\n",
            "\n",
            " iteration=4205 bias=34.77000000000165 loss=44.60676666665707\n",
            "\n",
            " iteration=4206 bias=34.78000000000165 loss=44.54866666665711\n",
            "\n",
            " iteration=4207 bias=34.79000000000165 loss=44.49076666665716\n",
            "\n",
            " iteration=4208 bias=34.79000000000165 loss=44.49076666665692\n",
            "\n",
            " iteration=4209 bias=34.800000000001646 loss=44.43166666665695\n",
            "\n",
            " iteration=4210 bias=34.810000000001644 loss=44.37276666665701\n",
            "\n",
            " iteration=4211 bias=34.82000000000164 loss=44.31406666665705\n",
            "\n",
            " iteration=4212 bias=34.83000000000164 loss=44.25556666665708\n",
            "\n",
            " iteration=4213 bias=34.84000000000164 loss=44.19726666665713\n",
            "\n",
            " iteration=4214 bias=34.850000000001636 loss=44.13916666665718\n",
            "\n",
            " iteration=4215 bias=34.860000000001634 loss=44.08126666665722\n",
            "\n",
            " iteration=4216 bias=34.87000000000163 loss=44.02356666665727\n",
            "\n",
            " iteration=4217 bias=34.88000000000163 loss=43.96606666665732\n",
            "\n",
            " iteration=4218 bias=34.88000000000163 loss=43.965599999990424\n",
            "\n",
            " iteration=4219 bias=34.89000000000163 loss=43.90689999999046\n",
            "\n",
            " iteration=4220 bias=34.900000000001626 loss=43.84839999999051\n",
            "\n",
            " iteration=4221 bias=34.910000000001624 loss=43.79009999999056\n",
            "\n",
            " iteration=4222 bias=34.92000000000162 loss=43.73199999999059\n",
            "\n",
            " iteration=4223 bias=34.93000000000162 loss=43.67409999999064\n",
            "\n",
            " iteration=4224 bias=34.94000000000162 loss=43.61639999999068\n",
            "\n",
            " iteration=4225 bias=34.950000000001616 loss=43.55889999999073\n",
            "\n",
            " iteration=4226 bias=34.960000000001614 loss=43.501599999990766\n",
            "\n",
            " iteration=4227 bias=34.97000000000161 loss=43.44449999999082\n",
            "\n",
            " iteration=4228 bias=34.97000000000161 loss=43.44356666665724\n",
            "\n",
            " iteration=4229 bias=34.98000000000161 loss=43.38526666665729\n",
            "\n",
            " iteration=4230 bias=34.99000000000161 loss=43.32716666665733\n",
            "\n",
            " iteration=4231 bias=35.000000000001606 loss=43.269266666657366\n",
            "\n",
            " iteration=4232 bias=35.010000000001604 loss=43.21156666665741\n",
            "\n",
            " iteration=4233 bias=35.0200000000016 loss=43.15406666665746\n",
            "\n",
            " iteration=4234 bias=35.0300000000016 loss=43.09676666665751\n",
            "\n",
            " iteration=4235 bias=35.0400000000016 loss=43.039666666657546\n",
            "\n",
            " iteration=4236 bias=35.050000000001596 loss=42.98276666665759\n",
            "\n",
            " iteration=4237 bias=35.050000000001596 loss=42.98276666665739\n",
            "\n",
            " iteration=4238 bias=35.060000000001594 loss=42.92466666665743\n",
            "\n",
            " iteration=4239 bias=35.07000000000159 loss=42.866766666657476\n",
            "\n",
            " iteration=4240 bias=35.08000000000159 loss=42.809066666657515\n",
            "\n",
            " iteration=4241 bias=35.09000000000159 loss=42.75156666665756\n",
            "\n",
            " iteration=4242 bias=35.100000000001586 loss=42.694266666657605\n",
            "\n",
            " iteration=4243 bias=35.110000000001584 loss=42.63716666665765\n",
            "\n",
            " iteration=4244 bias=35.12000000000158 loss=42.580266666657685\n",
            "\n",
            " iteration=4245 bias=35.13000000000158 loss=42.523566666657736\n",
            "\n",
            " iteration=4246 bias=35.14000000000158 loss=42.46706666665777\n",
            "\n",
            " iteration=4247 bias=35.14000000000158 loss=42.46659999999087\n",
            "\n",
            " iteration=4248 bias=35.150000000001576 loss=42.408899999990915\n",
            "\n",
            " iteration=4249 bias=35.160000000001574 loss=42.35139999999095\n",
            "\n",
            " iteration=4250 bias=35.17000000000157 loss=42.294099999991\n",
            "\n",
            " iteration=4251 bias=35.18000000000157 loss=42.236999999991035\n",
            "\n",
            " iteration=4252 bias=35.19000000000157 loss=42.18009999999108\n",
            "\n",
            " iteration=4253 bias=35.200000000001566 loss=42.123399999991115\n",
            "\n",
            " iteration=4254 bias=35.210000000001564 loss=42.066899999991165\n",
            "\n",
            " iteration=4255 bias=35.22000000000156 loss=42.01059999999121\n",
            "\n",
            " iteration=4256 bias=35.23000000000156 loss=41.95449999999125\n",
            "\n",
            " iteration=4257 bias=35.23000000000156 loss=41.953566666657714\n",
            "\n",
            " iteration=4258 bias=35.24000000000156 loss=41.89626666665776\n",
            "\n",
            " iteration=4259 bias=35.250000000001556 loss=41.839166666657796\n",
            "\n",
            " iteration=4260 bias=35.260000000001554 loss=41.78226666665784\n",
            "\n",
            " iteration=4261 bias=35.27000000000155 loss=41.72556666665788\n",
            "\n",
            " iteration=4262 bias=35.28000000000155 loss=41.669066666657926\n",
            "\n",
            " iteration=4263 bias=35.29000000000155 loss=41.61276666665797\n",
            "\n",
            " iteration=4264 bias=35.300000000001546 loss=41.55666666665801\n",
            "\n",
            " iteration=4265 bias=35.310000000001544 loss=41.50076666665805\n",
            "\n",
            " iteration=4266 bias=35.310000000001544 loss=41.500766666657846\n",
            "\n",
            " iteration=4267 bias=35.32000000000154 loss=41.44366666665789\n",
            "\n",
            " iteration=4268 bias=35.33000000000154 loss=41.38676666665793\n",
            "\n",
            " iteration=4269 bias=35.34000000000154 loss=41.33006666665797\n",
            "\n",
            " iteration=4270 bias=35.350000000001536 loss=41.27356666665801\n",
            "\n",
            " iteration=4271 bias=35.360000000001534 loss=41.217266666658055\n",
            "\n",
            " iteration=4272 bias=35.37000000000153 loss=41.1611666666581\n",
            "\n",
            " iteration=4273 bias=35.38000000000153 loss=41.10526666665814\n",
            "\n",
            " iteration=4274 bias=35.39000000000153 loss=41.04956666665818\n",
            "\n",
            " iteration=4275 bias=35.400000000001526 loss=40.99406666665822\n",
            "\n",
            " iteration=4276 bias=35.400000000001526 loss=40.99359999999132\n",
            "\n",
            " iteration=4277 bias=35.410000000001524 loss=40.93689999999136\n",
            "\n",
            " iteration=4278 bias=35.42000000000152 loss=40.880399999991404\n",
            "\n",
            " iteration=4279 bias=35.43000000000152 loss=40.82409999999144\n",
            "\n",
            " iteration=4280 bias=35.44000000000152 loss=40.76799999999148\n",
            "\n",
            " iteration=4281 bias=35.450000000001516 loss=40.71209999999153\n",
            "\n",
            " iteration=4282 bias=35.460000000001514 loss=40.65639999999157\n",
            "\n",
            " iteration=4283 bias=35.47000000000151 loss=40.60089999999161\n",
            "\n",
            " iteration=4284 bias=35.48000000000151 loss=40.54559999999165\n",
            "\n",
            " iteration=4285 bias=35.49000000000151 loss=40.49049999999169\n",
            "\n",
            " iteration=4286 bias=35.49000000000151 loss=40.48956666665816\n",
            "\n",
            " iteration=4287 bias=35.500000000001506 loss=40.4332666666582\n",
            "\n",
            " iteration=4288 bias=35.510000000001504 loss=40.37716666665825\n",
            "\n",
            " iteration=4289 bias=35.5200000000015 loss=40.32126666665829\n",
            "\n",
            " iteration=4290 bias=35.5300000000015 loss=40.26556666665832\n",
            "\n",
            " iteration=4291 bias=35.5400000000015 loss=40.21006666665837\n",
            "\n",
            " iteration=4292 bias=35.550000000001496 loss=40.15476666665841\n",
            "\n",
            " iteration=4293 bias=35.560000000001494 loss=40.09966666665845\n",
            "\n",
            " iteration=4294 bias=35.57000000000149 loss=40.04476666665849\n",
            "\n",
            " iteration=4295 bias=35.57000000000149 loss=40.04476666665828\n",
            "\n",
            " iteration=4296 bias=35.58000000000149 loss=39.988666666658325\n",
            "\n",
            " iteration=4297 bias=35.59000000000149 loss=39.93276666665836\n",
            "\n",
            " iteration=4298 bias=35.60000000000149 loss=39.8770666666584\n",
            "\n",
            " iteration=4299 bias=35.610000000001484 loss=39.82156666665844\n",
            "\n",
            " iteration=4300 bias=35.62000000000148 loss=39.76626666665848\n",
            "\n",
            " iteration=4301 bias=35.63000000000148 loss=39.71116666665852\n",
            "\n",
            " iteration=4302 bias=35.64000000000148 loss=39.65626666665856\n",
            "\n",
            " iteration=4303 bias=35.65000000000148 loss=39.601566666658606\n",
            "\n",
            " iteration=4304 bias=35.660000000001475 loss=39.547066666658644\n",
            "\n",
            " iteration=4305 bias=35.660000000001475 loss=39.54659999999179\n",
            "\n",
            " iteration=4306 bias=35.67000000000147 loss=39.490899999991825\n",
            "\n",
            " iteration=4307 bias=35.68000000000147 loss=39.435399999991866\n",
            "\n",
            " iteration=4308 bias=35.69000000000147 loss=39.380099999991906\n",
            "\n",
            " iteration=4309 bias=35.70000000000147 loss=39.324999999991945\n",
            "\n",
            " iteration=4310 bias=35.710000000001465 loss=39.27009999999199\n",
            "\n",
            " iteration=4311 bias=35.72000000000146 loss=39.21539999999203\n",
            "\n",
            " iteration=4312 bias=35.73000000000146 loss=39.16089999999207\n",
            "\n",
            " iteration=4313 bias=35.74000000000146 loss=39.106599999992106\n",
            "\n",
            " iteration=4314 bias=35.75000000000146 loss=39.05249999999214\n",
            "\n",
            " iteration=4315 bias=35.75000000000146 loss=39.05156666665859\n",
            "\n",
            " iteration=4316 bias=35.760000000001455 loss=38.99626666665863\n",
            "\n",
            " iteration=4317 bias=35.77000000000145 loss=38.94116666665867\n",
            "\n",
            " iteration=4318 bias=35.78000000000145 loss=38.886266666658706\n",
            "\n",
            " iteration=4319 bias=35.79000000000145 loss=38.831566666658745\n",
            "\n",
            " iteration=4320 bias=35.80000000000145 loss=38.77706666665878\n",
            "\n",
            " iteration=4321 bias=35.810000000001445 loss=38.72276666665883\n",
            "\n",
            " iteration=4322 bias=35.82000000000144 loss=38.668666666658865\n",
            "\n",
            " iteration=4323 bias=35.83000000000144 loss=38.61476666665891\n",
            "\n",
            " iteration=4324 bias=35.83000000000144 loss=38.61476666665871\n",
            "\n",
            " iteration=4325 bias=35.84000000000144 loss=38.55966666665876\n",
            "\n",
            " iteration=4326 bias=35.85000000000144 loss=38.50476666665879\n",
            "\n",
            " iteration=4327 bias=35.860000000001435 loss=38.450066666658834\n",
            "\n",
            " iteration=4328 bias=35.87000000000143 loss=38.39556666665887\n",
            "\n",
            " iteration=4329 bias=35.88000000000143 loss=38.34126666665892\n",
            "\n",
            " iteration=4330 bias=35.89000000000143 loss=38.287166666658955\n",
            "\n",
            " iteration=4331 bias=35.90000000000143 loss=38.233266666658984\n",
            "\n",
            " iteration=4332 bias=35.910000000001425 loss=38.179566666659035\n",
            "\n",
            " iteration=4333 bias=35.92000000000142 loss=38.126066666659064\n",
            "\n",
            " iteration=4334 bias=35.92000000000142 loss=38.12559999999221\n",
            "\n",
            " iteration=4335 bias=35.93000000000142 loss=38.07089999999226\n",
            "\n",
            " iteration=4336 bias=35.94000000000142 loss=38.016399999992295\n",
            "\n",
            " iteration=4337 bias=35.95000000000142 loss=37.962099999992326\n",
            "\n",
            " iteration=4338 bias=35.960000000001415 loss=37.90799999999237\n",
            "\n",
            " iteration=4339 bias=35.97000000000141 loss=37.85409999999241\n",
            "\n",
            " iteration=4340 bias=35.98000000000141 loss=37.80039999999244\n",
            "\n",
            " iteration=4341 bias=35.99000000000141 loss=37.746899999992486\n",
            "\n",
            " iteration=4342 bias=36.00000000000141 loss=37.69359999999253\n",
            "\n",
            " iteration=4343 bias=36.010000000001405 loss=37.640499999992564\n",
            "\n",
            " iteration=4344 bias=36.010000000001405 loss=37.63956666665902\n",
            "\n",
            " iteration=4345 bias=36.0200000000014 loss=37.58526666665906\n",
            "\n",
            " iteration=4346 bias=36.0300000000014 loss=37.5311666666591\n",
            "\n",
            " iteration=4347 bias=36.0400000000014 loss=37.477266666659126\n",
            "\n",
            " iteration=4348 bias=36.0500000000014 loss=37.42356666665918\n",
            "\n",
            " iteration=4349 bias=36.060000000001395 loss=37.370066666659206\n",
            "\n",
            " iteration=4350 bias=36.07000000000139 loss=37.31676666665925\n",
            "\n",
            " iteration=4351 bias=36.08000000000139 loss=37.26366666665928\n",
            "\n",
            " iteration=4352 bias=36.09000000000139 loss=37.21076666665933\n",
            "\n",
            " iteration=4353 bias=36.09000000000139 loss=37.21076666665915\n",
            "\n",
            " iteration=4354 bias=36.10000000000139 loss=37.156666666659184\n",
            "\n",
            " iteration=4355 bias=36.110000000001385 loss=37.10276666665922\n",
            "\n",
            " iteration=4356 bias=36.12000000000138 loss=37.04906666665926\n",
            "\n",
            " iteration=4357 bias=36.13000000000138 loss=36.99556666665929\n",
            "\n",
            " iteration=4358 bias=36.14000000000138 loss=36.94226666665933\n",
            "\n",
            " iteration=4359 bias=36.15000000000138 loss=36.88916666665937\n",
            "\n",
            " iteration=4360 bias=36.160000000001375 loss=36.836266666659405\n",
            "\n",
            " iteration=4361 bias=36.17000000000137 loss=36.783566666659446\n",
            "\n",
            " iteration=4362 bias=36.18000000000137 loss=36.73106666665949\n",
            "\n",
            " iteration=4363 bias=36.18000000000137 loss=36.73059999999261\n",
            "\n",
            " iteration=4364 bias=36.19000000000137 loss=36.676899999992656\n",
            "\n",
            " iteration=4365 bias=36.20000000000137 loss=36.62339999999269\n",
            "\n",
            " iteration=4366 bias=36.210000000001365 loss=36.57009999999273\n",
            "\n",
            " iteration=4367 bias=36.22000000000136 loss=36.51699999999277\n",
            "\n",
            " iteration=4368 bias=36.23000000000136 loss=36.464099999992804\n",
            "\n",
            " iteration=4369 bias=36.24000000000136 loss=36.411399999992845\n",
            "\n",
            " iteration=4370 bias=36.25000000000136 loss=36.35889999999288\n",
            "\n",
            " iteration=4371 bias=36.260000000001355 loss=36.30659999999292\n",
            "\n",
            " iteration=4372 bias=36.27000000000135 loss=36.25449999999295\n",
            "\n",
            " iteration=4373 bias=36.27000000000135 loss=36.25356666665945\n",
            "\n",
            " iteration=4374 bias=36.28000000000135 loss=36.200266666659495\n",
            "\n",
            " iteration=4375 bias=36.29000000000135 loss=36.14716666665953\n",
            "\n",
            " iteration=4376 bias=36.30000000000135 loss=36.094266666659564\n",
            "\n",
            " iteration=4377 bias=36.310000000001345 loss=36.0415666666596\n",
            "\n",
            " iteration=4378 bias=36.32000000000134 loss=35.98906666665963\n",
            "\n",
            " iteration=4379 bias=36.33000000000134 loss=35.93676666665967\n",
            "\n",
            " iteration=4380 bias=36.34000000000134 loss=35.88466666665971\n",
            "\n",
            " iteration=4381 bias=36.35000000000134 loss=35.83276666665975\n",
            "\n",
            " iteration=4382 bias=36.35000000000134 loss=35.83276666665955\n",
            "\n",
            " iteration=4383 bias=36.360000000001335 loss=35.77966666665959\n",
            "\n",
            " iteration=4384 bias=36.37000000000133 loss=35.72676666665962\n",
            "\n",
            " iteration=4385 bias=36.38000000000133 loss=35.67406666665966\n",
            "\n",
            " iteration=4386 bias=36.39000000000133 loss=35.621566666659696\n",
            "\n",
            " iteration=4387 bias=36.40000000000133 loss=35.569266666659736\n",
            "\n",
            " iteration=4388 bias=36.410000000001325 loss=35.51716666665977\n",
            "\n",
            " iteration=4389 bias=36.42000000000132 loss=35.46526666665981\n",
            "\n",
            " iteration=4390 bias=36.43000000000132 loss=35.41356666665985\n",
            "\n",
            " iteration=4391 bias=36.44000000000132 loss=35.36206666665988\n",
            "\n",
            " iteration=4392 bias=36.44000000000132 loss=35.36159999999304\n",
            "\n",
            " iteration=4393 bias=36.45000000000132 loss=35.30889999999308\n",
            "\n",
            " iteration=4394 bias=36.460000000001315 loss=35.256399999993114\n",
            "\n",
            " iteration=4395 bias=36.47000000000131 loss=35.204099999993154\n",
            "\n",
            " iteration=4396 bias=36.48000000000131 loss=35.151999999993194\n",
            "\n",
            " iteration=4397 bias=36.49000000000131 loss=35.100099999993226\n",
            "\n",
            " iteration=4398 bias=36.50000000000131 loss=35.04839999999326\n",
            "\n",
            " iteration=4399 bias=36.510000000001305 loss=34.996899999993296\n",
            "\n",
            " iteration=4400 bias=36.5200000000013 loss=34.945599999993334\n",
            "\n",
            " iteration=4401 bias=36.5300000000013 loss=34.89449999999337\n",
            "\n",
            " iteration=4402 bias=36.5300000000013 loss=34.89356666665984\n",
            "\n",
            " iteration=4403 bias=36.5400000000013 loss=34.84126666665987\n",
            "\n",
            " iteration=4404 bias=36.5500000000013 loss=34.78916666665991\n",
            "\n",
            " iteration=4405 bias=36.560000000001295 loss=34.73726666665994\n",
            "\n",
            " iteration=4406 bias=36.57000000000129 loss=34.68556666665998\n",
            "\n",
            " iteration=4407 bias=36.58000000000129 loss=34.63406666666002\n",
            "\n",
            " iteration=4408 bias=36.59000000000129 loss=34.582766666660056\n",
            "\n",
            " iteration=4409 bias=36.60000000000129 loss=34.531666666660094\n",
            "\n",
            " iteration=4410 bias=36.610000000001286 loss=34.480766666660124\n",
            "\n",
            " iteration=4411 bias=36.610000000001286 loss=34.48076666665995\n",
            "\n",
            " iteration=4412 bias=36.62000000000128 loss=34.42866666665999\n",
            "\n",
            " iteration=4413 bias=36.63000000000128 loss=34.376766666660025\n",
            "\n",
            " iteration=4414 bias=36.64000000000128 loss=34.325066666660064\n",
            "\n",
            " iteration=4415 bias=36.65000000000128 loss=34.273566666660095\n",
            "\n",
            " iteration=4416 bias=36.660000000001276 loss=34.22226666666014\n",
            "\n",
            " iteration=4417 bias=36.670000000001274 loss=34.17116666666017\n",
            "\n",
            " iteration=4418 bias=36.68000000000127 loss=34.12026666666021\n",
            "\n",
            " iteration=4419 bias=36.69000000000127 loss=34.06956666666024\n",
            "\n",
            " iteration=4420 bias=36.70000000000127 loss=34.01906666666028\n",
            "\n",
            " iteration=4421 bias=36.70000000000127 loss=34.01859999999345\n",
            "\n",
            " iteration=4422 bias=36.710000000001266 loss=33.96689999999348\n",
            "\n",
            " iteration=4423 bias=36.720000000001264 loss=33.91539999999352\n",
            "\n",
            " iteration=4424 bias=36.73000000000126 loss=33.86409999999355\n",
            "\n",
            " iteration=4425 bias=36.74000000000126 loss=33.812999999993586\n",
            "\n",
            " iteration=4426 bias=36.75000000000126 loss=33.762099999993616\n",
            "\n",
            " iteration=4427 bias=36.760000000001256 loss=33.71139999999366\n",
            "\n",
            " iteration=4428 bias=36.770000000001254 loss=33.66089999999369\n",
            "\n",
            " iteration=4429 bias=36.78000000000125 loss=33.610599999993724\n",
            "\n",
            " iteration=4430 bias=36.79000000000125 loss=33.56049999999376\n",
            "\n",
            " iteration=4431 bias=36.79000000000125 loss=33.55956666666023\n",
            "\n",
            " iteration=4432 bias=36.80000000000125 loss=33.50826666666027\n",
            "\n",
            " iteration=4433 bias=36.810000000001246 loss=33.4571666666603\n",
            "\n",
            " iteration=4434 bias=36.820000000001244 loss=33.406266666660336\n",
            "\n",
            " iteration=4435 bias=36.83000000000124 loss=33.35556666666037\n",
            "\n",
            " iteration=4436 bias=36.84000000000124 loss=33.3050666666604\n",
            "\n",
            " iteration=4437 bias=36.85000000000124 loss=33.25476666666044\n",
            "\n",
            " iteration=4438 bias=36.860000000001236 loss=33.20466666666047\n",
            "\n",
            " iteration=4439 bias=36.870000000001234 loss=33.154766666660514\n",
            "\n",
            " iteration=4440 bias=36.870000000001234 loss=33.15476666666035\n",
            "\n",
            " iteration=4441 bias=36.88000000000123 loss=33.10366666666039\n",
            "\n",
            " iteration=4442 bias=36.89000000000123 loss=33.052766666660425\n",
            "\n",
            " iteration=4443 bias=36.90000000000123 loss=33.002066666660454\n",
            "\n",
            " iteration=4444 bias=36.910000000001226 loss=32.95156666666049\n",
            "\n",
            " iteration=4445 bias=36.920000000001224 loss=32.901266666660526\n",
            "\n",
            " iteration=4446 bias=36.93000000000122 loss=32.85116666666056\n",
            "\n",
            " iteration=4447 bias=36.94000000000122 loss=32.80126666666059\n",
            "\n",
            " iteration=4448 bias=36.95000000000122 loss=32.75156666666063\n",
            "\n",
            " iteration=4449 bias=36.960000000001216 loss=32.70206666666066\n",
            "\n",
            " iteration=4450 bias=36.960000000001216 loss=32.70159999999381\n",
            "\n",
            " iteration=4451 bias=36.970000000001214 loss=32.65089999999387\n",
            "\n",
            " iteration=4452 bias=36.98000000000121 loss=32.60039999999388\n",
            "\n",
            " iteration=4453 bias=36.99000000000121 loss=32.55009999999393\n",
            "\n",
            " iteration=4454 bias=37.00000000000121 loss=32.49999999999395\n",
            "\n",
            " iteration=4455 bias=37.010000000001206 loss=32.450099999994\n",
            "\n",
            " iteration=4456 bias=37.020000000001204 loss=32.400399999994015\n",
            "\n",
            " iteration=4457 bias=37.0300000000012 loss=32.35089999999406\n",
            "\n",
            " iteration=4458 bias=37.0400000000012 loss=32.30159999999409\n",
            "\n",
            " iteration=4459 bias=37.0500000000012 loss=32.252499999994136\n",
            "\n",
            " iteration=4460 bias=37.0500000000012 loss=32.251566666660636\n",
            "\n",
            " iteration=4461 bias=37.060000000001196 loss=32.20126666666067\n",
            "\n",
            " iteration=4462 bias=37.070000000001194 loss=32.15116666666071\n",
            "\n",
            " iteration=4463 bias=37.08000000000119 loss=32.10126666666074\n",
            "\n",
            " iteration=4464 bias=37.09000000000119 loss=32.05156666666077\n",
            "\n",
            " iteration=4465 bias=37.10000000000119 loss=32.0020666666608\n",
            "\n",
            " iteration=4466 bias=37.110000000001186 loss=31.95276666666084\n",
            "\n",
            " iteration=4467 bias=37.120000000001184 loss=31.90366666666087\n",
            "\n",
            " iteration=4468 bias=37.13000000000118 loss=31.854766666660908\n",
            "\n",
            " iteration=4469 bias=37.13000000000118 loss=31.854766666660726\n",
            "\n",
            " iteration=4470 bias=37.14000000000118 loss=31.80466666666076\n",
            "\n",
            " iteration=4471 bias=37.15000000000118 loss=31.7547666666608\n",
            "\n",
            " iteration=4472 bias=37.160000000001176 loss=31.705066666660827\n",
            "\n",
            " iteration=4473 bias=37.170000000001174 loss=31.655566666660864\n",
            "\n",
            " iteration=4474 bias=37.18000000000117 loss=31.606266666660897\n",
            "\n",
            " iteration=4475 bias=37.19000000000117 loss=31.55716666666093\n",
            "\n",
            " iteration=4476 bias=37.20000000000117 loss=31.508266666660962\n",
            "\n",
            " iteration=4477 bias=37.210000000001166 loss=31.459566666660994\n",
            "\n",
            " iteration=4478 bias=37.220000000001164 loss=31.41106666666103\n",
            "\n",
            " iteration=4479 bias=37.220000000001164 loss=31.410599999994208\n",
            "\n",
            " iteration=4480 bias=37.23000000000116 loss=31.360899999994242\n",
            "\n",
            " iteration=4481 bias=37.24000000000116 loss=31.31139999999428\n",
            "\n",
            " iteration=4482 bias=37.25000000000116 loss=31.26209999999431\n",
            "\n",
            " iteration=4483 bias=37.260000000001156 loss=31.212999999994338\n",
            "\n",
            " iteration=4484 bias=37.270000000001154 loss=31.164099999994374\n",
            "\n",
            " iteration=4485 bias=37.28000000000115 loss=31.115399999994406\n",
            "\n",
            " iteration=4486 bias=37.29000000000115 loss=31.066899999994437\n",
            "\n",
            " iteration=4487 bias=37.30000000000115 loss=31.018599999994468\n",
            "\n",
            " iteration=4488 bias=37.310000000001146 loss=30.9704999999945\n",
            "\n",
            " iteration=4489 bias=37.310000000001146 loss=30.969566666661013\n",
            "\n",
            " iteration=4490 bias=37.320000000001144 loss=30.920266666661025\n",
            "\n",
            " iteration=4491 bias=37.33000000000114 loss=30.871166666661082\n",
            "\n",
            " iteration=4492 bias=37.34000000000114 loss=30.82226666666109\n",
            "\n",
            " iteration=4493 bias=37.35000000000114 loss=30.77356666666115\n",
            "\n",
            " iteration=4494 bias=37.360000000001136 loss=30.725066666661153\n",
            "\n",
            " iteration=4495 bias=37.370000000001134 loss=30.676766666661212\n",
            "\n",
            " iteration=4496 bias=37.38000000000113 loss=30.628666666661218\n",
            "\n",
            " iteration=4497 bias=37.39000000000113 loss=30.580766666661276\n",
            "\n",
            " iteration=4498 bias=37.39000000000113 loss=30.580766666661102\n",
            "\n",
            " iteration=4499 bias=37.40000000000113 loss=30.531666666661135\n",
            "\n",
            " iteration=4500 bias=37.410000000001126 loss=30.482766666661167\n",
            "\n",
            " iteration=4501 bias=37.420000000001124 loss=30.4340666666612\n",
            "\n",
            " iteration=4502 bias=37.43000000000112 loss=30.38556666666123\n",
            "\n",
            " iteration=4503 bias=37.44000000000112 loss=30.337266666661264\n",
            "\n",
            " iteration=4504 bias=37.45000000000112 loss=30.2891666666613\n",
            "\n",
            " iteration=4505 bias=37.460000000001116 loss=30.24126666666133\n",
            "\n",
            " iteration=4506 bias=37.470000000001114 loss=30.193566666661354\n",
            "\n",
            " iteration=4507 bias=37.48000000000111 loss=30.146066666661387\n",
            "\n",
            " iteration=4508 bias=37.48000000000111 loss=30.145599999994573\n",
            "\n",
            " iteration=4509 bias=37.49000000000111 loss=30.096899999994605\n",
            "\n",
            " iteration=4510 bias=37.50000000000111 loss=30.04839999999464\n",
            "\n",
            " iteration=4511 bias=37.51000000000111 loss=30.00009999999467\n",
            "\n",
            " iteration=4512 bias=37.520000000001104 loss=29.9519999999947\n",
            "\n",
            " iteration=4513 bias=37.5300000000011 loss=29.90409999999473\n",
            "\n",
            " iteration=4514 bias=37.5400000000011 loss=29.856399999994764\n",
            "\n",
            " iteration=4515 bias=37.5500000000011 loss=29.808899999994793\n",
            "\n",
            " iteration=4516 bias=37.5600000000011 loss=29.761599999994825\n",
            "\n",
            " iteration=4517 bias=37.570000000001095 loss=29.714499999994857\n",
            "\n",
            " iteration=4518 bias=37.570000000001095 loss=29.71356666666136\n",
            "\n",
            " iteration=4519 bias=37.58000000000109 loss=29.665266666661392\n",
            "\n",
            " iteration=4520 bias=37.59000000000109 loss=29.617166666661422\n",
            "\n",
            " iteration=4521 bias=37.60000000000109 loss=29.569266666661452\n",
            "\n",
            " iteration=4522 bias=37.61000000000109 loss=29.521566666661485\n",
            "\n",
            " iteration=4523 bias=37.620000000001085 loss=29.474066666661514\n",
            "\n",
            " iteration=4524 bias=37.63000000000108 loss=29.42676666666155\n",
            "\n",
            " iteration=4525 bias=37.64000000000108 loss=29.379666666661578\n",
            "\n",
            " iteration=4526 bias=37.65000000000108 loss=29.33276666666161\n",
            "\n",
            " iteration=4527 bias=37.65000000000108 loss=29.332766666661467\n",
            "\n",
            " iteration=4528 bias=37.66000000000108 loss=29.284666666661508\n",
            "\n",
            " iteration=4529 bias=37.670000000001075 loss=29.236766666661527\n",
            "\n",
            " iteration=4530 bias=37.68000000000107 loss=29.189066666661574\n",
            "\n",
            " iteration=4531 bias=37.69000000000107 loss=29.14156666666159\n",
            "\n",
            " iteration=4532 bias=37.70000000000107 loss=29.094266666661635\n",
            "\n",
            " iteration=4533 bias=37.71000000000107 loss=29.04716666666165\n",
            "\n",
            " iteration=4534 bias=37.720000000001065 loss=29.00026666666169\n",
            "\n",
            " iteration=4535 bias=37.73000000000106 loss=28.95356666666171\n",
            "\n",
            " iteration=4536 bias=37.74000000000106 loss=28.907066666661752\n",
            "\n",
            " iteration=4537 bias=37.74000000000106 loss=28.906599999994928\n",
            "\n",
            " iteration=4538 bias=37.75000000000106 loss=28.858899999994957\n",
            "\n",
            " iteration=4539 bias=37.76000000000106 loss=28.81139999999499\n",
            "\n",
            " iteration=4540 bias=37.770000000001055 loss=28.76409999999502\n",
            "\n",
            " iteration=4541 bias=37.78000000000105 loss=28.71699999999505\n",
            "\n",
            " iteration=4542 bias=37.79000000000105 loss=28.670099999995085\n",
            "\n",
            " iteration=4543 bias=37.80000000000105 loss=28.62339999999511\n",
            "\n",
            " iteration=4544 bias=37.81000000000105 loss=28.576899999995145\n",
            "\n",
            " iteration=4545 bias=37.820000000001045 loss=28.53059999999517\n",
            "\n",
            " iteration=4546 bias=37.83000000000104 loss=28.484499999995197\n",
            "\n",
            " iteration=4547 bias=37.83000000000104 loss=28.483566666661734\n",
            "\n",
            " iteration=4548 bias=37.84000000000104 loss=28.436266666661766\n",
            "\n",
            " iteration=4549 bias=37.85000000000104 loss=28.389166666661794\n",
            "\n",
            " iteration=4550 bias=37.86000000000104 loss=28.342266666661818\n",
            "\n",
            " iteration=4551 bias=37.870000000001035 loss=28.295566666661852\n",
            "\n",
            " iteration=4552 bias=37.88000000000103 loss=28.24906666666188\n",
            "\n",
            " iteration=4553 bias=37.89000000000103 loss=28.202766666661915\n",
            "\n",
            " iteration=4554 bias=37.90000000000103 loss=28.156666666661938\n",
            "\n",
            " iteration=4555 bias=37.91000000000103 loss=28.11076666666197\n",
            "\n",
            " iteration=4556 bias=37.91000000000103 loss=28.110766666661814\n",
            "\n",
            " iteration=4557 bias=37.920000000001025 loss=28.06366666666184\n",
            "\n",
            " iteration=4558 bias=37.93000000000102 loss=28.01676666666187\n",
            "\n",
            " iteration=4559 bias=37.94000000000102 loss=27.970066666661904\n",
            "\n",
            " iteration=4560 bias=37.95000000000102 loss=27.92356666666193\n",
            "\n",
            " iteration=4561 bias=37.96000000000102 loss=27.877266666661956\n",
            "\n",
            " iteration=4562 bias=37.970000000001015 loss=27.83116666666199\n",
            "\n",
            " iteration=4563 bias=37.98000000000101 loss=27.78526666666202\n",
            "\n",
            " iteration=4564 bias=37.99000000000101 loss=27.739566666662046\n",
            "\n",
            " iteration=4565 bias=38.00000000000101 loss=27.694066666662078\n",
            "\n",
            " iteration=4566 bias=38.00000000000101 loss=27.693599999995275\n",
            "\n",
            " iteration=4567 bias=38.01000000000101 loss=27.64689999999531\n",
            "\n",
            " iteration=4568 bias=38.020000000001005 loss=27.600399999995336\n",
            "\n",
            " iteration=4569 bias=38.030000000001 loss=27.554099999995362\n",
            "\n",
            " iteration=4570 bias=38.040000000001 loss=27.507999999995395\n",
            "\n",
            " iteration=4571 bias=38.050000000001 loss=27.462099999995427\n",
            "\n",
            " iteration=4572 bias=38.060000000001 loss=27.416399999995452\n",
            "\n",
            " iteration=4573 bias=38.070000000000995 loss=27.370899999995483\n",
            "\n",
            " iteration=4574 bias=38.08000000000099 loss=27.325599999995507\n",
            "\n",
            " iteration=4575 bias=38.09000000000099 loss=27.280499999995538\n",
            "\n",
            " iteration=4576 bias=38.09000000000099 loss=27.279566666662078\n",
            "\n",
            " iteration=4577 bias=38.10000000000099 loss=27.233266666662104\n",
            "\n",
            " iteration=4578 bias=38.11000000000099 loss=27.187166666662137\n",
            "\n",
            " iteration=4579 bias=38.120000000000985 loss=27.141266666662165\n",
            "\n",
            " iteration=4580 bias=38.13000000000098 loss=27.095566666662194\n",
            "\n",
            " iteration=4581 bias=38.14000000000098 loss=27.050066666662218\n",
            "\n",
            " iteration=4582 bias=38.15000000000098 loss=27.00476666666225\n",
            "\n",
            " iteration=4583 bias=38.16000000000098 loss=26.959666666662276\n",
            "\n",
            " iteration=4584 bias=38.170000000000975 loss=26.914766666662306\n",
            "\n",
            " iteration=4585 bias=38.170000000000975 loss=26.914766666662157\n",
            "\n",
            " iteration=4586 bias=38.18000000000097 loss=26.868666666662183\n",
            "\n",
            " iteration=4587 bias=38.19000000000097 loss=26.822766666662215\n",
            "\n",
            " iteration=4588 bias=38.20000000000097 loss=26.77706666666224\n",
            "\n",
            " iteration=4589 bias=38.21000000000097 loss=26.73156666666227\n",
            "\n",
            " iteration=4590 bias=38.220000000000965 loss=26.686266666662295\n",
            "\n",
            " iteration=4591 bias=38.23000000000096 loss=26.641166666662325\n",
            "\n",
            " iteration=4592 bias=38.24000000000096 loss=26.59626666666235\n",
            "\n",
            " iteration=4593 bias=38.25000000000096 loss=26.55156666666238\n",
            "\n",
            " iteration=4594 bias=38.26000000000096 loss=26.50706666666241\n",
            "\n",
            " iteration=4595 bias=38.26000000000096 loss=26.50659999999562\n",
            "\n",
            " iteration=4596 bias=38.270000000000955 loss=26.460899999995647\n",
            "\n",
            " iteration=4597 bias=38.28000000000095 loss=26.415399999995675\n",
            "\n",
            " iteration=4598 bias=38.29000000000095 loss=26.370099999995702\n",
            "\n",
            " iteration=4599 bias=38.30000000000095 loss=26.324999999995725\n",
            "\n",
            " iteration=4600 bias=38.31000000000095 loss=26.28009999999576\n",
            "\n",
            " iteration=4601 bias=38.320000000000945 loss=26.23539999999578\n",
            "\n",
            " iteration=4602 bias=38.33000000000094 loss=26.19089999999581\n",
            "\n",
            " iteration=4603 bias=38.34000000000094 loss=26.14659999999584\n",
            "\n",
            " iteration=4604 bias=38.35000000000094 loss=26.10249999999587\n",
            "\n",
            " iteration=4605 bias=38.35000000000094 loss=26.101566666662407\n",
            "\n",
            " iteration=4606 bias=38.36000000000094 loss=26.056266666662424\n",
            "\n",
            " iteration=4607 bias=38.370000000000935 loss=26.01116666666246\n",
            "\n",
            " iteration=4608 bias=38.38000000000093 loss=25.966266666662477\n",
            "\n",
            " iteration=4609 bias=38.39000000000093 loss=25.921566666662518\n",
            "\n",
            " iteration=4610 bias=38.40000000000093 loss=25.87706666666253\n",
            "\n",
            " iteration=4611 bias=38.41000000000093 loss=25.832766666662575\n",
            "\n",
            " iteration=4612 bias=38.420000000000925 loss=25.78866666666259\n",
            "\n",
            " iteration=4613 bias=38.43000000000092 loss=25.744766666662628\n",
            "\n",
            " iteration=4614 bias=38.43000000000092 loss=25.744766666662503\n",
            "\n",
            " iteration=4615 bias=38.44000000000092 loss=25.699666666662527\n",
            "\n",
            " iteration=4616 bias=38.45000000000092 loss=25.654766666662557\n",
            "\n",
            " iteration=4617 bias=38.46000000000092 loss=25.61006666666258\n",
            "\n",
            " iteration=4618 bias=38.470000000000915 loss=25.56556666666261\n",
            "\n",
            " iteration=4619 bias=38.48000000000091 loss=25.521266666662637\n",
            "\n",
            " iteration=4620 bias=38.49000000000091 loss=25.477166666662665\n",
            "\n",
            " iteration=4621 bias=38.50000000000091 loss=25.43326666666269\n",
            "\n",
            " iteration=4622 bias=38.51000000000091 loss=25.389566666662716\n",
            "\n",
            " iteration=4623 bias=38.520000000000906 loss=25.34606666666274\n",
            "\n",
            " iteration=4624 bias=38.520000000000906 loss=25.34559999999594\n",
            "\n",
            " iteration=4625 bias=38.5300000000009 loss=25.300899999995966\n",
            "\n",
            " iteration=4626 bias=38.5400000000009 loss=25.256399999995995\n",
            "\n",
            " iteration=4627 bias=38.5500000000009 loss=25.212099999996024\n",
            "\n",
            " iteration=4628 bias=38.5600000000009 loss=25.167999999996045\n",
            "\n",
            " iteration=4629 bias=38.570000000000896 loss=25.124099999996073\n",
            "\n",
            " iteration=4630 bias=38.580000000000894 loss=25.080399999996104\n",
            "\n",
            " iteration=4631 bias=38.59000000000089 loss=25.036899999996127\n",
            "\n",
            " iteration=4632 bias=38.60000000000089 loss=24.993599999996153\n",
            "\n",
            " iteration=4633 bias=38.61000000000089 loss=24.95049999999618\n",
            "\n",
            " iteration=4634 bias=38.61000000000089 loss=24.94956666666273\n",
            "\n",
            " iteration=4635 bias=38.620000000000886 loss=24.905266666662758\n",
            "\n",
            " iteration=4636 bias=38.630000000000884 loss=24.861166666662786\n",
            "\n",
            " iteration=4637 bias=38.64000000000088 loss=24.817266666662807\n",
            "\n",
            " iteration=4638 bias=38.65000000000088 loss=24.773566666662834\n",
            "\n",
            " iteration=4639 bias=38.66000000000088 loss=24.73006666666286\n",
            "\n",
            " iteration=4640 bias=38.670000000000876 loss=24.68676666666289\n",
            "\n",
            " iteration=4641 bias=38.680000000000874 loss=24.64366666666292\n",
            "\n",
            " iteration=4642 bias=38.69000000000087 loss=24.60076666666294\n",
            "\n",
            " iteration=4643 bias=38.69000000000087 loss=24.600766666662803\n",
            "\n",
            " iteration=4644 bias=38.70000000000087 loss=24.55666666666285\n",
            "\n",
            " iteration=4645 bias=38.71000000000087 loss=24.512766666662856\n",
            "\n",
            " iteration=4646 bias=38.720000000000866 loss=24.4690666666629\n",
            "\n",
            " iteration=4647 bias=38.730000000000864 loss=24.425566666662906\n",
            "\n",
            " iteration=4648 bias=38.74000000000086 loss=24.382266666662957\n",
            "\n",
            " iteration=4649 bias=38.75000000000086 loss=24.33916666666296\n",
            "\n",
            " iteration=4650 bias=38.76000000000086 loss=24.296266666663\n",
            "\n",
            " iteration=4651 bias=38.770000000000856 loss=24.253566666663016\n",
            "\n",
            " iteration=4652 bias=38.780000000000854 loss=24.211066666663054\n",
            "\n",
            " iteration=4653 bias=38.780000000000854 loss=24.21059999999626\n",
            "\n",
            " iteration=4654 bias=38.79000000000085 loss=24.16689999999628\n",
            "\n",
            " iteration=4655 bias=38.80000000000085 loss=24.12339999999631\n",
            "\n",
            " iteration=4656 bias=38.81000000000085 loss=24.08009999999633\n",
            "\n",
            " iteration=4657 bias=38.820000000000846 loss=24.036999999996358\n",
            "\n",
            " iteration=4658 bias=38.830000000000844 loss=23.994099999996383\n",
            "\n",
            " iteration=4659 bias=38.84000000000084 loss=23.951399999996408\n",
            "\n",
            " iteration=4660 bias=38.85000000000084 loss=23.908899999996436\n",
            "\n",
            " iteration=4661 bias=38.86000000000084 loss=23.866599999996463\n",
            "\n",
            " iteration=4662 bias=38.870000000000836 loss=23.824499999996487\n",
            "\n",
            " iteration=4663 bias=38.870000000000836 loss=23.82356666666304\n",
            "\n",
            " iteration=4664 bias=38.880000000000834 loss=23.780266666663067\n",
            "\n",
            " iteration=4665 bias=38.89000000000083 loss=23.737166666663096\n",
            "\n",
            " iteration=4666 bias=38.90000000000083 loss=23.694266666663115\n",
            "\n",
            " iteration=4667 bias=38.91000000000083 loss=23.651566666663143\n",
            "\n",
            " iteration=4668 bias=38.920000000000826 loss=23.609066666663168\n",
            "\n",
            " iteration=4669 bias=38.930000000000824 loss=23.566766666663195\n",
            "\n",
            " iteration=4670 bias=38.94000000000082 loss=23.52466666666322\n",
            "\n",
            " iteration=4671 bias=38.95000000000082 loss=23.48276666666324\n",
            "\n",
            " iteration=4672 bias=38.95000000000082 loss=23.48276666666312\n",
            "\n",
            " iteration=4673 bias=38.96000000000082 loss=23.439666666663143\n",
            "\n",
            " iteration=4674 bias=38.970000000000816 loss=23.396766666663165\n",
            "\n",
            " iteration=4675 bias=38.980000000000814 loss=23.354066666663197\n",
            "\n",
            " iteration=4676 bias=38.99000000000081 loss=23.311566666663214\n",
            "\n",
            " iteration=4677 bias=39.00000000000081 loss=23.269266666663242\n",
            "\n",
            " iteration=4678 bias=39.01000000000081 loss=23.227166666663265\n",
            "\n",
            " iteration=4679 bias=39.020000000000806 loss=23.185266666663292\n",
            "\n",
            " iteration=4680 bias=39.030000000000804 loss=23.143566666663315\n",
            "\n",
            " iteration=4681 bias=39.0400000000008 loss=23.102066666663337\n",
            "\n",
            " iteration=4682 bias=39.0400000000008 loss=23.101599999996576\n",
            "\n",
            " iteration=4683 bias=39.0500000000008 loss=23.058899999996584\n",
            "\n",
            " iteration=4684 bias=39.0600000000008 loss=23.016399999996622\n",
            "\n",
            " iteration=4685 bias=39.070000000000796 loss=22.97409999999664\n",
            "\n",
            " iteration=4686 bias=39.080000000000794 loss=22.931999999996673\n",
            "\n",
            " iteration=4687 bias=39.09000000000079 loss=22.890099999996682\n",
            "\n",
            " iteration=4688 bias=39.10000000000079 loss=22.84839999999672\n",
            "\n",
            " iteration=4689 bias=39.11000000000079 loss=22.80689999999673\n",
            "\n",
            " iteration=4690 bias=39.120000000000786 loss=22.76559999999677\n",
            "\n",
            " iteration=4691 bias=39.130000000000784 loss=22.724499999996777\n",
            "\n",
            " iteration=4692 bias=39.130000000000784 loss=22.723566666663334\n",
            "\n",
            " iteration=4693 bias=39.14000000000078 loss=22.681266666663365\n",
            "\n",
            " iteration=4694 bias=39.15000000000078 loss=22.639166666663385\n",
            "\n",
            " iteration=4695 bias=39.16000000000078 loss=22.597266666663415\n",
            "\n",
            " iteration=4696 bias=39.170000000000776 loss=22.555566666663438\n",
            "\n",
            " iteration=4697 bias=39.180000000000774 loss=22.514066666663457\n",
            "\n",
            " iteration=4698 bias=39.19000000000077 loss=22.472766666663485\n",
            "\n",
            " iteration=4699 bias=39.20000000000077 loss=22.431666666663507\n",
            "\n",
            " iteration=4700 bias=39.21000000000077 loss=22.390766666663527\n",
            "\n",
            " iteration=4701 bias=39.21000000000077 loss=22.390766666663428\n",
            "\n",
            " iteration=4702 bias=39.220000000000766 loss=22.34866666666346\n",
            "\n",
            " iteration=4703 bias=39.230000000000764 loss=22.306766666663478\n",
            "\n",
            " iteration=4704 bias=39.24000000000076 loss=22.2650666666635\n",
            "\n",
            " iteration=4705 bias=39.25000000000076 loss=22.223566666663526\n",
            "\n",
            " iteration=4706 bias=39.26000000000076 loss=22.182266666663548\n",
            "\n",
            " iteration=4707 bias=39.270000000000756 loss=22.141166666663576\n",
            "\n",
            " iteration=4708 bias=39.280000000000754 loss=22.100266666663597\n",
            "\n",
            " iteration=4709 bias=39.29000000000075 loss=22.059566666663617\n",
            "\n",
            " iteration=4710 bias=39.30000000000075 loss=22.019066666663644\n",
            "\n",
            " iteration=4711 bias=39.30000000000075 loss=22.018599999996855\n",
            "\n",
            " iteration=4712 bias=39.31000000000075 loss=21.976899999996878\n",
            "\n",
            " iteration=4713 bias=39.320000000000746 loss=21.935399999996903\n",
            "\n",
            " iteration=4714 bias=39.330000000000744 loss=21.894099999996925\n",
            "\n",
            " iteration=4715 bias=39.34000000000074 loss=21.85299999999695\n",
            "\n",
            " iteration=4716 bias=39.35000000000074 loss=21.812099999996974\n",
            "\n",
            " iteration=4717 bias=39.36000000000074 loss=21.771399999996998\n",
            "\n",
            " iteration=4718 bias=39.370000000000736 loss=21.730899999997018\n",
            "\n",
            " iteration=4719 bias=39.380000000000734 loss=21.690599999997044\n",
            "\n",
            " iteration=4720 bias=39.39000000000073 loss=21.650499999997063\n",
            "\n",
            " iteration=4721 bias=39.39000000000073 loss=21.649566666663635\n",
            "\n",
            " iteration=4722 bias=39.40000000000073 loss=21.608266666663656\n",
            "\n",
            " iteration=4723 bias=39.41000000000073 loss=21.56716666666368\n",
            "\n",
            " iteration=4724 bias=39.42000000000073 loss=21.5262666666637\n",
            "\n",
            " iteration=4725 bias=39.430000000000724 loss=21.485566666663725\n",
            "\n",
            " iteration=4726 bias=39.44000000000072 loss=21.445066666663745\n",
            "\n",
            " iteration=4727 bias=39.45000000000072 loss=21.40476666666377\n",
            "\n",
            " iteration=4728 bias=39.46000000000072 loss=21.364666666663794\n",
            "\n",
            " iteration=4729 bias=39.47000000000072 loss=21.324766666663816\n",
            "\n",
            " iteration=4730 bias=39.47000000000072 loss=21.324766666663724\n",
            "\n",
            " iteration=4731 bias=39.480000000000715 loss=21.283666666663745\n",
            "\n",
            " iteration=4732 bias=39.49000000000071 loss=21.242766666663766\n",
            "\n",
            " iteration=4733 bias=39.50000000000071 loss=21.20206666666379\n",
            "\n",
            " iteration=4734 bias=39.51000000000071 loss=21.161566666663813\n",
            "\n",
            " iteration=4735 bias=39.52000000000071 loss=21.121266666663832\n",
            "\n",
            " iteration=4736 bias=39.530000000000705 loss=21.081166666663854\n",
            "\n",
            " iteration=4737 bias=39.5400000000007 loss=21.041266666663876\n",
            "\n",
            " iteration=4738 bias=39.5500000000007 loss=21.001566666663898\n",
            "\n",
            " iteration=4739 bias=39.5600000000007 loss=20.96206666666392\n",
            "\n",
            " iteration=4740 bias=39.5600000000007 loss=20.961599999997144\n",
            "\n",
            " iteration=4741 bias=39.5700000000007 loss=20.920899999997165\n",
            "\n",
            " iteration=4742 bias=39.580000000000695 loss=20.880399999997188\n",
            "\n",
            " iteration=4743 bias=39.59000000000069 loss=20.84009999999721\n",
            "\n",
            " iteration=4744 bias=39.60000000000069 loss=20.79999999999723\n",
            "\n",
            " iteration=4745 bias=39.61000000000069 loss=20.76009999999725\n",
            "\n",
            " iteration=4746 bias=39.62000000000069 loss=20.720399999997273\n",
            "\n",
            " iteration=4747 bias=39.630000000000685 loss=20.680899999997294\n",
            "\n",
            " iteration=4748 bias=39.64000000000068 loss=20.641599999997315\n",
            "\n",
            " iteration=4749 bias=39.65000000000068 loss=20.602499999997338\n",
            "\n",
            " iteration=4750 bias=39.65000000000068 loss=20.601566666663917\n",
            "\n",
            " iteration=4751 bias=39.66000000000068 loss=20.56126666666394\n",
            "\n",
            " iteration=4752 bias=39.67000000000068 loss=20.521166666663962\n",
            "\n",
            " iteration=4753 bias=39.680000000000675 loss=20.481266666663984\n",
            "\n",
            " iteration=4754 bias=39.69000000000067 loss=20.441566666664006\n",
            "\n",
            " iteration=4755 bias=39.70000000000067 loss=20.402066666664027\n",
            "\n",
            " iteration=4756 bias=39.71000000000067 loss=20.362766666664047\n",
            "\n",
            " iteration=4757 bias=39.72000000000067 loss=20.323666666664067\n",
            "\n",
            " iteration=4758 bias=39.730000000000665 loss=20.284766666664087\n",
            "\n",
            " iteration=4759 bias=39.730000000000665 loss=20.284766666663998\n",
            "\n",
            " iteration=4760 bias=39.74000000000066 loss=20.244666666664006\n",
            "\n",
            " iteration=4761 bias=39.75000000000066 loss=20.204766666664042\n",
            "\n",
            " iteration=4762 bias=39.76000000000066 loss=20.16506666666405\n",
            "\n",
            " iteration=4763 bias=39.77000000000066 loss=20.125566666664085\n",
            "\n",
            " iteration=4764 bias=39.780000000000655 loss=20.08626666666409\n",
            "\n",
            " iteration=4765 bias=39.79000000000065 loss=20.047166666664126\n",
            "\n",
            " iteration=4766 bias=39.80000000000065 loss=20.00826666666413\n",
            "\n",
            " iteration=4767 bias=39.81000000000065 loss=19.969566666664168\n",
            "\n",
            " iteration=4768 bias=39.82000000000065 loss=19.931066666664176\n",
            "\n",
            " iteration=4769 bias=39.82000000000065 loss=19.93059999999743\n",
            "\n",
            " iteration=4770 bias=39.830000000000645 loss=19.890899999997455\n",
            "\n",
            " iteration=4771 bias=39.84000000000064 loss=19.851399999997472\n",
            "\n",
            " iteration=4772 bias=39.85000000000064 loss=19.812099999997496\n",
            "\n",
            " iteration=4773 bias=39.86000000000064 loss=19.772999999997513\n",
            "\n",
            " iteration=4774 bias=39.87000000000064 loss=19.734099999997536\n",
            "\n",
            " iteration=4775 bias=39.880000000000635 loss=19.69539999999756\n",
            "\n",
            " iteration=4776 bias=39.89000000000063 loss=19.656899999997577\n",
            "\n",
            " iteration=4777 bias=39.90000000000063 loss=19.618599999997596\n",
            "\n",
            " iteration=4778 bias=39.91000000000063 loss=19.580499999997617\n",
            "\n",
            " iteration=4779 bias=39.91000000000063 loss=19.57956666666419\n",
            "\n",
            " iteration=4780 bias=39.92000000000063 loss=19.540266666664206\n",
            "\n",
            " iteration=4781 bias=39.930000000000625 loss=19.50116666666423\n",
            "\n",
            " iteration=4782 bias=39.94000000000062 loss=19.462266666664245\n",
            "\n",
            " iteration=4783 bias=39.95000000000062 loss=19.423566666664268\n",
            "\n",
            " iteration=4784 bias=39.96000000000062 loss=19.385066666664287\n",
            "\n",
            " iteration=4785 bias=39.97000000000062 loss=19.34676666666431\n",
            "\n",
            " iteration=4786 bias=39.980000000000615 loss=19.308666666664326\n",
            "\n",
            " iteration=4787 bias=39.99000000000061 loss=19.270766666664347\n",
            "\n",
            " iteration=4788 bias=39.99000000000061 loss=19.27076666666427\n",
            "\n",
            " iteration=4789 bias=40.00000000000061 loss=19.231666666664292\n",
            "\n",
            " iteration=4790 bias=40.01000000000061 loss=19.19276666666431\n",
            "\n",
            " iteration=4791 bias=40.02000000000061 loss=19.154066666664328\n",
            "\n",
            " iteration=4792 bias=40.030000000000605 loss=19.115566666664346\n",
            "\n",
            " iteration=4793 bias=40.0400000000006 loss=19.077266666664368\n",
            "\n",
            " iteration=4794 bias=40.0500000000006 loss=19.039166666664386\n",
            "\n",
            " iteration=4795 bias=40.0600000000006 loss=19.001266666664407\n",
            "\n",
            " iteration=4796 bias=40.0700000000006 loss=18.963566666664423\n",
            "\n",
            " iteration=4797 bias=40.080000000000595 loss=18.926066666664443\n",
            "\n",
            " iteration=4798 bias=40.080000000000595 loss=18.925599999997683\n",
            "\n",
            " iteration=4799 bias=40.09000000000059 loss=18.88689999999772\n",
            "\n",
            " iteration=4800 bias=40.10000000000059 loss=18.84839999999772\n",
            "\n",
            " iteration=4801 bias=40.11000000000059 loss=18.810099999997757\n",
            "\n",
            " iteration=4802 bias=40.12000000000059 loss=18.77199999999776\n",
            "\n",
            " iteration=4803 bias=40.130000000000585 loss=18.734099999997795\n",
            "\n",
            " iteration=4804 bias=40.14000000000058 loss=18.696399999997798\n",
            "\n",
            " iteration=4805 bias=40.15000000000058 loss=18.658899999997836\n",
            "\n",
            " iteration=4806 bias=40.16000000000058 loss=18.621599999997837\n",
            "\n",
            " iteration=4807 bias=40.17000000000058 loss=18.58449999999787\n",
            "\n",
            " iteration=4808 bias=40.17000000000058 loss=18.58356666666445\n",
            "\n",
            " iteration=4809 bias=40.180000000000575 loss=18.545266666664464\n",
            "\n",
            " iteration=4810 bias=40.19000000000057 loss=18.507166666664485\n",
            "\n",
            " iteration=4811 bias=40.20000000000057 loss=18.469266666664502\n",
            "\n",
            " iteration=4812 bias=40.21000000000057 loss=18.431566666664523\n",
            "\n",
            " iteration=4813 bias=40.22000000000057 loss=18.39406666666454\n",
            "\n",
            " iteration=4814 bias=40.230000000000565 loss=18.35676666666456\n",
            "\n",
            " iteration=4815 bias=40.24000000000056 loss=18.319666666664578\n",
            "\n",
            " iteration=4816 bias=40.25000000000056 loss=18.282766666664596\n",
            "\n",
            " iteration=4817 bias=40.25000000000056 loss=18.282766666664525\n",
            "\n",
            " iteration=4818 bias=40.26000000000056 loss=18.244666666664546\n",
            "\n",
            " iteration=4819 bias=40.27000000000056 loss=18.206766666664564\n",
            "\n",
            " iteration=4820 bias=40.280000000000555 loss=18.16906666666458\n",
            "\n",
            " iteration=4821 bias=40.29000000000055 loss=18.1315666666646\n",
            "\n",
            " iteration=4822 bias=40.30000000000055 loss=18.09426666666462\n",
            "\n",
            " iteration=4823 bias=40.31000000000055 loss=18.05716666666464\n",
            "\n",
            " iteration=4824 bias=40.32000000000055 loss=18.020266666664654\n",
            "\n",
            " iteration=4825 bias=40.330000000000545 loss=17.98356666666467\n",
            "\n",
            " iteration=4826 bias=40.34000000000054 loss=17.947066666664693\n",
            "\n",
            " iteration=4827 bias=40.34000000000054 loss=17.946599999997936\n",
            "\n",
            " iteration=4828 bias=40.35000000000054 loss=17.90889999999796\n",
            "\n",
            " iteration=4829 bias=40.36000000000054 loss=17.871399999997973\n",
            "\n",
            " iteration=4830 bias=40.37000000000054 loss=17.834099999998\n",
            "\n",
            " iteration=4831 bias=40.380000000000535 loss=17.796999999998008\n",
            "\n",
            " iteration=4832 bias=40.39000000000053 loss=17.760099999998033\n",
            "\n",
            " iteration=4833 bias=40.40000000000053 loss=17.723399999998044\n",
            "\n",
            " iteration=4834 bias=40.41000000000053 loss=17.686899999998065\n",
            "\n",
            " iteration=4835 bias=40.42000000000053 loss=17.65059999999808\n",
            "\n",
            " iteration=4836 bias=40.430000000000526 loss=17.614499999998102\n",
            "\n",
            " iteration=4837 bias=40.430000000000526 loss=17.6135666666647\n",
            "\n",
            " iteration=4838 bias=40.44000000000052 loss=17.576266666664726\n",
            "\n",
            " iteration=4839 bias=40.45000000000052 loss=17.53916666666473\n",
            "\n",
            " iteration=4840 bias=40.46000000000052 loss=17.502266666664763\n",
            "\n",
            " iteration=4841 bias=40.47000000000052 loss=17.465566666664767\n",
            "\n",
            " iteration=4842 bias=40.480000000000516 loss=17.4290666666648\n",
            "\n",
            " iteration=4843 bias=40.490000000000514 loss=17.3927666666648\n",
            "\n",
            " iteration=4844 bias=40.50000000000051 loss=17.356666666664832\n",
            "\n",
            " iteration=4845 bias=40.51000000000051 loss=17.320766666664838\n",
            "\n",
            " iteration=4846 bias=40.51000000000051 loss=17.32076666666477\n",
            "\n",
            " iteration=4847 bias=40.52000000000051 loss=17.283666666664786\n",
            "\n",
            " iteration=4848 bias=40.530000000000506 loss=17.246766666664804\n",
            "\n",
            " iteration=4849 bias=40.540000000000504 loss=17.210066666664822\n",
            "\n",
            " iteration=4850 bias=40.5500000000005 loss=17.17356666666484\n",
            "\n",
            " iteration=4851 bias=40.5600000000005 loss=17.137266666664857\n",
            "\n",
            " iteration=4852 bias=40.5700000000005 loss=17.10116666666487\n",
            "\n",
            " iteration=4853 bias=40.580000000000496 loss=17.06526666666489\n",
            "\n",
            " iteration=4854 bias=40.590000000000494 loss=17.029566666664905\n",
            "\n",
            " iteration=4855 bias=40.60000000000049 loss=16.994066666664924\n",
            "\n",
            " iteration=4856 bias=40.60000000000049 loss=16.9935999999982\n",
            "\n",
            " iteration=4857 bias=40.61000000000049 loss=16.95689999999821\n",
            "\n",
            " iteration=4858 bias=40.62000000000049 loss=16.920399999998235\n",
            "\n",
            " iteration=4859 bias=40.630000000000486 loss=16.88409999999824\n",
            "\n",
            " iteration=4860 bias=40.640000000000484 loss=16.84799999999827\n",
            "\n",
            " iteration=4861 bias=40.65000000000048 loss=16.812099999998278\n",
            "\n",
            " iteration=4862 bias=40.66000000000048 loss=16.7763999999983\n",
            "\n",
            " iteration=4863 bias=40.67000000000048 loss=16.74089999999831\n",
            "\n",
            " iteration=4864 bias=40.680000000000476 loss=16.70559999999833\n",
            "\n",
            " iteration=4865 bias=40.690000000000474 loss=16.670499999998345\n",
            "\n",
            " iteration=4866 bias=40.690000000000474 loss=16.669566666664938\n",
            "\n",
            " iteration=4867 bias=40.70000000000047 loss=16.63326666666495\n",
            "\n",
            " iteration=4868 bias=40.71000000000047 loss=16.59716666666497\n",
            "\n",
            " iteration=4869 bias=40.72000000000047 loss=16.561266666664988\n",
            "\n",
            " iteration=4870 bias=40.730000000000466 loss=16.525566666665004\n",
            "\n",
            " iteration=4871 bias=40.740000000000464 loss=16.49006666666502\n",
            "\n",
            " iteration=4872 bias=40.75000000000046 loss=16.454766666665034\n",
            "\n",
            " iteration=4873 bias=40.76000000000046 loss=16.41966666666505\n",
            "\n",
            " iteration=4874 bias=40.77000000000046 loss=16.38476666666507\n",
            "\n",
            " iteration=4875 bias=40.77000000000046 loss=16.384766666665012\n",
            "\n",
            " iteration=4876 bias=40.780000000000456 loss=16.348666666665025\n",
            "\n",
            " iteration=4877 bias=40.790000000000454 loss=16.31276666666504\n",
            "\n",
            " iteration=4878 bias=40.80000000000045 loss=16.27706666666506\n",
            "\n",
            " iteration=4879 bias=40.81000000000045 loss=16.241566666665076\n",
            "\n",
            " iteration=4880 bias=40.82000000000045 loss=16.20626666666509\n",
            "\n",
            " iteration=4881 bias=40.830000000000446 loss=16.171166666665105\n",
            "\n",
            " iteration=4882 bias=40.840000000000444 loss=16.136266666665122\n",
            "\n",
            " iteration=4883 bias=40.85000000000044 loss=16.101566666665136\n",
            "\n",
            " iteration=4884 bias=40.86000000000044 loss=16.067066666665152\n",
            "\n",
            " iteration=4885 bias=40.86000000000044 loss=16.06659999999843\n",
            "\n",
            " iteration=4886 bias=40.87000000000044 loss=16.030899999998447\n",
            "\n",
            " iteration=4887 bias=40.880000000000436 loss=15.995399999998464\n",
            "\n",
            " iteration=4888 bias=40.890000000000434 loss=15.960099999998477\n",
            "\n",
            " iteration=4889 bias=40.90000000000043 loss=15.924999999998493\n",
            "\n",
            " iteration=4890 bias=40.91000000000043 loss=15.89009999999851\n",
            "\n",
            " iteration=4891 bias=40.92000000000043 loss=15.855399999998525\n",
            "\n",
            " iteration=4892 bias=40.930000000000426 loss=15.82089999999854\n",
            "\n",
            " iteration=4893 bias=40.940000000000424 loss=15.786599999998552\n",
            "\n",
            " iteration=4894 bias=40.95000000000042 loss=15.75249999999857\n",
            "\n",
            " iteration=4895 bias=40.95000000000042 loss=15.75156666666517\n",
            "\n",
            " iteration=4896 bias=40.96000000000042 loss=15.71626666666518\n",
            "\n",
            " iteration=4897 bias=40.97000000000042 loss=15.6811666666652\n",
            "\n",
            " iteration=4898 bias=40.980000000000416 loss=15.646266666665207\n",
            "\n",
            " iteration=4899 bias=40.990000000000414 loss=15.611566666665231\n",
            "\n",
            " iteration=4900 bias=41.00000000000041 loss=15.57706666666524\n",
            "\n",
            " iteration=4901 bias=41.01000000000041 loss=15.542766666665264\n",
            "\n",
            " iteration=4902 bias=41.02000000000041 loss=15.508666666665269\n",
            "\n",
            " iteration=4903 bias=41.030000000000406 loss=15.47476666666529\n",
            "\n",
            " iteration=4904 bias=41.030000000000406 loss=15.47476666666524\n",
            "\n",
            " iteration=4905 bias=41.040000000000404 loss=15.439666666665255\n",
            "\n",
            " iteration=4906 bias=41.0500000000004 loss=15.40476666666527\n",
            "\n",
            " iteration=4907 bias=41.0600000000004 loss=15.370066666665286\n",
            "\n",
            " iteration=4908 bias=41.0700000000004 loss=15.335566666665295\n",
            "\n",
            " iteration=4909 bias=41.080000000000396 loss=15.301266666665313\n",
            "\n",
            " iteration=4910 bias=41.090000000000394 loss=15.267166666665327\n",
            "\n",
            " iteration=4911 bias=41.10000000000039 loss=15.233266666665344\n",
            "\n",
            " iteration=4912 bias=41.11000000000039 loss=15.199566666665357\n",
            "\n",
            " iteration=4913 bias=41.12000000000039 loss=15.16606666666537\n",
            "\n",
            " iteration=4914 bias=41.12000000000039 loss=15.165599999998642\n",
            "\n",
            " iteration=4915 bias=41.130000000000386 loss=15.130899999998666\n",
            "\n",
            " iteration=4916 bias=41.140000000000384 loss=15.096399999998672\n",
            "\n",
            " iteration=4917 bias=41.15000000000038 loss=15.062099999998699\n",
            "\n",
            " iteration=4918 bias=41.16000000000038 loss=15.027999999998698\n",
            "\n",
            " iteration=4919 bias=41.17000000000038 loss=14.994099999998724\n",
            "\n",
            " iteration=4920 bias=41.180000000000376 loss=14.960399999998728\n",
            "\n",
            " iteration=4921 bias=41.190000000000374 loss=14.926899999998753\n",
            "\n",
            " iteration=4922 bias=41.20000000000037 loss=14.893599999998756\n",
            "\n",
            " iteration=4923 bias=41.21000000000037 loss=14.86049999999878\n",
            "\n",
            " iteration=4924 bias=41.21000000000037 loss=14.859566666665396\n",
            "\n",
            " iteration=4925 bias=41.22000000000037 loss=14.825266666665419\n",
            "\n",
            " iteration=4926 bias=41.230000000000366 loss=14.791166666665426\n",
            "\n",
            " iteration=4927 bias=41.240000000000364 loss=14.757266666665444\n",
            "\n",
            " iteration=4928 bias=41.25000000000036 loss=14.723566666665453\n",
            "\n",
            " iteration=4929 bias=41.26000000000036 loss=14.690066666665473\n",
            "\n",
            " iteration=4930 bias=41.27000000000036 loss=14.656766666665481\n",
            "\n",
            " iteration=4931 bias=41.280000000000356 loss=14.6236666666655\n",
            "\n",
            " iteration=4932 bias=41.290000000000354 loss=14.590766666665507\n",
            "\n",
            " iteration=4933 bias=41.290000000000354 loss=14.590766666665452\n",
            "\n",
            " iteration=4934 bias=41.30000000000035 loss=14.556666666665464\n",
            "\n",
            " iteration=4935 bias=41.31000000000035 loss=14.52276666666548\n",
            "\n",
            " iteration=4936 bias=41.32000000000035 loss=14.489066666665494\n",
            "\n",
            " iteration=4937 bias=41.33000000000035 loss=14.455566666665504\n",
            "\n",
            " iteration=4938 bias=41.340000000000344 loss=14.422266666665521\n",
            "\n",
            " iteration=4939 bias=41.35000000000034 loss=14.389166666665531\n",
            "\n",
            " iteration=4940 bias=41.36000000000034 loss=14.356266666665547\n",
            "\n",
            " iteration=4941 bias=41.37000000000034 loss=14.323566666665561\n",
            "\n",
            " iteration=4942 bias=41.38000000000034 loss=14.291066666665571\n",
            "\n",
            " iteration=4943 bias=41.38000000000034 loss=14.290599999998868\n",
            "\n",
            " iteration=4944 bias=41.390000000000335 loss=14.256899999998879\n",
            "\n",
            " iteration=4945 bias=41.40000000000033 loss=14.223399999998895\n",
            "\n",
            " iteration=4946 bias=41.41000000000033 loss=14.190099999998907\n",
            "\n",
            " iteration=4947 bias=41.42000000000033 loss=14.156999999998922\n",
            "\n",
            " iteration=4948 bias=41.43000000000033 loss=14.124099999998933\n",
            "\n",
            " iteration=4949 bias=41.440000000000325 loss=14.091399999998947\n",
            "\n",
            " iteration=4950 bias=41.45000000000032 loss=14.058899999998957\n",
            "\n",
            " iteration=4951 bias=41.46000000000032 loss=14.02659999999897\n",
            "\n",
            " iteration=4952 bias=41.47000000000032 loss=13.994499999998984\n",
            "\n",
            " iteration=4953 bias=41.47000000000032 loss=13.9935666666656\n",
            "\n",
            " iteration=4954 bias=41.48000000000032 loss=13.96026666666562\n",
            "\n",
            " iteration=4955 bias=41.490000000000315 loss=13.927166666665626\n",
            "\n",
            " iteration=4956 bias=41.50000000000031 loss=13.894266666665644\n",
            "\n",
            " iteration=4957 bias=41.51000000000031 loss=13.861566666665647\n",
            "\n",
            " iteration=4958 bias=41.52000000000031 loss=13.82906666666567\n",
            "\n",
            " iteration=4959 bias=41.53000000000031 loss=13.796766666665675\n",
            "\n",
            " iteration=4960 bias=41.540000000000305 loss=13.764666666665695\n",
            "\n",
            " iteration=4961 bias=41.5500000000003 loss=13.732766666665698\n",
            "\n",
            " iteration=4962 bias=41.5500000000003 loss=13.73276666666566\n",
            "\n",
            " iteration=4963 bias=41.5600000000003 loss=13.69966666666567\n",
            "\n",
            " iteration=4964 bias=41.5700000000003 loss=13.666766666665682\n",
            "\n",
            " iteration=4965 bias=41.5800000000003 loss=13.634066666665696\n",
            "\n",
            " iteration=4966 bias=41.590000000000295 loss=13.60156666666571\n",
            "\n",
            " iteration=4967 bias=41.60000000000029 loss=13.56926666666572\n",
            "\n",
            " iteration=4968 bias=41.61000000000029 loss=13.537166666665732\n",
            "\n",
            " iteration=4969 bias=41.62000000000029 loss=13.505266666665742\n",
            "\n",
            " iteration=4970 bias=41.63000000000029 loss=13.473566666665755\n",
            "\n",
            " iteration=4971 bias=41.640000000000285 loss=13.442066666665767\n",
            "\n",
            " iteration=4972 bias=41.640000000000285 loss=13.44159999999907\n",
            "\n",
            " iteration=4973 bias=41.65000000000028 loss=13.40889999999908\n",
            "\n",
            " iteration=4974 bias=41.66000000000028 loss=13.376399999999094\n",
            "\n",
            " iteration=4975 bias=41.67000000000028 loss=13.344099999999107\n",
            "\n",
            " iteration=4976 bias=41.68000000000028 loss=13.311999999999117\n",
            "\n",
            " iteration=4977 bias=41.690000000000275 loss=13.280099999999129\n",
            "\n",
            " iteration=4978 bias=41.70000000000027 loss=13.248399999999142\n",
            "\n",
            " iteration=4979 bias=41.71000000000027 loss=13.216899999999152\n",
            "\n",
            " iteration=4980 bias=41.72000000000027 loss=13.185599999999162\n",
            "\n",
            " iteration=4981 bias=41.73000000000027 loss=13.154499999999175\n",
            "\n",
            " iteration=4982 bias=41.73000000000027 loss=13.153566666665794\n",
            "\n",
            " iteration=4983 bias=41.740000000000265 loss=13.12126666666581\n",
            "\n",
            " iteration=4984 bias=41.75000000000026 loss=13.089166666665816\n",
            "\n",
            " iteration=4985 bias=41.76000000000026 loss=13.057266666665834\n",
            "\n",
            " iteration=4986 bias=41.77000000000026 loss=13.025566666665839\n",
            "\n",
            " iteration=4987 bias=41.78000000000026 loss=12.994066666665859\n",
            "\n",
            " iteration=4988 bias=41.790000000000255 loss=12.962766666665862\n",
            "\n",
            " iteration=4989 bias=41.80000000000025 loss=12.931666666665878\n",
            "\n",
            " iteration=4990 bias=41.81000000000025 loss=12.900766666665882\n",
            "\n",
            " iteration=4991 bias=41.81000000000025 loss=12.900766666665858\n",
            "\n",
            " iteration=4992 bias=41.82000000000025 loss=12.868666666665879\n",
            "\n",
            " iteration=4993 bias=41.83000000000025 loss=12.836766666665875\n",
            "\n",
            " iteration=4994 bias=41.840000000000245 loss=12.8050666666659\n",
            "\n",
            " iteration=4995 bias=41.85000000000024 loss=12.7735666666659\n",
            "\n",
            " iteration=4996 bias=41.86000000000024 loss=12.742266666665921\n",
            "\n",
            " iteration=4997 bias=41.87000000000024 loss=12.711166666665923\n",
            "\n",
            " iteration=4998 bias=41.88000000000024 loss=12.680266666665943\n",
            "\n",
            " iteration=4999 bias=41.890000000000235 loss=12.649566666665942\n",
            "\n",
            " iteration=5000 bias=41.90000000000023 loss=12.619066666665963\n",
            "\n",
            " iteration=5001 bias=41.90000000000023 loss=12.618599999999256\n",
            "\n",
            " iteration=5002 bias=41.91000000000023 loss=12.586899999999268\n",
            "\n",
            " iteration=5003 bias=41.92000000000023 loss=12.555399999999281\n",
            "\n",
            " iteration=5004 bias=41.93000000000023 loss=12.524099999999288\n",
            "\n",
            " iteration=5005 bias=41.940000000000225 loss=12.492999999999299\n",
            "\n",
            " iteration=5006 bias=41.95000000000022 loss=12.46209999999931\n",
            "\n",
            " iteration=5007 bias=41.96000000000022 loss=12.43139999999932\n",
            "\n",
            " iteration=5008 bias=41.97000000000022 loss=12.400899999999332\n",
            "\n",
            " iteration=5009 bias=41.98000000000022 loss=12.370599999999342\n",
            "\n",
            " iteration=5010 bias=41.990000000000215 loss=12.340499999999352\n",
            "\n",
            " iteration=5011 bias=41.990000000000215 loss=12.339566666666002\n",
            "\n",
            " iteration=5012 bias=42.00000000000021 loss=12.308266666666006\n",
            "\n",
            " iteration=5013 bias=42.01000000000021 loss=12.27716666666602\n",
            "\n",
            " iteration=5014 bias=42.02000000000021 loss=12.246266666666024\n",
            "\n",
            " iteration=5015 bias=42.03000000000021 loss=12.215566666666042\n",
            "\n",
            " iteration=5016 bias=42.040000000000205 loss=12.185066666666046\n",
            "\n",
            " iteration=5017 bias=42.0500000000002 loss=12.154766666666058\n",
            "\n",
            " iteration=5018 bias=42.0600000000002 loss=12.124666666666064\n",
            "\n",
            " iteration=5019 bias=42.0700000000002 loss=12.09476666666608\n",
            "\n",
            " iteration=5020 bias=42.0700000000002 loss=12.094766666666041\n",
            "\n",
            " iteration=5021 bias=42.0800000000002 loss=12.063666666666052\n",
            "\n",
            " iteration=5022 bias=42.090000000000195 loss=12.032766666666058\n",
            "\n",
            " iteration=5023 bias=42.10000000000019 loss=12.002066666666073\n",
            "\n",
            " iteration=5024 bias=42.11000000000019 loss=11.971566666666078\n",
            "\n",
            " iteration=5025 bias=42.12000000000019 loss=11.94126666666609\n",
            "\n",
            " iteration=5026 bias=42.13000000000019 loss=11.9111666666661\n",
            "\n",
            " iteration=5027 bias=42.140000000000185 loss=11.881266666666107\n",
            "\n",
            " iteration=5028 bias=42.15000000000018 loss=11.851566666666118\n",
            "\n",
            " iteration=5029 bias=42.16000000000018 loss=11.822066666666126\n",
            "\n",
            " iteration=5030 bias=42.16000000000018 loss=11.821599999999444\n",
            "\n",
            " iteration=5031 bias=42.17000000000018 loss=11.790899999999452\n",
            "\n",
            " iteration=5032 bias=42.18000000000018 loss=11.760399999999459\n",
            "\n",
            " iteration=5033 bias=42.190000000000175 loss=11.730099999999473\n",
            "\n",
            " iteration=5034 bias=42.20000000000017 loss=11.699999999999479\n",
            "\n",
            " iteration=5035 bias=42.21000000000017 loss=11.670099999999488\n",
            "\n",
            " iteration=5036 bias=42.22000000000017 loss=11.640399999999497\n",
            "\n",
            " iteration=5037 bias=42.23000000000017 loss=11.610899999999509\n",
            "\n",
            " iteration=5038 bias=42.240000000000165 loss=11.581599999999517\n",
            "\n",
            " iteration=5039 bias=42.25000000000016 loss=11.552499999999526\n",
            "\n",
            " iteration=5040 bias=42.25000000000016 loss=11.551566666666176\n",
            "\n",
            " iteration=5041 bias=42.26000000000016 loss=11.521266666666184\n",
            "\n",
            " iteration=5042 bias=42.27000000000016 loss=11.491166666666194\n",
            "\n",
            " iteration=5043 bias=42.28000000000016 loss=11.461266666666203\n",
            "\n",
            " iteration=5044 bias=42.290000000000155 loss=11.431566666666212\n",
            "\n",
            " iteration=5045 bias=42.30000000000015 loss=11.40206666666622\n",
            "\n",
            " iteration=5046 bias=42.31000000000015 loss=11.372766666666228\n",
            "\n",
            " iteration=5047 bias=42.32000000000015 loss=11.343666666666238\n",
            "\n",
            " iteration=5048 bias=42.33000000000015 loss=11.314766666666246\n",
            "\n",
            " iteration=5049 bias=42.33000000000015 loss=11.314766666666216\n",
            "\n",
            " iteration=5050 bias=42.340000000000146 loss=11.284666666666231\n",
            "\n",
            " iteration=5051 bias=42.35000000000014 loss=11.254766666666233\n",
            "\n",
            " iteration=5052 bias=42.36000000000014 loss=11.225066666666246\n",
            "\n",
            " iteration=5053 bias=42.37000000000014 loss=11.195566666666247\n",
            "\n",
            " iteration=5054 bias=42.38000000000014 loss=11.166266666666262\n",
            "\n",
            " iteration=5055 bias=42.390000000000136 loss=11.137166666666266\n",
            "\n",
            " iteration=5056 bias=42.400000000000134 loss=11.108266666666276\n",
            "\n",
            " iteration=5057 bias=42.41000000000013 loss=11.079566666666281\n",
            "\n",
            " iteration=5058 bias=42.42000000000013 loss=11.051066666666296\n",
            "\n",
            " iteration=5059 bias=42.42000000000013 loss=11.050599999999614\n",
            "\n",
            " iteration=5060 bias=42.43000000000013 loss=11.020899999999623\n",
            "\n",
            " iteration=5061 bias=42.440000000000126 loss=10.991399999999635\n",
            "\n",
            " iteration=5062 bias=42.450000000000124 loss=10.962099999999642\n",
            "\n",
            " iteration=5063 bias=42.46000000000012 loss=10.93299999999965\n",
            "\n",
            " iteration=5064 bias=42.47000000000012 loss=10.904099999999657\n",
            "\n",
            " iteration=5065 bias=42.48000000000012 loss=10.875399999999663\n",
            "\n",
            " iteration=5066 bias=42.490000000000116 loss=10.846899999999673\n",
            "\n",
            " iteration=5067 bias=42.500000000000114 loss=10.818599999999678\n",
            "\n",
            " iteration=5068 bias=42.51000000000011 loss=10.790499999999687\n",
            "\n",
            " iteration=5069 bias=42.51000000000011 loss=10.789566666666344\n",
            "\n",
            " iteration=5070 bias=42.52000000000011 loss=10.76026666666634\n",
            "\n",
            " iteration=5071 bias=42.53000000000011 loss=10.73116666666636\n",
            "\n",
            " iteration=5072 bias=42.540000000000106 loss=10.702266666666356\n",
            "\n",
            " iteration=5073 bias=42.550000000000104 loss=10.673566666666375\n",
            "\n",
            " iteration=5074 bias=42.5600000000001 loss=10.645066666666372\n",
            "\n",
            " iteration=5075 bias=42.5700000000001 loss=10.616766666666388\n",
            "\n",
            " iteration=5076 bias=42.5800000000001 loss=10.588666666666386\n",
            "\n",
            " iteration=5077 bias=42.590000000000096 loss=10.560766666666403\n",
            "\n",
            " iteration=5078 bias=42.590000000000096 loss=10.560766666666396\n",
            "\n",
            " iteration=5079 bias=42.600000000000094 loss=10.531666666666398\n",
            "\n",
            " iteration=5080 bias=42.61000000000009 loss=10.502766666666412\n",
            "\n",
            " iteration=5081 bias=42.62000000000009 loss=10.474066666666412\n",
            "\n",
            " iteration=5082 bias=42.63000000000009 loss=10.445566666666425\n",
            "\n",
            " iteration=5083 bias=42.640000000000086 loss=10.417266666666427\n",
            "\n",
            " iteration=5084 bias=42.650000000000084 loss=10.389166666666439\n",
            "\n",
            " iteration=5085 bias=42.66000000000008 loss=10.361266666666442\n",
            "\n",
            " iteration=5086 bias=42.67000000000008 loss=10.333566666666455\n",
            "\n",
            " iteration=5087 bias=42.68000000000008 loss=10.306066666666455\n",
            "\n",
            " iteration=5088 bias=42.68000000000008 loss=10.305599999999776\n",
            "\n",
            " iteration=5089 bias=42.690000000000076 loss=10.276899999999783\n",
            "\n",
            " iteration=5090 bias=42.700000000000074 loss=10.248399999999789\n",
            "\n",
            " iteration=5091 bias=42.71000000000007 loss=10.220099999999796\n",
            "\n",
            " iteration=5092 bias=42.72000000000007 loss=10.191999999999803\n",
            "\n",
            " iteration=5093 bias=42.73000000000007 loss=10.164099999999808\n",
            "\n",
            " iteration=5094 bias=42.740000000000066 loss=10.136399999999815\n",
            "\n",
            " iteration=5095 bias=42.750000000000064 loss=10.108899999999823\n",
            "\n",
            " iteration=5096 bias=42.76000000000006 loss=10.08159999999983\n",
            "\n",
            " iteration=5097 bias=42.77000000000006 loss=10.054499999999836\n",
            "\n",
            " iteration=5098 bias=42.77000000000006 loss=10.053566666666502\n",
            "\n",
            " iteration=5099 bias=42.78000000000006 loss=10.025266666666509\n",
            "\n",
            " iteration=5100 bias=42.790000000000056 loss=9.997166666666514\n",
            "\n",
            " iteration=5101 bias=42.800000000000054 loss=9.969266666666522\n",
            "\n",
            " iteration=5102 bias=42.81000000000005 loss=9.941566666666526\n",
            "\n",
            " iteration=5103 bias=42.82000000000005 loss=9.914066666666534\n",
            "\n",
            " iteration=5104 bias=42.83000000000005 loss=9.88676666666654\n",
            "\n",
            " iteration=5105 bias=42.840000000000046 loss=9.859666666666547\n",
            "\n",
            " iteration=5106 bias=42.850000000000044 loss=9.832766666666553\n",
            "\n",
            " iteration=5107 bias=42.850000000000044 loss=9.832766666666547\n",
            "\n",
            " iteration=5108 bias=42.86000000000004 loss=9.804666666666545\n",
            "\n",
            " iteration=5109 bias=42.87000000000004 loss=9.776766666666559\n",
            "\n",
            " iteration=5110 bias=42.88000000000004 loss=9.749066666666558\n",
            "\n",
            " iteration=5111 bias=42.890000000000036 loss=9.721566666666572\n",
            "\n",
            " iteration=5112 bias=42.900000000000034 loss=9.69426666666657\n",
            "\n",
            " iteration=5113 bias=42.91000000000003 loss=9.667166666666583\n",
            "\n",
            " iteration=5114 bias=42.92000000000003 loss=9.640266666666582\n",
            "\n",
            " iteration=5115 bias=42.93000000000003 loss=9.613566666666594\n",
            "\n",
            " iteration=5116 bias=42.940000000000026 loss=9.587066666666592\n",
            "\n",
            " iteration=5117 bias=42.940000000000026 loss=9.586599999999924\n",
            "\n",
            " iteration=5118 bias=42.950000000000024 loss=9.55889999999993\n",
            "\n",
            " iteration=5119 bias=42.96000000000002 loss=9.531399999999936\n",
            "\n",
            " iteration=5120 bias=42.97000000000002 loss=9.504099999999939\n",
            "\n",
            " iteration=5121 bias=42.98000000000002 loss=9.476999999999947\n",
            "\n",
            " iteration=5122 bias=42.990000000000016 loss=9.450099999999951\n",
            "\n",
            " iteration=5123 bias=43.000000000000014 loss=9.423399999999956\n",
            "\n",
            " iteration=5124 bias=43.01000000000001 loss=9.396899999999961\n",
            "\n",
            " iteration=5125 bias=43.02000000000001 loss=9.370599999999968\n",
            "\n",
            " iteration=5126 bias=43.03000000000001 loss=9.344499999999973\n",
            "\n",
            " iteration=5127 bias=43.03000000000001 loss=9.343566666666646\n",
            "\n",
            " iteration=5128 bias=43.040000000000006 loss=9.316266666666651\n",
            "\n",
            " iteration=5129 bias=43.050000000000004 loss=9.289166666666658\n",
            "\n",
            " iteration=5130 bias=43.06 loss=9.262266666666662\n",
            "\n",
            " iteration=5131 bias=43.07 loss=9.235566666666667\n",
            "\n",
            " iteration=5132 bias=43.08 loss=9.209066666666672\n",
            "\n",
            " iteration=5133 bias=43.089999999999996 loss=9.182766666666678\n",
            "\n",
            " iteration=5134 bias=43.099999999999994 loss=9.156666666666682\n",
            "\n",
            " iteration=5135 bias=43.10999999999999 loss=9.130766666666688\n",
            "\n",
            " iteration=5136 bias=43.10999999999999 loss=9.130766666666686\n",
            "\n",
            " iteration=5137 bias=43.11999999999999 loss=9.103666666666685\n",
            "\n",
            " iteration=5138 bias=43.12999999999999 loss=9.076766666666696\n",
            "\n",
            " iteration=5139 bias=43.139999999999986 loss=9.050066666666696\n",
            "\n",
            " iteration=5140 bias=43.149999999999984 loss=9.023566666666705\n",
            "\n",
            " iteration=5141 bias=43.15999999999998 loss=8.997266666666704\n",
            "\n",
            " iteration=5142 bias=43.16999999999998 loss=8.971166666666715\n",
            "\n",
            " iteration=5143 bias=43.17999999999998 loss=8.945266666666713\n",
            "\n",
            " iteration=5144 bias=43.189999999999976 loss=8.919566666666723\n",
            "\n",
            " iteration=5145 bias=43.199999999999974 loss=8.894066666666724\n",
            "\n",
            " iteration=5146 bias=43.199999999999974 loss=8.893600000000076\n",
            "\n",
            " iteration=5147 bias=43.20999999999997 loss=8.86690000000007\n",
            "\n",
            " iteration=5148 bias=43.21999999999997 loss=8.840400000000084\n",
            "\n",
            " iteration=5149 bias=43.22999999999997 loss=8.81410000000008\n",
            "\n",
            " iteration=5150 bias=43.23999999999997 loss=8.788000000000094\n",
            "\n",
            " iteration=5151 bias=43.249999999999964 loss=8.762100000000089\n",
            "\n",
            " iteration=5152 bias=43.25999999999996 loss=8.736400000000101\n",
            "\n",
            " iteration=5153 bias=43.26999999999996 loss=8.710900000000096\n",
            "\n",
            " iteration=5154 bias=43.27999999999996 loss=8.68560000000011\n",
            "\n",
            " iteration=5155 bias=43.28999999999996 loss=8.660500000000104\n",
            "\n",
            " iteration=5156 bias=43.28999999999996 loss=8.659566666666782\n",
            "\n",
            " iteration=5157 bias=43.299999999999955 loss=8.633266666666785\n",
            "\n",
            " iteration=5158 bias=43.30999999999995 loss=8.60716666666679\n",
            "\n",
            " iteration=5159 bias=43.31999999999995 loss=8.581266666666794\n",
            "\n",
            " iteration=5160 bias=43.32999999999995 loss=8.555566666666797\n",
            "\n",
            " iteration=5161 bias=43.33999999999995 loss=8.5300666666668\n",
            "\n",
            " iteration=5162 bias=43.349999999999945 loss=8.504766666666805\n",
            "\n",
            " iteration=5163 bias=43.35999999999994 loss=8.479666666666809\n",
            "\n",
            " iteration=5164 bias=43.36999999999994 loss=8.454766666666812\n",
            "\n",
            " iteration=5165 bias=43.37999999999994 loss=8.430066666666816\n",
            "\n",
            " iteration=5166 bias=43.37999999999994 loss=8.428666666666834\n",
            "\n",
            " iteration=5167 bias=43.38999999999994 loss=8.402766666666833\n",
            "\n",
            " iteration=5168 bias=43.399999999999935 loss=8.37706666666684\n",
            "\n",
            " iteration=5169 bias=43.40999999999993 loss=8.351566666666839\n",
            "\n",
            " iteration=5170 bias=43.41999999999993 loss=8.326266666666848\n",
            "\n",
            " iteration=5171 bias=43.42999999999993 loss=8.301166666666846\n",
            "\n",
            " iteration=5172 bias=43.43999999999993 loss=8.276266666666855\n",
            "\n",
            " iteration=5173 bias=43.449999999999925 loss=8.251566666666854\n",
            "\n",
            " iteration=5174 bias=43.45999999999992 loss=8.22706666666686\n",
            "\n",
            " iteration=5175 bias=43.45999999999992 loss=8.226600000000197\n",
            "\n",
            " iteration=5176 bias=43.46999999999992 loss=8.2009000000002\n",
            "\n",
            " iteration=5177 bias=43.47999999999992 loss=8.175400000000202\n",
            "\n",
            " iteration=5178 bias=43.48999999999992 loss=8.150100000000206\n",
            "\n",
            " iteration=5179 bias=43.499999999999915 loss=8.125000000000208\n",
            "\n",
            " iteration=5180 bias=43.50999999999991 loss=8.100100000000213\n",
            "\n",
            " iteration=5181 bias=43.51999999999991 loss=8.075400000000215\n",
            "\n",
            " iteration=5182 bias=43.52999999999991 loss=8.050900000000217\n",
            "\n",
            " iteration=5183 bias=43.53999999999991 loss=8.02660000000022\n",
            "\n",
            " iteration=5184 bias=43.549999999999905 loss=8.002500000000223\n",
            "\n",
            " iteration=5185 bias=43.549999999999905 loss=8.001566666666909\n",
            "\n",
            " iteration=5186 bias=43.5599999999999 loss=7.976266666666912\n",
            "\n",
            " iteration=5187 bias=43.5699999999999 loss=7.951166666666915\n",
            "\n",
            " iteration=5188 bias=43.5799999999999 loss=7.926266666666916\n",
            "\n",
            " iteration=5189 bias=43.5899999999999 loss=7.901566666666921\n",
            "\n",
            " iteration=5190 bias=43.599999999999895 loss=7.877066666666923\n",
            "\n",
            " iteration=5191 bias=43.60999999999989 loss=7.852766666666926\n",
            "\n",
            " iteration=5192 bias=43.61999999999989 loss=7.828666666666927\n",
            "\n",
            " iteration=5193 bias=43.62999999999989 loss=7.804766666666931\n",
            "\n",
            " iteration=5194 bias=43.63999999999989 loss=7.781066666666933\n",
            "\n",
            " iteration=5195 bias=43.63999999999989 loss=7.779666666666955\n",
            "\n",
            " iteration=5196 bias=43.649999999999885 loss=7.754766666666957\n",
            "\n",
            " iteration=5197 bias=43.65999999999988 loss=7.73006666666696\n",
            "\n",
            " iteration=5198 bias=43.66999999999988 loss=7.705566666666961\n",
            "\n",
            " iteration=5199 bias=43.67999999999988 loss=7.681266666666964\n",
            "\n",
            " iteration=5200 bias=43.68999999999988 loss=7.657166666666964\n",
            "\n",
            " iteration=5201 bias=43.699999999999875 loss=7.633266666666967\n",
            "\n",
            " iteration=5202 bias=43.70999999999987 loss=7.609566666666969\n",
            "\n",
            " iteration=5203 bias=43.71999999999987 loss=7.586066666666972\n",
            "\n",
            " iteration=5204 bias=43.71999999999987 loss=7.585600000000315\n",
            "\n",
            " iteration=5205 bias=43.72999999999987 loss=7.560900000000321\n",
            "\n",
            " iteration=5206 bias=43.73999999999987 loss=7.536400000000319\n",
            "\n",
            " iteration=5207 bias=43.749999999999865 loss=7.512100000000326\n",
            "\n",
            " iteration=5208 bias=43.75999999999986 loss=7.488000000000322\n",
            "\n",
            " iteration=5209 bias=43.76999999999986 loss=7.464100000000329\n",
            "\n",
            " iteration=5210 bias=43.77999999999986 loss=7.440400000000326\n",
            "\n",
            " iteration=5211 bias=43.78999999999986 loss=7.416900000000332\n",
            "\n",
            " iteration=5212 bias=43.799999999999855 loss=7.393600000000329\n",
            "\n",
            " iteration=5213 bias=43.80999999999985 loss=7.3705000000003364\n",
            "\n",
            " iteration=5214 bias=43.80999999999985 loss=7.369566666667027\n",
            "\n",
            " iteration=5215 bias=43.81999999999985 loss=7.34526666666703\n",
            "\n",
            " iteration=5216 bias=43.82999999999985 loss=7.32116666666703\n",
            "\n",
            " iteration=5217 bias=43.83999999999985 loss=7.297266666667032\n",
            "\n",
            " iteration=5218 bias=43.849999999999845 loss=7.273566666667033\n",
            "\n",
            " iteration=5219 bias=43.85999999999984 loss=7.250066666667035\n",
            "\n",
            " iteration=5220 bias=43.86999999999984 loss=7.226766666667035\n",
            "\n",
            " iteration=5221 bias=43.87999999999984 loss=7.203666666667037\n",
            "\n",
            " iteration=5222 bias=43.88999999999984 loss=7.180766666667037\n",
            "\n",
            " iteration=5223 bias=43.899999999999835 loss=7.15806666666704\n",
            "\n",
            " iteration=5224 bias=43.899999999999835 loss=7.156666666667057\n",
            "\n",
            " iteration=5225 bias=43.90999999999983 loss=7.132766666667067\n",
            "\n",
            " iteration=5226 bias=43.91999999999983 loss=7.109066666667061\n",
            "\n",
            " iteration=5227 bias=43.92999999999983 loss=7.085566666667069\n",
            "\n",
            " iteration=5228 bias=43.93999999999983 loss=7.062266666667061\n",
            "\n",
            " iteration=5229 bias=43.949999999999825 loss=7.039166666667072\n",
            "\n",
            " iteration=5230 bias=43.95999999999982 loss=7.0162666666670646\n",
            "\n",
            " iteration=5231 bias=43.96999999999982 loss=6.993566666667072\n",
            "\n",
            " iteration=5232 bias=43.97999999999982 loss=6.971066666667066\n",
            "\n",
            " iteration=5233 bias=43.97999999999982 loss=6.970600000000438\n",
            "\n",
            " iteration=5234 bias=43.98999999999982 loss=6.946900000000434\n",
            "\n",
            " iteration=5235 bias=43.999999999999815 loss=6.923400000000439\n",
            "\n",
            " iteration=5236 bias=44.00999999999981 loss=6.900100000000435\n",
            "\n",
            " iteration=5237 bias=44.01999999999981 loss=6.87700000000044\n",
            "\n",
            " iteration=5238 bias=44.02999999999981 loss=6.854100000000436\n",
            "\n",
            " iteration=5239 bias=44.03999999999981 loss=6.831400000000442\n",
            "\n",
            " iteration=5240 bias=44.049999999999805 loss=6.808900000000437\n",
            "\n",
            " iteration=5241 bias=44.0599999999998 loss=6.786600000000441\n",
            "\n",
            " iteration=5242 bias=44.0699999999998 loss=6.764500000000439\n",
            "\n",
            " iteration=5243 bias=44.0699999999998 loss=6.763566666667131\n",
            "\n",
            " iteration=5244 bias=44.0799999999998 loss=6.740266666667131\n",
            "\n",
            " iteration=5245 bias=44.0899999999998 loss=6.71716666666713\n",
            "\n",
            " iteration=5246 bias=44.099999999999795 loss=6.694266666667132\n",
            "\n",
            " iteration=5247 bias=44.10999999999979 loss=6.6715666666671325\n",
            "\n",
            " iteration=5248 bias=44.11999999999979 loss=6.649066666667132\n",
            "\n",
            " iteration=5249 bias=44.12999999999979 loss=6.626766666667133\n",
            "\n",
            " iteration=5250 bias=44.13999999999979 loss=6.604666666667132\n",
            "\n",
            " iteration=5251 bias=44.149999999999785 loss=6.5827666666671325\n",
            "\n",
            " iteration=5252 bias=44.15999999999978 loss=6.561066666667132\n",
            "\n",
            " iteration=5253 bias=44.15999999999978 loss=6.5596666666671695\n",
            "\n",
            " iteration=5254 bias=44.16999999999978 loss=6.5367666666671695\n",
            "\n",
            " iteration=5255 bias=44.17999999999978 loss=6.514066666667169\n",
            "\n",
            " iteration=5256 bias=44.18999999999978 loss=6.491566666667169\n",
            "\n",
            " iteration=5257 bias=44.199999999999775 loss=6.46926666666717\n",
            "\n",
            " iteration=5258 bias=44.20999999999977 loss=6.447166666667169\n",
            "\n",
            " iteration=5259 bias=44.21999999999977 loss=6.425266666667167\n",
            "\n",
            " iteration=5260 bias=44.22999999999977 loss=6.403566666667167\n",
            "\n",
            " iteration=5261 bias=44.23999999999977 loss=6.382066666667167\n",
            "\n",
            " iteration=5262 bias=44.23999999999977 loss=6.381600000000534\n",
            "\n",
            " iteration=5263 bias=44.249999999999766 loss=6.358900000000528\n",
            "\n",
            " iteration=5264 bias=44.25999999999976 loss=6.336400000000533\n",
            "\n",
            " iteration=5265 bias=44.26999999999976 loss=6.3141000000005265\n",
            "\n",
            " iteration=5266 bias=44.27999999999976 loss=6.292000000000532\n",
            "\n",
            " iteration=5267 bias=44.28999999999976 loss=6.270100000000525\n",
            "\n",
            " iteration=5268 bias=44.299999999999756 loss=6.24840000000053\n",
            "\n",
            " iteration=5269 bias=44.309999999999754 loss=6.226900000000524\n",
            "\n",
            " iteration=5270 bias=44.31999999999975 loss=6.20560000000053\n",
            "\n",
            " iteration=5271 bias=44.32999999999975 loss=6.184500000000521\n",
            "\n",
            " iteration=5272 bias=44.32999999999975 loss=6.183566666667225\n",
            "\n",
            " iteration=5273 bias=44.33999999999975 loss=6.161266666667224\n",
            "\n",
            " iteration=5274 bias=44.349999999999746 loss=6.139166666667223\n",
            "\n",
            " iteration=5275 bias=44.359999999999744 loss=6.117266666667223\n",
            "\n",
            " iteration=5276 bias=44.36999999999974 loss=6.095566666667221\n",
            "\n",
            " iteration=5277 bias=44.37999999999974 loss=6.074066666667221\n",
            "\n",
            " iteration=5278 bias=44.38999999999974 loss=6.052766666667218\n",
            "\n",
            " iteration=5279 bias=44.399999999999736 loss=6.031666666667218\n",
            "\n",
            " iteration=5280 bias=44.409999999999734 loss=6.010766666667216\n",
            "\n",
            " iteration=5281 bias=44.41999999999973 loss=5.990066666667214\n",
            "\n",
            " iteration=5282 bias=44.41999999999973 loss=5.988666666667259\n",
            "\n",
            " iteration=5283 bias=44.42999999999973 loss=5.966766666667257\n",
            "\n",
            " iteration=5284 bias=44.43999999999973 loss=5.945066666667256\n",
            "\n",
            " iteration=5285 bias=44.449999999999726 loss=5.923566666667256\n",
            "\n",
            " iteration=5286 bias=44.459999999999724 loss=5.902266666667255\n",
            "\n",
            " iteration=5287 bias=44.46999999999972 loss=5.881166666667252\n",
            "\n",
            " iteration=5288 bias=44.47999999999972 loss=5.8602666666672505\n",
            "\n",
            " iteration=5289 bias=44.48999999999972 loss=5.839566666667248\n",
            "\n",
            " iteration=5290 bias=44.499999999999716 loss=5.819066666667247\n",
            "\n",
            " iteration=5291 bias=44.499999999999716 loss=5.818600000000618\n",
            "\n",
            " iteration=5292 bias=44.509999999999714 loss=5.796900000000612\n",
            "\n",
            " iteration=5293 bias=44.51999999999971 loss=5.775400000000616\n",
            "\n",
            " iteration=5294 bias=44.52999999999971 loss=5.7541000000006095\n",
            "\n",
            " iteration=5295 bias=44.53999999999971 loss=5.733000000000611\n",
            "\n",
            " iteration=5296 bias=44.549999999999706 loss=5.712100000000606\n",
            "\n",
            " iteration=5297 bias=44.559999999999704 loss=5.691400000000608\n",
            "\n",
            " iteration=5298 bias=44.5699999999997 loss=5.670900000000603\n",
            "\n",
            " iteration=5299 bias=44.5799999999997 loss=5.650600000000604\n",
            "\n",
            " iteration=5300 bias=44.5899999999997 loss=5.630500000000597\n",
            "\n",
            " iteration=5301 bias=44.5899999999997 loss=5.629566666667311\n",
            "\n",
            " iteration=5302 bias=44.599999999999696 loss=5.608266666667316\n",
            "\n",
            " iteration=5303 bias=44.609999999999694 loss=5.587166666667308\n",
            "\n",
            " iteration=5304 bias=44.61999999999969 loss=5.566266666667313\n",
            "\n",
            " iteration=5305 bias=44.62999999999969 loss=5.545566666667303\n",
            "\n",
            " iteration=5306 bias=44.63999999999969 loss=5.525066666667307\n",
            "\n",
            " iteration=5307 bias=44.649999999999686 loss=5.504766666667298\n",
            "\n",
            " iteration=5308 bias=44.659999999999684 loss=5.484666666667302\n",
            "\n",
            " iteration=5309 bias=44.66999999999968 loss=5.464766666667292\n",
            "\n",
            " iteration=5310 bias=44.67999999999968 loss=5.445066666667297\n",
            "\n",
            " iteration=5311 bias=44.67999999999968 loss=5.4436666666673394\n",
            "\n",
            " iteration=5312 bias=44.68999999999968 loss=5.422766666667336\n",
            "\n",
            " iteration=5313 bias=44.699999999999676 loss=5.402066666667333\n",
            "\n",
            " iteration=5314 bias=44.709999999999674 loss=5.381566666667331\n",
            "\n",
            " iteration=5315 bias=44.71999999999967 loss=5.361266666667329\n",
            "\n",
            " iteration=5316 bias=44.72999999999967 loss=5.341166666667324\n",
            "\n",
            " iteration=5317 bias=44.73999999999967 loss=5.321266666667323\n",
            "\n",
            " iteration=5318 bias=44.749999999999666 loss=5.301566666667319\n",
            "\n",
            " iteration=5319 bias=44.759999999999664 loss=5.282066666667316\n",
            "\n",
            " iteration=5320 bias=44.759999999999664 loss=5.281600000000702\n",
            "\n",
            " iteration=5321 bias=44.76999999999966 loss=5.260900000000702\n",
            "\n",
            " iteration=5322 bias=44.77999999999966 loss=5.240400000000695\n",
            "\n",
            " iteration=5323 bias=44.78999999999966 loss=5.220100000000696\n",
            "\n",
            " iteration=5324 bias=44.799999999999656 loss=5.200000000000689\n",
            "\n",
            " iteration=5325 bias=44.809999999999654 loss=5.18010000000069\n",
            "\n",
            " iteration=5326 bias=44.81999999999965 loss=5.160400000000682\n",
            "\n",
            " iteration=5327 bias=44.82999999999965 loss=5.140900000000683\n",
            "\n",
            " iteration=5328 bias=44.83999999999965 loss=5.121600000000676\n",
            "\n",
            " iteration=5329 bias=44.849999999999646 loss=5.102500000000677\n",
            "\n",
            " iteration=5330 bias=44.849999999999646 loss=5.101566666667385\n",
            "\n",
            " iteration=5331 bias=44.859999999999644 loss=5.081266666667383\n",
            "\n",
            " iteration=5332 bias=44.86999999999964 loss=5.061166666667379\n",
            "\n",
            " iteration=5333 bias=44.87999999999964 loss=5.041266666667376\n",
            "\n",
            " iteration=5334 bias=44.88999999999964 loss=5.021566666667373\n",
            "\n",
            " iteration=5335 bias=44.899999999999636 loss=5.0020666666673685\n",
            "\n",
            " iteration=5336 bias=44.909999999999634 loss=4.982766666667366\n",
            "\n",
            " iteration=5337 bias=44.91999999999963 loss=4.963666666667361\n",
            "\n",
            " iteration=5338 bias=44.92999999999963 loss=4.944766666667357\n",
            "\n",
            " iteration=5339 bias=44.93999999999963 loss=4.926066666667354\n",
            "\n",
            " iteration=5340 bias=44.93999999999963 loss=4.92466666666741\n",
            "\n",
            " iteration=5341 bias=44.949999999999626 loss=4.904766666667407\n",
            "\n",
            " iteration=5342 bias=44.959999999999624 loss=4.885066666667403\n",
            "\n",
            " iteration=5343 bias=44.96999999999962 loss=4.865566666667399\n",
            "\n",
            " iteration=5344 bias=44.97999999999962 loss=4.846266666667396\n",
            "\n",
            " iteration=5345 bias=44.98999999999962 loss=4.827166666667392\n",
            "\n",
            " iteration=5346 bias=44.999999999999616 loss=4.808266666667387\n",
            "\n",
            " iteration=5347 bias=45.009999999999614 loss=4.789566666667383\n",
            "\n",
            " iteration=5348 bias=45.01999999999961 loss=4.771066666667379\n",
            "\n",
            " iteration=5349 bias=45.01999999999961 loss=4.770600000000772\n",
            "\n",
            " iteration=5350 bias=45.02999999999961 loss=4.750900000000768\n",
            "\n",
            " iteration=5351 bias=45.03999999999961 loss=4.731400000000764\n",
            "\n",
            " iteration=5352 bias=45.049999999999606 loss=4.712100000000759\n",
            "\n",
            " iteration=5353 bias=45.059999999999604 loss=4.693000000000755\n",
            "\n",
            " iteration=5354 bias=45.0699999999996 loss=4.67410000000075\n",
            "\n",
            " iteration=5355 bias=45.0799999999996 loss=4.655400000000746\n",
            "\n",
            " iteration=5356 bias=45.0899999999996 loss=4.636900000000741\n",
            "\n",
            " iteration=5357 bias=45.099999999999596 loss=4.618600000000737\n",
            "\n",
            " iteration=5358 bias=45.109999999999594 loss=4.600500000000732\n",
            "\n",
            " iteration=5359 bias=45.109999999999594 loss=4.5995666666674495\n",
            "\n",
            " iteration=5360 bias=45.11999999999959 loss=4.580266666667448\n",
            "\n",
            " iteration=5361 bias=45.12999999999959 loss=4.56116666666744\n",
            "\n",
            " iteration=5362 bias=45.13999999999959 loss=4.542266666667438\n",
            "\n",
            " iteration=5363 bias=45.14999999999959 loss=4.523566666667431\n",
            "\n",
            " iteration=5364 bias=45.159999999999584 loss=4.505066666667429\n",
            "\n",
            " iteration=5365 bias=45.16999999999958 loss=4.486766666667421\n",
            "\n",
            " iteration=5366 bias=45.17999999999958 loss=4.46866666666742\n",
            "\n",
            " iteration=5367 bias=45.18999999999958 loss=4.450766666667411\n",
            "\n",
            " iteration=5368 bias=45.19999999999958 loss=4.433066666667409\n",
            "\n",
            " iteration=5369 bias=45.19999999999958 loss=4.431666666667472\n",
            "\n",
            " iteration=5370 bias=45.209999999999575 loss=4.412766666667468\n",
            "\n",
            " iteration=5371 bias=45.21999999999957 loss=4.394066666667463\n",
            "\n",
            " iteration=5372 bias=45.22999999999957 loss=4.375566666667457\n",
            "\n",
            " iteration=5373 bias=45.23999999999957 loss=4.357266666667453\n",
            "\n",
            " iteration=5374 bias=45.24999999999957 loss=4.339166666667448\n",
            "\n",
            " iteration=5375 bias=45.259999999999565 loss=4.321266666667442\n",
            "\n",
            " iteration=5376 bias=45.26999999999956 loss=4.303566666667436\n",
            "\n",
            " iteration=5377 bias=45.27999999999956 loss=4.286066666667431\n",
            "\n",
            " iteration=5378 bias=45.27999999999956 loss=4.285600000000823\n",
            "\n",
            " iteration=5379 bias=45.28999999999956 loss=4.266900000000824\n",
            "\n",
            " iteration=5380 bias=45.29999999999956 loss=4.248400000000813\n",
            "\n",
            " iteration=5381 bias=45.309999999999555 loss=4.230100000000813\n",
            "\n",
            " iteration=5382 bias=45.31999999999955 loss=4.212000000000802\n",
            "\n",
            " iteration=5383 bias=45.32999999999955 loss=4.194100000000802\n",
            "\n",
            " iteration=5384 bias=45.33999999999955 loss=4.17640000000079\n",
            "\n",
            " iteration=5385 bias=45.34999999999955 loss=4.1589000000007905\n",
            "\n",
            " iteration=5386 bias=45.359999999999545 loss=4.141600000000778\n",
            "\n",
            " iteration=5387 bias=45.36999999999954 loss=4.124500000000778\n",
            "\n",
            " iteration=5388 bias=45.36999999999954 loss=4.123566666667514\n",
            "\n",
            " iteration=5389 bias=45.37999999999954 loss=4.105266666667505\n",
            "\n",
            " iteration=5390 bias=45.38999999999954 loss=4.087166666667502\n",
            "\n",
            " iteration=5391 bias=45.39999999999954 loss=4.069266666667493\n",
            "\n",
            " iteration=5392 bias=45.409999999999535 loss=4.05156666666749\n",
            "\n",
            " iteration=5393 bias=45.41999999999953 loss=4.034066666667481\n",
            "\n",
            " iteration=5394 bias=45.42999999999953 loss=4.016766666667478\n",
            "\n",
            " iteration=5395 bias=45.43999999999953 loss=3.9996666666674687\n",
            "\n",
            " iteration=5396 bias=45.44999999999953 loss=3.982766666667466\n",
            "\n",
            " iteration=5397 bias=45.459999999999525 loss=3.9660666666674556\n",
            "\n",
            " iteration=5398 bias=45.459999999999525 loss=3.964666666667522\n",
            "\n",
            " iteration=5399 bias=45.46999999999952 loss=3.9467666666675156\n",
            "\n",
            " iteration=5400 bias=45.47999999999952 loss=3.9290666666675094\n",
            "\n",
            " iteration=5401 bias=45.48999999999952 loss=3.9115666666675026\n",
            "\n",
            " iteration=5402 bias=45.49999999999952 loss=3.8942666666674963\n",
            "\n",
            " iteration=5403 bias=45.509999999999515 loss=3.87716666666749\n",
            "\n",
            " iteration=5404 bias=45.51999999999951 loss=3.860266666667483\n",
            "\n",
            " iteration=5405 bias=45.52999999999951 loss=3.8435666666674764\n",
            "\n",
            " iteration=5406 bias=45.53999999999951 loss=3.82706666666747\n",
            "\n",
            " iteration=5407 bias=45.53999999999951 loss=3.826600000000878\n",
            "\n",
            " iteration=5408 bias=45.54999999999951 loss=3.8089000000008717\n",
            "\n",
            " iteration=5409 bias=45.559999999999505 loss=3.791400000000865\n",
            "\n",
            " iteration=5410 bias=45.5699999999995 loss=3.774100000000858\n",
            "\n",
            " iteration=5411 bias=45.5799999999995 loss=3.757000000000851\n",
            "\n",
            " iteration=5412 bias=45.5899999999995 loss=3.7401000000008437\n",
            "\n",
            " iteration=5413 bias=45.5999999999995 loss=3.723400000000837\n",
            "\n",
            " iteration=5414 bias=45.609999999999495 loss=3.7069000000008305\n",
            "\n",
            " iteration=5415 bias=45.61999999999949 loss=3.6906000000008228\n",
            "\n",
            " iteration=5416 bias=45.62999999999949 loss=3.674500000000816\n",
            "\n",
            " iteration=5417 bias=45.62999999999949 loss=3.6735666666675555\n",
            "\n",
            " iteration=5418 bias=45.63999999999949 loss=3.6562666666675434\n",
            "\n",
            " iteration=5419 bias=45.64999999999949 loss=3.6391666666675415\n",
            "\n",
            " iteration=5420 bias=45.659999999999485 loss=3.6222666666675294\n",
            "\n",
            " iteration=5421 bias=45.66999999999948 loss=3.6055666666675275\n",
            "\n",
            " iteration=5422 bias=45.67999999999948 loss=3.5890666666675153\n",
            "\n",
            " iteration=5423 bias=45.68999999999948 loss=3.5727666666675124\n",
            "\n",
            " iteration=5424 bias=45.69999999999948 loss=3.5566666666675\n",
            "\n",
            " iteration=5425 bias=45.709999999999475 loss=3.5407666666674977\n",
            "\n",
            " iteration=5426 bias=45.71999999999947 loss=3.5250666666674846\n",
            "\n",
            " iteration=5427 bias=45.71999999999947 loss=3.523666666667564\n",
            "\n",
            " iteration=5428 bias=45.72999999999947 loss=3.5067666666675557\n",
            "\n",
            " iteration=5429 bias=45.73999999999947 loss=3.4900666666675484\n",
            "\n",
            " iteration=5430 bias=45.74999999999947 loss=3.4735666666675407\n",
            "\n",
            " iteration=5431 bias=45.759999999999465 loss=3.457266666667533\n",
            "\n",
            " iteration=5432 bias=45.76999999999946 loss=3.4411666666675256\n",
            "\n",
            " iteration=5433 bias=45.77999999999946 loss=3.425266666667518\n",
            "\n",
            " iteration=5434 bias=45.78999999999946 loss=3.40956666666751\n",
            "\n",
            " iteration=5435 bias=45.79999999999946 loss=3.394066666667502\n",
            "\n",
            " iteration=5436 bias=45.79999999999946 loss=3.3936000000009146\n",
            "\n",
            " iteration=5437 bias=45.809999999999455 loss=3.376900000000903\n",
            "\n",
            " iteration=5438 bias=45.81999999999945 loss=3.3604000000008996\n",
            "\n",
            " iteration=5439 bias=45.82999999999945 loss=3.344100000000887\n",
            "\n",
            " iteration=5440 bias=45.83999999999945 loss=3.328000000000884\n",
            "\n",
            " iteration=5441 bias=45.84999999999945 loss=3.3121000000008713\n",
            "\n",
            " iteration=5442 bias=45.859999999999445 loss=3.2964000000008675\n",
            "\n",
            " iteration=5443 bias=45.86999999999944 loss=3.280900000000855\n",
            "\n",
            " iteration=5444 bias=45.87999999999944 loss=3.2656000000008505\n",
            "\n",
            " iteration=5445 bias=45.88999999999944 loss=3.2505000000008377\n",
            "\n",
            " iteration=5446 bias=45.88999999999944 loss=3.249566666667587\n",
            "\n",
            " iteration=5447 bias=45.89999999999944 loss=3.2332666666675784\n",
            "\n",
            " iteration=5448 bias=45.909999999999435 loss=3.2171666666675702\n",
            "\n",
            " iteration=5449 bias=45.91999999999943 loss=3.201266666667562\n",
            "\n",
            " iteration=5450 bias=45.92999999999943 loss=3.185566666667554\n",
            "\n",
            " iteration=5451 bias=45.93999999999943 loss=3.170066666667545\n",
            "\n",
            " iteration=5452 bias=45.94999999999943 loss=3.1547666666675362\n",
            "\n",
            " iteration=5453 bias=45.959999999999425 loss=3.1396666666675284\n",
            "\n",
            " iteration=5454 bias=45.96999999999942 loss=3.124766666667519\n",
            "\n",
            " iteration=5455 bias=45.97999999999942 loss=3.1100666666675103\n",
            "\n",
            " iteration=5456 bias=45.97999999999942 loss=3.1086666666675904\n",
            "\n",
            " iteration=5457 bias=45.98999999999942 loss=3.0927666666675866\n",
            "\n",
            " iteration=5458 bias=45.99999999999942 loss=3.0770666666675734\n",
            "\n",
            " iteration=5459 bias=46.009999999999415 loss=3.0615666666675687\n",
            "\n",
            " iteration=5460 bias=46.01999999999941 loss=3.046266666667556\n",
            "\n",
            " iteration=5461 bias=46.02999999999941 loss=3.031166666667552\n",
            "\n",
            " iteration=5462 bias=46.03999999999941 loss=3.0162666666675384\n",
            "\n",
            " iteration=5463 bias=46.04999999999941 loss=3.0015666666675336\n",
            "\n",
            " iteration=5464 bias=46.059999999999405 loss=2.98706666666752\n",
            "\n",
            " iteration=5465 bias=46.059999999999405 loss=2.9866000000009394\n",
            "\n",
            " iteration=5466 bias=46.0699999999994 loss=2.970900000000931\n",
            "\n",
            " iteration=5467 bias=46.0799999999994 loss=2.9554000000009224\n",
            "\n",
            " iteration=5468 bias=46.0899999999994 loss=2.9401000000009128\n",
            "\n",
            " iteration=5469 bias=46.0999999999994 loss=2.9250000000009035\n",
            "\n",
            " iteration=5470 bias=46.109999999999395 loss=2.910100000000894\n",
            "\n",
            " iteration=5471 bias=46.11999999999939 loss=2.8954000000008855\n",
            "\n",
            " iteration=5472 bias=46.12999999999939 loss=2.8809000000008758\n",
            "\n",
            " iteration=5473 bias=46.13999999999939 loss=2.8666000000008665\n",
            "\n",
            " iteration=5474 bias=46.14999999999939 loss=2.8525000000008567\n",
            "\n",
            " iteration=5475 bias=46.14999999999939 loss=2.8515666666676083\n",
            "\n",
            " iteration=5476 bias=46.159999999999386 loss=2.836266666667603\n",
            "\n",
            " iteration=5477 bias=46.16999999999938 loss=2.821166666667589\n",
            "\n",
            " iteration=5478 bias=46.17999999999938 loss=2.806266666667584\n",
            "\n",
            " iteration=5479 bias=46.18999999999938 loss=2.7915666666675705\n",
            "\n",
            " iteration=5480 bias=46.19999999999938 loss=2.777066666667565\n",
            "\n",
            " iteration=5481 bias=46.209999999999376 loss=2.762766666667551\n",
            "\n",
            " iteration=5482 bias=46.219999999999374 loss=2.7486666666675457\n",
            "\n",
            " iteration=5483 bias=46.22999999999937 loss=2.734766666667531\n",
            "\n",
            " iteration=5484 bias=46.23999999999937 loss=2.7210666666675256\n",
            "\n",
            " iteration=5485 bias=46.23999999999937 loss=2.7196666666676124\n",
            "\n",
            " iteration=5486 bias=46.24999999999937 loss=2.7047666666676022\n",
            "\n",
            " iteration=5487 bias=46.259999999999366 loss=2.6900666666675925\n",
            "\n",
            " iteration=5488 bias=46.269999999999364 loss=2.675566666667583\n",
            "\n",
            " iteration=5489 bias=46.27999999999936 loss=2.661266666667573\n",
            "\n",
            " iteration=5490 bias=46.28999999999936 loss=2.647166666667563\n",
            "\n",
            " iteration=5491 bias=46.29999999999936 loss=2.633266666667553\n",
            "\n",
            " iteration=5492 bias=46.309999999999356 loss=2.619566666667543\n",
            "\n",
            " iteration=5493 bias=46.319999999999354 loss=2.6060666666675325\n",
            "\n",
            " iteration=5494 bias=46.319999999999354 loss=2.6056000000009547\n",
            "\n",
            " iteration=5495 bias=46.32999999999935 loss=2.5909000000009486\n",
            "\n",
            " iteration=5496 bias=46.33999999999935 loss=2.5764000000009344\n",
            "\n",
            " iteration=5497 bias=46.34999999999935 loss=2.562100000000928\n",
            "\n",
            " iteration=5498 bias=46.359999999999346 loss=2.548000000000914\n",
            "\n",
            " iteration=5499 bias=46.369999999999344 loss=2.5341000000009077\n",
            "\n",
            " iteration=5500 bias=46.37999999999934 loss=2.5204000000008935\n",
            "\n",
            " iteration=5501 bias=46.38999999999934 loss=2.5069000000008868\n",
            "\n",
            " iteration=5502 bias=46.39999999999934 loss=2.4936000000008725\n",
            "\n",
            " iteration=5503 bias=46.409999999999336 loss=2.4805000000008657\n",
            "\n",
            " iteration=5504 bias=46.409999999999336 loss=2.479566666667623\n",
            "\n",
            " iteration=5505 bias=46.419999999999334 loss=2.465266666667613\n",
            "\n",
            " iteration=5506 bias=46.42999999999933 loss=2.451166666667602\n",
            "\n",
            " iteration=5507 bias=46.43999999999933 loss=2.4372666666675915\n",
            "\n",
            " iteration=5508 bias=46.44999999999933 loss=2.423566666667581\n",
            "\n",
            " iteration=5509 bias=46.459999999999326 loss=2.41006666666757\n",
            "\n",
            " iteration=5510 bias=46.469999999999324 loss=2.3967666666675593\n",
            "\n",
            " iteration=5511 bias=46.47999999999932 loss=2.383666666667548\n",
            "\n",
            " iteration=5512 bias=46.48999999999932 loss=2.3707666666675373\n",
            "\n",
            " iteration=5513 bias=46.49999999999932 loss=2.358066666667526\n",
            "\n",
            " iteration=5514 bias=46.49999999999932 loss=2.3566666666676235\n",
            "\n",
            " iteration=5515 bias=46.509999999999316 loss=2.342766666667609\n",
            "\n",
            " iteration=5516 bias=46.519999999999314 loss=2.3290666666676016\n",
            "\n",
            " iteration=5517 bias=46.52999999999931 loss=2.315566666667587\n",
            "\n",
            " iteration=5518 bias=46.53999999999931 loss=2.3022666666675793\n",
            "\n",
            " iteration=5519 bias=46.54999999999931 loss=2.2891666666675645\n",
            "\n",
            " iteration=5520 bias=46.559999999999306 loss=2.276266666667557\n",
            "\n",
            " iteration=5521 bias=46.569999999999304 loss=2.263566666667542\n",
            "\n",
            " iteration=5522 bias=46.5799999999993 loss=2.2510666666675347\n",
            "\n",
            " iteration=5523 bias=46.5799999999993 loss=2.250600000000963\n",
            "\n",
            " iteration=5524 bias=46.5899999999993 loss=2.236900000000952\n",
            "\n",
            " iteration=5525 bias=46.5999999999993 loss=2.223400000000941\n",
            "\n",
            " iteration=5526 bias=46.609999999999296 loss=2.210100000000929\n",
            "\n",
            " iteration=5527 bias=46.619999999999294 loss=2.197000000000918\n",
            "\n",
            " iteration=5528 bias=46.62999999999929 loss=2.1841000000009063\n",
            "\n",
            " iteration=5529 bias=46.63999999999929 loss=2.1714000000008946\n",
            "\n",
            " iteration=5530 bias=46.64999999999929 loss=2.1589000000008833\n",
            "\n",
            " iteration=5531 bias=46.659999999999286 loss=2.1466000000008716\n",
            "\n",
            " iteration=5532 bias=46.669999999999284 loss=2.1345000000008594\n",
            "\n",
            " iteration=5533 bias=46.669999999999284 loss=2.1335666666676274\n",
            "\n",
            " iteration=5534 bias=46.67999999999928 loss=2.120266666667612\n",
            "\n",
            " iteration=5535 bias=46.68999999999928 loss=2.107166666667604\n",
            "\n",
            " iteration=5536 bias=46.69999999999928 loss=2.094266666667589\n",
            "\n",
            " iteration=5537 bias=46.709999999999276 loss=2.0815666666675807\n",
            "\n",
            " iteration=5538 bias=46.719999999999274 loss=2.0690666666675654\n",
            "\n",
            " iteration=5539 bias=46.72999999999927 loss=2.056766666667557\n",
            "\n",
            " iteration=5540 bias=46.73999999999927 loss=2.044666666667541\n",
            "\n",
            " iteration=5541 bias=46.74999999999927 loss=2.032766666667533\n",
            "\n",
            " iteration=5542 bias=46.759999999999266 loss=2.0210666666675166\n",
            "\n",
            " iteration=5543 bias=46.759999999999266 loss=2.01966666666762\n",
            "\n",
            " iteration=5544 bias=46.769999999999264 loss=2.0067666666676085\n",
            "\n",
            " iteration=5545 bias=46.77999999999926 loss=1.9940666666675961\n",
            "\n",
            " iteration=5546 bias=46.78999999999926 loss=1.9815666666675842\n",
            "\n",
            " iteration=5547 bias=46.79999999999926 loss=1.969266666667572\n",
            "\n",
            " iteration=5548 bias=46.809999999999256 loss=1.9571666666675593\n",
            "\n",
            " iteration=5549 bias=46.819999999999254 loss=1.945266666667547\n",
            "\n",
            " iteration=5550 bias=46.82999999999925 loss=1.9335666666675344\n",
            "\n",
            " iteration=5551 bias=46.83999999999925 loss=1.9220666666675221\n",
            "\n",
            " iteration=5552 bias=46.83999999999925 loss=1.9216000000009608\n",
            "\n",
            " iteration=5553 bias=46.84999999999925 loss=1.9089000000009448\n",
            "\n",
            " iteration=5554 bias=46.859999999999246 loss=1.896400000000936\n",
            "\n",
            " iteration=5555 bias=46.869999999999244 loss=1.8841000000009203\n",
            "\n",
            " iteration=5556 bias=46.87999999999924 loss=1.8720000000009112\n",
            "\n",
            " iteration=5557 bias=46.88999999999924 loss=1.8601000000008951\n",
            "\n",
            " iteration=5558 bias=46.89999999999924 loss=1.8484000000008856\n",
            "\n",
            " iteration=5559 bias=46.909999999999236 loss=1.8369000000008693\n",
            "\n",
            " iteration=5560 bias=46.919999999999234 loss=1.82560000000086\n",
            "\n",
            " iteration=5561 bias=46.92999999999923 loss=1.8145000000008435\n",
            "\n",
            " iteration=5562 bias=46.92999999999923 loss=1.8135666666676178\n",
            "\n",
            " iteration=5563 bias=46.93999999999923 loss=1.8012666666676054\n",
            "\n",
            " iteration=5564 bias=46.94999999999923 loss=1.789166666667592\n",
            "\n",
            " iteration=5565 bias=46.959999999999226 loss=1.7772666666675796\n",
            "\n",
            " iteration=5566 bias=46.969999999999224 loss=1.7655666666675665\n",
            "\n",
            " iteration=5567 bias=46.97999999999922 loss=1.7540666666675537\n",
            "\n",
            " iteration=5568 bias=46.98999999999922 loss=1.7427666666675403\n",
            "\n",
            " iteration=5569 bias=46.99999999999922 loss=1.731666666667527\n",
            "\n",
            " iteration=5570 bias=47.009999999999216 loss=1.720766666667514\n",
            "\n",
            " iteration=5571 bias=47.019999999999214 loss=1.7100666666675004\n",
            "\n",
            " iteration=5572 bias=47.019999999999214 loss=1.7086666666676071\n",
            "\n",
            " iteration=5573 bias=47.02999999999921 loss=1.6967666666675971\n",
            "\n",
            " iteration=5574 bias=47.03999999999921 loss=1.6850666666675806\n",
            "\n",
            " iteration=5575 bias=47.04999999999921 loss=1.6735666666675708\n",
            "\n",
            " iteration=5576 bias=47.05999999999921 loss=1.6622666666675538\n",
            "\n",
            " iteration=5577 bias=47.069999999999204 loss=1.6511666666675435\n",
            "\n",
            " iteration=5578 bias=47.0799999999992 loss=1.640266666667527\n",
            "\n",
            " iteration=5579 bias=47.0899999999992 loss=1.6295666666675166\n",
            "\n",
            " iteration=5580 bias=47.0999999999992 loss=1.6190666666674998\n",
            "\n",
            " iteration=5581 bias=47.0999999999992 loss=1.6186000000009446\n",
            "\n",
            " iteration=5582 bias=47.1099999999992 loss=1.6069000000009313\n",
            "\n",
            " iteration=5583 bias=47.119999999999195 loss=1.5954000000009179\n",
            "\n",
            " iteration=5584 bias=47.12999999999919 loss=1.5841000000009042\n",
            "\n",
            " iteration=5585 bias=47.13999999999919 loss=1.5730000000008904\n",
            "\n",
            " iteration=5586 bias=47.14999999999919 loss=1.5621000000008767\n",
            "\n",
            " iteration=5587 bias=47.15999999999919 loss=1.5514000000008625\n",
            "\n",
            " iteration=5588 bias=47.169999999999185 loss=1.540900000000849\n",
            "\n",
            " iteration=5589 bias=47.17999999999918 loss=1.5306000000008346\n",
            "\n",
            " iteration=5590 bias=47.18999999999918 loss=1.5205000000008209\n",
            "\n",
            " iteration=5591 bias=47.18999999999918 loss=1.519566666667598\n",
            "\n",
            " iteration=5592 bias=47.19999999999918 loss=1.5082666666675875\n",
            "\n",
            " iteration=5593 bias=47.20999999999918 loss=1.4971666666675703\n",
            "\n",
            " iteration=5594 bias=47.219999999999175 loss=1.4862666666675592\n",
            "\n",
            " iteration=5595 bias=47.22999999999917 loss=1.4755666666675422\n",
            "\n",
            " iteration=5596 bias=47.23999999999917 loss=1.4650666666675312\n",
            "\n",
            " iteration=5597 bias=47.24999999999917 loss=1.454766666667514\n",
            "\n",
            " iteration=5598 bias=47.25999999999917 loss=1.4446666666675025\n",
            "\n",
            " iteration=5599 bias=47.269999999999165 loss=1.4347666666674848\n",
            "\n",
            " iteration=5600 bias=47.27999999999916 loss=1.4250666666674736\n",
            "\n",
            " iteration=5601 bias=47.27999999999916 loss=1.4236666666675868\n",
            "\n",
            " iteration=5602 bias=47.28999999999916 loss=1.4127666666675722\n",
            "\n",
            " iteration=5603 bias=47.29999999999916 loss=1.402066666667558\n",
            "\n",
            " iteration=5604 bias=47.30999999999916 loss=1.3915666666675435\n",
            "\n",
            " iteration=5605 bias=47.319999999999155 loss=1.381266666667529\n",
            "\n",
            " iteration=5606 bias=47.32999999999915 loss=1.3711666666675144\n",
            "\n",
            " iteration=5607 bias=47.33999999999915 loss=1.3612666666674997\n",
            "\n",
            " iteration=5608 bias=47.34999999999915 loss=1.351566666667485\n",
            "\n",
            " iteration=5609 bias=47.35999999999915 loss=1.3420666666674699\n",
            "\n",
            " iteration=5610 bias=47.35999999999915 loss=1.3416000000009187\n",
            "\n",
            " iteration=5611 bias=47.369999999999145 loss=1.3309000000009068\n",
            "\n",
            " iteration=5612 bias=47.37999999999914 loss=1.3204000000008893\n",
            "\n",
            " iteration=5613 bias=47.38999999999914 loss=1.3101000000008776\n",
            "\n",
            " iteration=5614 bias=47.39999999999914 loss=1.3000000000008598\n",
            "\n",
            " iteration=5615 bias=47.40999999999914 loss=1.2901000000008478\n",
            "\n",
            " iteration=5616 bias=47.419999999999135 loss=1.2804000000008298\n",
            "\n",
            " iteration=5617 bias=47.42999999999913 loss=1.2709000000008175\n",
            "\n",
            " iteration=5618 bias=47.43999999999913 loss=1.2616000000007996\n",
            "\n",
            " iteration=5619 bias=47.44999999999913 loss=1.252500000000787\n",
            "\n",
            " iteration=5620 bias=47.44999999999913 loss=1.2515666666675713\n",
            "\n",
            " iteration=5621 bias=47.45999999999913 loss=1.2412666666675563\n",
            "\n",
            " iteration=5622 bias=47.469999999999125 loss=1.231166666667541\n",
            "\n",
            " iteration=5623 bias=47.47999999999912 loss=1.2212666666675258\n",
            "\n",
            " iteration=5624 bias=47.48999999999912 loss=1.2115666666675107\n",
            "\n",
            " iteration=5625 bias=47.49999999999912 loss=1.2020666666674955\n",
            "\n",
            " iteration=5626 bias=47.50999999999912 loss=1.1927666666674799\n",
            "\n",
            " iteration=5627 bias=47.519999999999115 loss=1.1836666666674645\n",
            "\n",
            " iteration=5628 bias=47.52999999999911 loss=1.174766666667449\n",
            "\n",
            " iteration=5629 bias=47.53999999999911 loss=1.1660666666674333\n",
            "\n",
            " iteration=5630 bias=47.53999999999911 loss=1.1646666666675556\n",
            "\n",
            " iteration=5631 bias=47.54999999999911 loss=1.1547666666675376\n",
            "\n",
            " iteration=5632 bias=47.55999999999911 loss=1.1450666666675247\n",
            "\n",
            " iteration=5633 bias=47.569999999999105 loss=1.1355666666675066\n",
            "\n",
            " iteration=5634 bias=47.5799999999991 loss=1.1262666666674936\n",
            "\n",
            " iteration=5635 bias=47.5899999999991 loss=1.117166666667475\n",
            "\n",
            " iteration=5636 bias=47.5999999999991 loss=1.1082666666674619\n",
            "\n",
            " iteration=5637 bias=47.6099999999991 loss=1.0995666666674435\n",
            "\n",
            " iteration=5638 bias=47.619999999999095 loss=1.09106666666743\n",
            "\n",
            " iteration=5639 bias=47.619999999999095 loss=1.090600000000885\n",
            "\n",
            " iteration=5640 bias=47.62999999999909 loss=1.0809000000008693\n",
            "\n",
            " iteration=5641 bias=47.63999999999909 loss=1.0714000000008534\n",
            "\n",
            " iteration=5642 bias=47.64999999999909 loss=1.0621000000008376\n",
            "\n",
            " iteration=5643 bias=47.65999999999909 loss=1.0530000000008215\n",
            "\n",
            " iteration=5644 bias=47.669999999999085 loss=1.0441000000008056\n",
            "\n",
            " iteration=5645 bias=47.67999999999908 loss=1.0354000000007895\n",
            "\n",
            " iteration=5646 bias=47.68999999999908 loss=1.026900000000773\n",
            "\n",
            " iteration=5647 bias=47.69999999999908 loss=1.018600000000757\n",
            "\n",
            " iteration=5648 bias=47.70999999999908 loss=1.0105000000007405\n",
            "\n",
            " iteration=5649 bias=47.70999999999908 loss=1.0095666666675338\n",
            "\n",
            " iteration=5650 bias=47.719999999999075 loss=1.000266666667515\n",
            "\n",
            " iteration=5651 bias=47.72999999999907 loss=0.9911666666675013\n",
            "\n",
            " iteration=5652 bias=47.73999999999907 loss=0.9822666666674825\n",
            "\n",
            " iteration=5653 bias=47.74999999999907 loss=0.9735666666674686\n",
            "\n",
            " iteration=5654 bias=47.75999999999907 loss=0.9650666666674496\n",
            "\n",
            " iteration=5655 bias=47.769999999999065 loss=0.9567666666674356\n",
            "\n",
            " iteration=5656 bias=47.77999999999906 loss=0.9486666666674163\n",
            "\n",
            " iteration=5657 bias=47.78999999999906 loss=0.9407666666674022\n",
            "\n",
            " iteration=5658 bias=47.79999999999906 loss=0.9330666666673828\n",
            "\n",
            " iteration=5659 bias=47.79999999999906 loss=0.9316666666675116\n",
            "\n",
            " iteration=5660 bias=47.80999999999906 loss=0.9227666666674951\n",
            "\n",
            " iteration=5661 bias=47.819999999999055 loss=0.9140666666674785\n",
            "\n",
            " iteration=5662 bias=47.82999999999905 loss=0.9055666666674617\n",
            "\n",
            " iteration=5663 bias=47.83999999999905 loss=0.8972666666674449\n",
            "\n",
            " iteration=5664 bias=47.84999999999905 loss=0.8891666666674279\n",
            "\n",
            " iteration=5665 bias=47.85999999999905 loss=0.8812666666674112\n",
            "\n",
            " iteration=5666 bias=47.869999999999045 loss=0.873566666667394\n",
            "\n",
            " iteration=5667 bias=47.87999999999904 loss=0.866066666667377\n",
            "\n",
            " iteration=5668 bias=47.87999999999904 loss=0.8656000000008409\n",
            "\n",
            " iteration=5669 bias=47.88999999999904 loss=0.8569000000008217\n",
            "\n",
            " iteration=5670 bias=47.89999999999904 loss=0.8484000000008071\n",
            "\n",
            " iteration=5671 bias=47.90999999999904 loss=0.8401000000007878\n",
            "\n",
            " iteration=5672 bias=47.919999999999035 loss=0.8320000000007729\n",
            "\n",
            " iteration=5673 bias=47.92999999999903 loss=0.8241000000007533\n",
            "\n",
            " iteration=5674 bias=47.93999999999903 loss=0.8164000000007383\n",
            "\n",
            " iteration=5675 bias=47.94999999999903 loss=0.8089000000007186\n",
            "\n",
            " iteration=5676 bias=47.95999999999903 loss=0.8016000000007035\n",
            "\n",
            " iteration=5677 bias=47.969999999999025 loss=0.7945000000006837\n",
            "\n",
            " iteration=5678 bias=47.969999999999025 loss=0.7935666666674832\n",
            "\n",
            " iteration=5679 bias=47.97999999999902 loss=0.785266666667466\n",
            "\n",
            " iteration=5680 bias=47.98999999999902 loss=0.7771666666674486\n",
            "\n",
            " iteration=5681 bias=47.99999999999902 loss=0.7692666666674312\n",
            "\n",
            " iteration=5682 bias=48.00999999999902 loss=0.7615666666674136\n",
            "\n",
            " iteration=5683 bias=48.019999999999015 loss=0.7540666666673959\n",
            "\n",
            " iteration=5684 bias=48.02999999999901 loss=0.7467666666673782\n",
            "\n",
            " iteration=5685 bias=48.03999999999901 loss=0.7396666666673605\n",
            "\n",
            " iteration=5686 bias=48.04999999999901 loss=0.7327666666673426\n",
            "\n",
            " iteration=5687 bias=48.05999999999901 loss=0.7260666666673247\n",
            "\n",
            " iteration=5688 bias=48.05999999999901 loss=0.7246666666674576\n",
            "\n",
            " iteration=5689 bias=48.069999999999006 loss=0.716766666667442\n",
            "\n",
            " iteration=5690 bias=48.079999999999 loss=0.7090666666674221\n",
            "\n",
            " iteration=5691 bias=48.089999999999 loss=0.7015666666674063\n",
            "\n",
            " iteration=5692 bias=48.099999999999 loss=0.6942666666673863\n",
            "\n",
            " iteration=5693 bias=48.109999999999 loss=0.6871666666673703\n",
            "\n",
            " iteration=5694 bias=48.119999999998996 loss=0.6802666666673503\n",
            "\n",
            " iteration=5695 bias=48.129999999998994 loss=0.6735666666673342\n",
            "\n",
            " iteration=5696 bias=48.13999999999899 loss=0.6670666666673138\n",
            "\n",
            " iteration=5697 bias=48.13999999999899 loss=0.6666000000007841\n",
            "\n",
            " iteration=5698 bias=48.14999999999899 loss=0.658900000000766\n",
            "\n",
            " iteration=5699 bias=48.15999999999899 loss=0.6514000000007479\n",
            "\n",
            " iteration=5700 bias=48.169999999998986 loss=0.6441000000007298\n",
            "\n",
            " iteration=5701 bias=48.179999999998984 loss=0.6370000000007114\n",
            "\n",
            " iteration=5702 bias=48.18999999999898 loss=0.630100000000693\n",
            "\n",
            " iteration=5703 bias=48.19999999999898 loss=0.6234000000006746\n",
            "\n",
            " iteration=5704 bias=48.20999999999898 loss=0.6169000000006561\n",
            "\n",
            " iteration=5705 bias=48.219999999998976 loss=0.6106000000006375\n",
            "\n",
            " iteration=5706 bias=48.229999999998974 loss=0.6045000000006189\n",
            "\n",
            " iteration=5707 bias=48.229999999998974 loss=0.6035666666674229\n",
            "\n",
            " iteration=5708 bias=48.23999999999897 loss=0.5962666666674062\n",
            "\n",
            " iteration=5709 bias=48.24999999999897 loss=0.5891666666673858\n",
            "\n",
            " iteration=5710 bias=48.25999999999897 loss=0.5822666666673691\n",
            "\n",
            " iteration=5711 bias=48.269999999998966 loss=0.5755666666673486\n",
            "\n",
            " iteration=5712 bias=48.279999999998964 loss=0.5690666666673317\n",
            "\n",
            " iteration=5713 bias=48.28999999999896 loss=0.5627666666673109\n",
            "\n",
            " iteration=5714 bias=48.29999999999896 loss=0.5566666666672939\n",
            "\n",
            " iteration=5715 bias=48.30999999999896 loss=0.550766666667273\n",
            "\n",
            " iteration=5716 bias=48.319999999998956 loss=0.5450666666672558\n",
            "\n",
            " iteration=5717 bias=48.319999999998956 loss=0.5436666666673954\n",
            "\n",
            " iteration=5718 bias=48.329999999998954 loss=0.5367666666673765\n",
            "\n",
            " iteration=5719 bias=48.33999999999895 loss=0.5300666666673576\n",
            "\n",
            " iteration=5720 bias=48.34999999999895 loss=0.5235666666673385\n",
            "\n",
            " iteration=5721 bias=48.35999999999895 loss=0.5172666666673195\n",
            "\n",
            " iteration=5722 bias=48.369999999998946 loss=0.5111666666673003\n",
            "\n",
            " iteration=5723 bias=48.379999999998944 loss=0.505266666667281\n",
            "\n",
            " iteration=5724 bias=48.38999999999894 loss=0.49956666666726174\n",
            "\n",
            " iteration=5725 bias=48.39999999999894 loss=0.49406666666724225\n",
            "\n",
            " iteration=5726 bias=48.39999999999894 loss=0.4936000000007172\n",
            "\n",
            " iteration=5727 bias=48.40999999999894 loss=0.4869000000006998\n",
            "\n",
            " iteration=5728 bias=48.419999999998936 loss=0.4804000000006788\n",
            "\n",
            " iteration=5729 bias=48.429999999998934 loss=0.47410000000066105\n",
            "\n",
            " iteration=5730 bias=48.43999999999893 loss=0.46800000000064007\n",
            "\n",
            " iteration=5731 bias=48.44999999999893 loss=0.4621000000006222\n",
            "\n",
            " iteration=5732 bias=48.45999999999893 loss=0.45640000000060094\n",
            "\n",
            " iteration=5733 bias=48.469999999998926 loss=0.45090000000058295\n",
            "\n",
            " iteration=5734 bias=48.479999999998924 loss=0.44560000000056155\n",
            "\n",
            " iteration=5735 bias=48.48999999999892 loss=0.4405000000005434\n",
            "\n",
            " iteration=5736 bias=48.48999999999892 loss=0.4395666666673539\n",
            "\n",
            " iteration=5737 bias=48.49999999999892 loss=0.4332666666673343\n",
            "\n",
            " iteration=5738 bias=48.50999999999892 loss=0.4271666666673146\n",
            "\n",
            " iteration=5739 bias=48.519999999998916 loss=0.42126666666729484\n",
            "\n",
            " iteration=5740 bias=48.529999999998914 loss=0.4155666666672751\n",
            "\n",
            " iteration=5741 bias=48.53999999999891 loss=0.4100666666672552\n",
            "\n",
            " iteration=5742 bias=48.54999999999891 loss=0.40476666666723515\n",
            "\n",
            " iteration=5743 bias=48.55999999999891 loss=0.39966666666721506\n",
            "\n",
            " iteration=5744 bias=48.569999999998906 loss=0.39476666666719495\n",
            "\n",
            " iteration=5745 bias=48.579999999998904 loss=0.39006666666717466\n",
            "\n",
            " iteration=5746 bias=48.579999999998904 loss=0.3886666666673224\n",
            "\n",
            " iteration=5747 bias=48.5899999999989 loss=0.3827666666673009\n",
            "\n",
            " iteration=5748 bias=48.5999999999989 loss=0.3770666666672824\n",
            "\n",
            " iteration=5749 bias=48.6099999999989 loss=0.37156666666726074\n",
            "\n",
            " iteration=5750 bias=48.619999999998896 loss=0.366266666667242\n",
            "\n",
            " iteration=5751 bias=48.629999999998894 loss=0.36116666666722014\n",
            "\n",
            " iteration=5752 bias=48.63999999999889 loss=0.3562666666672012\n",
            "\n",
            " iteration=5753 bias=48.64999999999889 loss=0.3515666666671793\n",
            "\n",
            " iteration=5754 bias=48.65999999999889 loss=0.3470666666671602\n",
            "\n",
            " iteration=5755 bias=48.65999999999889 loss=0.34660000000064173\n",
            "\n",
            " iteration=5756 bias=48.669999999998886 loss=0.3409000000006213\n",
            "\n",
            " iteration=5757 bias=48.679999999998884 loss=0.33540000000060094\n",
            "\n",
            " iteration=5758 bias=48.68999999999888 loss=0.3301000000005805\n",
            "\n",
            " iteration=5759 bias=48.69999999999888 loss=0.3250000000005599\n",
            "\n",
            " iteration=5760 bias=48.70999999999888 loss=0.32010000000053923\n",
            "\n",
            " iteration=5761 bias=48.719999999998876 loss=0.31540000000051854\n",
            "\n",
            " iteration=5762 bias=48.729999999998874 loss=0.3109000000004977\n",
            "\n",
            " iteration=5763 bias=48.73999999999887 loss=0.3066000000004769\n",
            "\n",
            " iteration=5764 bias=48.74999999999887 loss=0.30250000000045585\n",
            "\n",
            " iteration=5765 bias=48.74999999999887 loss=0.30156666666727433\n",
            "\n",
            " iteration=5766 bias=48.75999999999887 loss=0.29626666666725227\n",
            "\n",
            " iteration=5767 bias=48.769999999998866 loss=0.29116666666723284\n",
            "\n",
            " iteration=5768 bias=48.779999999998864 loss=0.2862666666672106\n",
            "\n",
            " iteration=5769 bias=48.78999999999886 loss=0.281566666667191\n",
            "\n",
            " iteration=5770 bias=48.79999999999886 loss=0.27706666666716856\n",
            "\n",
            " iteration=5771 bias=48.80999999999886 loss=0.27276666666714877\n",
            "\n",
            " iteration=5772 bias=48.819999999998856 loss=0.26866666666712624\n",
            "\n",
            " iteration=5773 bias=48.829999999998854 loss=0.2647666666671063\n",
            "\n",
            " iteration=5774 bias=48.83999999999885 loss=0.26106666666708356\n",
            "\n",
            " iteration=5775 bias=48.83999999999885 loss=0.25966666666723764\n",
            "\n",
            " iteration=5776 bias=48.84999999999885 loss=0.25476666666721653\n",
            "\n",
            " iteration=5777 bias=48.85999999999885 loss=0.2500666666671953\n",
            "\n",
            " iteration=5778 bias=48.869999999998846 loss=0.245566666667174\n",
            "\n",
            " iteration=5779 bias=48.879999999998844 loss=0.2412666666671526\n",
            "\n",
            " iteration=5780 bias=48.88999999999884 loss=0.23716666666713113\n",
            "\n",
            " iteration=5781 bias=48.89999999999884 loss=0.2332666666671096\n",
            "\n",
            " iteration=5782 bias=48.90999999999884 loss=0.229566666667088\n",
            "\n",
            " iteration=5783 bias=48.919999999998836 loss=0.22606666666706632\n",
            "\n",
            " iteration=5784 bias=48.919999999998836 loss=0.22560000000055555\n",
            "\n",
            " iteration=5785 bias=48.929999999998834 loss=0.22090000000053292\n",
            "\n",
            " iteration=5786 bias=48.93999999999883 loss=0.21640000000051252\n",
            "\n",
            " iteration=5787 bias=48.94999999999883 loss=0.21210000000048976\n",
            "\n",
            " iteration=5788 bias=48.95999999999883 loss=0.20800000000046923\n",
            "\n",
            " iteration=5789 bias=48.96999999999883 loss=0.20410000000044626\n",
            "\n",
            " iteration=5790 bias=48.979999999998824 loss=0.2004000000004255\n",
            "\n",
            " iteration=5791 bias=48.98999999999882 loss=0.19690000000040242\n",
            "\n",
            " iteration=5792 bias=48.99999999999882 loss=0.19360000000038155\n",
            "\n",
            " iteration=5793 bias=49.00999999999882 loss=0.1905000000003583\n",
            "\n",
            " iteration=5794 bias=49.00999999999882 loss=0.18956666666718314\n",
            "\n",
            " iteration=5795 bias=49.01999999999882 loss=0.1852666666671613\n",
            "\n",
            " iteration=5796 bias=49.029999999998815 loss=0.18116666666713932\n",
            "\n",
            " iteration=5797 bias=49.03999999999881 loss=0.1772666666671173\n",
            "\n",
            " iteration=5798 bias=49.04999999999881 loss=0.1735666666670952\n",
            "\n",
            " iteration=5799 bias=49.05999999999881 loss=0.17006666666707296\n",
            "\n",
            " iteration=5800 bias=49.06999999999881 loss=0.16676666666705073\n",
            "\n",
            " iteration=5801 bias=49.079999999998805 loss=0.16366666666702834\n",
            "\n",
            " iteration=5802 bias=49.0899999999988 loss=0.1607666666670059\n",
            "\n",
            " iteration=5803 bias=49.0999999999988 loss=0.1580666666669834\n",
            "\n",
            " iteration=5804 bias=49.0999999999988 loss=0.1566666666671428\n",
            "\n",
            " iteration=5805 bias=49.1099999999988 loss=0.15276666666712146\n",
            "\n",
            " iteration=5806 bias=49.1199999999988 loss=0.14906666666709814\n",
            "\n",
            " iteration=5807 bias=49.129999999998795 loss=0.14556666666707666\n",
            "\n",
            " iteration=5808 bias=49.13999999999879 loss=0.14226666666705318\n",
            "\n",
            " iteration=5809 bias=49.14999999999879 loss=0.1391666666670315\n",
            "\n",
            " iteration=5810 bias=49.15999999999879 loss=0.1362666666670079\n",
            "\n",
            " iteration=5811 bias=49.16999999999879 loss=0.13356666666698608\n",
            "\n",
            " iteration=5812 bias=49.179999999998785 loss=0.1310666666669623\n",
            "\n",
            " iteration=5813 bias=49.179999999998785 loss=0.13060000000045793\n",
            "\n",
            " iteration=5814 bias=49.18999999999878 loss=0.1269000000004353\n",
            "\n",
            " iteration=5815 bias=49.19999999999878 loss=0.12340000000041261\n",
            "\n",
            " iteration=5816 bias=49.20999999999878 loss=0.12010000000038983\n",
            "\n",
            " iteration=5817 bias=49.21999999999878 loss=0.11700000000036698\n",
            "\n",
            " iteration=5818 bias=49.229999999998775 loss=0.11410000000034405\n",
            "\n",
            " iteration=5819 bias=49.23999999999877 loss=0.11140000000032103\n",
            "\n",
            " iteration=5820 bias=49.24999999999877 loss=0.10890000000029794\n",
            "\n",
            " iteration=5821 bias=49.25999999999877 loss=0.10660000000027477\n",
            "\n",
            " iteration=5822 bias=49.26999999999877 loss=0.1045000000002515\n",
            "\n",
            " iteration=5823 bias=49.26999999999877 loss=0.1035666666670819\n",
            "\n",
            " iteration=5824 bias=49.279999999998765 loss=0.10026666666705963\n",
            "\n",
            " iteration=5825 bias=49.28999999999876 loss=0.09716666666703577\n",
            "\n",
            " iteration=5826 bias=49.29999999999876 loss=0.09426666666701333\n",
            "\n",
            " iteration=5827 bias=49.30999999999876 loss=0.09156666666698933\n",
            "\n",
            " iteration=5828 bias=49.31999999999876 loss=0.08906666666696676\n",
            "\n",
            " iteration=5829 bias=49.329999999998755 loss=0.08676666666694256\n",
            "\n",
            " iteration=5830 bias=49.33999999999875 loss=0.08466666666691984\n",
            "\n",
            " iteration=5831 bias=49.34999999999875 loss=0.08276666666689549\n",
            "\n",
            " iteration=5832 bias=49.35999999999875 loss=0.08106666666687258\n",
            "\n",
            " iteration=5833 bias=49.35999999999875 loss=0.07966666666703855\n",
            "\n",
            " iteration=5834 bias=49.36999999999875 loss=0.07676666666701512\n",
            "\n",
            " iteration=5835 bias=49.379999999998745 loss=0.07406666666699162\n",
            "\n",
            " iteration=5836 bias=49.38999999999874 loss=0.07156666666696802\n",
            "\n",
            " iteration=5837 bias=49.39999999999874 loss=0.06926666666694435\n",
            "\n",
            " iteration=5838 bias=49.40999999999874 loss=0.0671666666669206\n",
            "\n",
            " iteration=5839 bias=49.41999999999874 loss=0.06526666666689677\n",
            "\n",
            " iteration=5840 bias=49.429999999998735 loss=0.06356666666687287\n",
            "\n",
            " iteration=5841 bias=49.43999999999873 loss=0.06206666666684888\n",
            "\n",
            " iteration=5842 bias=49.43999999999873 loss=0.06160000000035023\n",
            "\n",
            " iteration=5843 bias=49.44999999999873 loss=0.058900000000327045\n",
            "\n",
            " iteration=5844 bias=49.45999999999873 loss=0.05640000000030263\n",
            "\n",
            " iteration=5845 bias=49.46999999999873 loss=0.05410000000027928\n",
            "\n",
            " iteration=5846 bias=49.479999999998725 loss=0.05200000000025471\n",
            "\n",
            " iteration=5847 bias=49.48999999999872 loss=0.0501000000002312\n",
            "\n",
            " iteration=5848 bias=49.49999999999872 loss=0.04840000000020648\n",
            "\n",
            " iteration=5849 bias=49.50999999999872 loss=0.046900000000182816\n",
            "\n",
            " iteration=5850 bias=49.51999999999872 loss=0.045600000000157924\n",
            "\n",
            " iteration=5851 bias=49.529999999998715 loss=0.0445000000001341\n",
            "\n",
            " iteration=5852 bias=49.529999999998715 loss=0.043566666666971045\n",
            "\n",
            " iteration=5853 bias=49.53999999999871 loss=0.04126666666694687\n",
            "\n",
            " iteration=5854 bias=49.54999999999871 loss=0.039166666666922624\n",
            "\n",
            " iteration=5855 bias=49.55999999999871 loss=0.0372666666668983\n",
            "\n",
            " iteration=5856 bias=49.56999999999871 loss=0.03556666666687389\n",
            "\n",
            " iteration=5857 bias=49.579999999998705 loss=0.03406666666684941\n",
            "\n",
            " iteration=5858 bias=49.5899999999987 loss=0.032766666666824845\n",
            "\n",
            " iteration=5859 bias=49.5999999999987 loss=0.0316666666668002\n",
            "\n",
            " iteration=5860 bias=49.6099999999987 loss=0.03076666666677548\n",
            "\n",
            " iteration=5861 bias=49.6199999999987 loss=0.030066666666750674\n",
            "\n",
            " iteration=5862 bias=49.6199999999987 loss=0.02866666666692368\n",
            "\n",
            " iteration=5863 bias=49.629999999998695 loss=0.026766666666898725\n",
            "\n",
            " iteration=5864 bias=49.63999999999869 loss=0.02506666666687445\n",
            "\n",
            " iteration=5865 bias=49.64999999999869 loss=0.02356666666684934\n",
            "\n",
            " iteration=5866 bias=49.65999999999869 loss=0.022266666666824905\n",
            "\n",
            " iteration=5867 bias=49.66999999999869 loss=0.02116666666679963\n",
            "\n",
            " iteration=5868 bias=49.679999999998685 loss=0.020266666666775037\n",
            "\n",
            " iteration=5869 bias=49.68999999999868 loss=0.019566666666749607\n",
            "\n",
            " iteration=5870 bias=49.69999999999868 loss=0.019066666666724852\n",
            "\n",
            " iteration=5871 bias=49.69999999999868 loss=0.01860000000023276\n",
            "\n",
            " iteration=5872 bias=49.70999999999868 loss=0.01690000000020786\n",
            "\n",
            " iteration=5873 bias=49.71999999999868 loss=0.015400000000182879\n",
            "\n",
            " iteration=5874 bias=49.729999999998675 loss=0.014100000000157814\n",
            "\n",
            " iteration=5875 bias=49.73999999999867 loss=0.013000000000132675\n",
            "\n",
            " iteration=5876 bias=49.74999999999867 loss=0.01210000000010745\n",
            "\n",
            " iteration=5877 bias=49.75999999999867 loss=0.01140000000008215\n",
            "\n",
            " iteration=5878 bias=49.76999999999867 loss=0.010900000000056769\n",
            "\n",
            " iteration=5879 bias=49.779999999998665 loss=0.010600000000031308\n",
            "\n",
            " iteration=5880 bias=49.78999999999866 loss=0.010500000000005769\n",
            "\n",
            " iteration=5881 bias=49.78999999999866 loss=0.009566666666849554\n",
            "\n",
            " iteration=5882 bias=49.79999999999866 loss=0.008266666666824055\n",
            "\n",
            " iteration=5883 bias=49.80999999999866 loss=0.0071666666667988535\n",
            "\n",
            " iteration=5884 bias=49.81999999999866 loss=0.006266666666773194\n",
            "\n",
            " iteration=5885 bias=49.829999999998655 loss=0.0055666666667478345\n",
            "\n",
            " iteration=5886 bias=49.83999999999865 loss=0.005066666666722015\n",
            "\n",
            " iteration=5887 bias=49.84999999999865 loss=0.004766666666696496\n",
            "\n",
            " iteration=5888 bias=49.85999999999865 loss=0.004666666666670517\n",
            "\n",
            "w=-2.4799999999999915, b=49.85999999999865\n",
            "Prediction: x=8, Y=>30.019999999998717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showHistory(X,Y, history,15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "ZC4rlg-Cah8r",
        "outputId": "4665c524-1b17-481b-ee27-17eeec00784b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a69ba9266c6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshowHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-630e9a438d8e>\u001b[0m in \u001b[0;36mshowHistory\u001b[0;34m(X, Y, historyW, step)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mupdateLineL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mupdateLineL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-630e9a438d8e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshowHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtheLine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mupdateLineL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0mupdateLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheLine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistoryW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-97795ef9b1c6>\u001b[0m in \u001b[0;36mupdateLine\u001b[0;34m(X1, Y1, theLine)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtheLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtheLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#plt.pause(0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m                 )\n\u001b[1;32m   2341\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_draw_disabled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3141\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3064\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3065\u001b[0m             renderer, self, artists, self.figure.suppressComposite)\n\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         \u001b[0;31m# Shift label away from axes to avoid overlapping ticklabels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    299\u001b[0m         for artist in [self.gridline, self.tick1line, self.tick2line,\n\u001b[1;32m    300\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Needed for contains() method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subslice\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0minterpolation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_LOOKUP_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drawstyle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         self._path = Path(np.asarray(xy).T,\n\u001b[0m\u001b[1;32m    692\u001b[0m                           _interpolation_steps=interpolation_steps)\n\u001b[1;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformed_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAHSCAYAAAA9u8W4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABobklEQVR4nO3deVhUZf8G8HsGZNhkUQREUdwVd0WIFJdekt7M1NJcEtDSFq1UytQsTS01S7PStCy3yi130zTTcN83XEBTwR0EZFGQ/fn9wW/Oy8AAM8OZGQbvz3Wd65oZznnOdxhmzs05zzyPQgghQERERERGpzR3AURERERPCgYvIiIiIhNh8CIiIiIyEQYvIiIiIhNh8CIiIiIyEQYvIiIiIhNh8CIiIiIyEQYvIiIiIhNh8CIiIiIyEQYvIiIiIhN5ooLX/v370bt3b3h5eUGhUGDz5s3lbhMZGYkOHTpApVKhcePGWL58udHrJCIioqrJpMErKysLWVlZptylhoyMDLRt2xYLFy7Uaf3Y2Fj06tULPXr0wNmzZzF27FiMGDECu3btMnKlREREVBUp5J4k+8GDBzh48CBOnjyJc+fOIS4uDrdu3UJ6ejrUu1IoFHByckK9evXg4+ODNm3awM/PD507d0bNmjXlLKdUCoUCmzZtQt++fUtdZ8KECdi+fTsuXLggPTZo0CCkpqZi586dJqiSiIiIqhJrORq5fv06Vq1ahT/++AOnTp1CQUGB9DNtuU4IgdTUVKSmpuL8+fPYtm0bgMIw1LFjR/Tq1QtDhgxB48aN5SjPYEeOHEFwcLDGYyEhIRg7dmyp22RnZyM7O1u6X1BQgAcPHqBmzZpQKBTGKpWIiIhkJITAw4cP4eXlBaVSxguEwkA5OTli5cqVIjAwUCiVSmlRKBRCoVBoPKbLom27gIAAsXLlSpGTk2NomaUCIDZt2lTmOk2aNBEzZ87UeGz79u0CgMjMzNS6zdSpUwUALly4cOHChUsVWG7duiVX9BBCCKH3Ga/MzEx8++23+Oabb3D//n0AgBCixNkcUeRMl42NDRwcHGBvbw8hBB4/foyMjAzk5OSUuh8hBE6cOIFhw4bhww8/xHvvvYf33nsPDg4O+pZsUpMmTUJERIR0Py0tDfXq1cOtW7fg5ORkxsqIiIhIV+np6fD29kb16tVlbVfn4JWXl4dvv/0WX3zxBZKSkqSwpQ5YQgg4OTmhS5cu6NixI1q3bo3mzZvDy8sLNWrU0NpmcnIy7t69i5iYGJw/fx6nTp3CoUOHkJ6eLrWpUCiQkJCAjz/+GF9//TUmTpyId999F9WqVZPh6ZfN09MTCQkJGo8lJCTAyckJdnZ2WrdRqVRQqVQlHndycmLwIiIisjBydxPSKXj98ccfeP/993H16lWNs1tCCPj6+qJfv37o06cPOnTooNd10Jo1a6JmzZpo3bo1BgwYAKCwT9Tp06exZcsWbNq0CZcuXZLWT0pKwvjx47F48WJ8/fXX6NWrlz7PVW+BgYHYsWOHxmO7d+9GYGCgUfdLREREVZNO32pUKpUaZ7ecnJwwZMgQjBgxAh06dDBqgWfOnMGSJUuwevVqpKWlSXUolUrk5eXp1dajR49w9epVAED79u0xb9489OjRAzVq1EC9evUwadIk3LlzBytXrgRQOJxEq1atMHr0aLz22mvYu3cv3nvvPWzfvh0hISE67TM9PR3Ozs5IS0vjGS8iIiILYazjt87BCwDq1KmDMWPG4M0335T9mmd5Hj16hMWLF+Obb77BnTt3oFAokJ+fr1cbkZGR6NGjR4nHw8PDsXz5cgwbNgxxcXGIjIzU2GbcuHG4dOkS6tati08++QTDhg3TeZ8MXkRERJbHrMHL3d0dkydPxttvvw0bGxvZdm6InJwcfP/995g1a1aJ/leVEYMXERGR5TFr8Hr06BEcHR1l26kcKmNN2jB4ERERWR5jHb916glfGQNOZayJiIiIqCxP1CTZRERERObE4EVERERkIgxeRERERCbC4EVERERkIgxeRERERCai9yTZ+oiKisKff/6JM2fO4ObNm0hPT8fjx4+hwwgWGhQKBa5du2akKomIiIhMwyjB6/DhwxgzZgxOnz6t8bi+gUtN7gkqiYiIiMxB9uD17bffIiIiAkIIKWipg5MhAcrQsEZERERU2cgavLZu3YqxY8cCKAxZ6gmthRCoVq0aXFxcYG9vL+cuiYiIiCyGrMGraOgSQqBWrVoYN24c+vTpg2bNmkmTbRMRERE9iWQLXseOHUNcXJwUulq3bo09e/bAzc1Nrl0QERERWTTZTkFFRUUBKOyTpVAo8PPPPzN0ERERERUhW/BKSkqSbtetWxd+fn5yNU1ERERUJcgWvNSd5hUKBWrXri1Xs0RERERVhmzBq2nTptLttLQ0uZolIiIiqjJkC15dunSBra0thBC4du0awxcRERFRMbIFr+rVq2Po0KEAgPz8fKxcuVKupomIiIiqBFkH1vrss8/g4eEBAPj0009x5coVOZsnIiIismiyBi93d3ds3boVTk5OSElJQY8ePbBnzx45d0FERERksRTCCJMhxsTEYMCAAbh48SIUCgW6dOmC/v37o0OHDqhVqxZsbW31brNevXpyl2kS6enpcHZ2RlpaGpycnMxdDhEREenAWMdvowQvALh79y6effZZREdHGzQ5dlEKhQJ5eXkyVWZaDF5ERESWx1jHb6NMnjh79mw0a9YMMTExGhNlV2QhIiIisnSyTpIthMCQIUOwbt06aeog4H+TZhMRERE9yWQNXl999RXWrl0LQDNseXh4oGXLlqhZs6Y0wj0RERHRk0a24JWVlYVZs2ZpXFoMDg7GZ599Bn9/f7l2Q0RERGSxZAtekZGRSE1NhUKhgEKhwMsvv4y1a9dWuGM9ERERUVUhW+f6mJgYAJD6ds2fP5+hi4iIiKgI2YJXdnY2gMK+XY0bN4aXl5dcTRMRERFVCbIFr6JBy8XFRa5miYiIiKoM2YJXw4YNpdv379+Xq1kiIiKiKkO24BUYGIg6depACIEbN27g1q1bcjVNREREVCXIFryUSiVGjBgh3Z87d65cTRMRERFVCbJOGTRx4kS0a9cOQggsXLgQGzdulLN5IiIiIosma/BSqVTYuXMnOnbsiPz8fAwcOBCTJ09Genq6nLshIiIiskgKIeMkiitXrgQAPH78GF988QXi4uKgUCjg4OCA4OBgdOzYEbVq1YKtra3ebYeFhclVpkkZa3ZzIiIiMh5jHb9lDV5KpbLEoKnq5is6mGp+fn6FtjcXBi8iIiLLY6zjt6yTZKupR68HSgYufXKeet5HjoBPREREVYHswUsdrOQ4kSbjyTgiIiIis5M1eC1btkzO5oiIiIiqFFmDV3h4uJzNEREREVUpsg4nQURERESlY/AiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiIT0Sl4/fnnn8auQ2+VsSYiIiKisugUvHr16oUePXrg8OHDxq6nXIcOHUL37t3xwgsvmLsUIiIiIr3ofKlx//79CAoKQlBQELZt22bSUeWFENiyZQuCgoLQtWtX7N+/32T7JiIiIpKLTgOourm5ISkpCQBw+PBh9O3bF3Xr1sVrr72GoUOHolGjRkYp7urVq/jll1+wbNky3LlzB8D/phGqVauWUfZJREREZCwKocOpq7S0NHzyySdYvHgx8vLy/rfx/09e3apVK/Tp0wc9evTA008/DZVKZVAxWVlZOHLkCP755x9s3rwZFy9eBPC/SbeFELC2tsbbb7+N6dOnw9nZ2aD9mJKxZjcnIiIi4zHW8Vun4KUWExODKVOmYMOGDRphCPhfCKtWrRp8fX3RqlUrNGvWDHXr1kXt2rXh6OgIOzs7CCGQlZWFhw8f4t69e7h9+zYuX76M8+fPIyYmBrm5uQCg0a56X/3798e0adPQvHlz2X4BxsbgRUREZHkqRfBSO3/+PL744gv8/vvvyM3NlUJX0abUj+lK27ZCCFSrVg2vvPIKPvzwQ7Ru3VrfUs2OwYuIiMjyVKrgpRYfH48lS5bgt99+w5UrV/7XaJHQVV7zpa3bpEkThIaGYsSIEfD09DS0RLNj8CIiIrI8lTJ4FXX69Gn88ccf2LVrF06cOKHRF0wX1tbW6NSpE0JCQtCrVy907NhRjrLMjsGLiIjI8lT64FVUdnY2oqKiEBUVhdjYWNy6dQtpaWnIzMwEANjb28PFxQXe3t7w8fFBmzZt0KZNG4M75VdmDF5ERESWx1jHb52Gk9CXSqVCp06d0KlTJ2M0T0RERGSROFcjERERkYkweBERERGZCIMXERERkYkweBERERGZCIMXERERkYk8ccFr4cKF8PHxga2tLQICAnD8+PEy158/fz6aNWsGOzs7eHt7Y9y4ccjKyjJRtURERFSVPFHBa+3atYiIiMDUqVNx+vRptG3bFiEhIbh//77W9VetWoWJEydi6tSpiI6Oxs8//4y1a9fio48+MnHlREREVBU8UcFr3rx5GDlyJIYPHw5fX18sXrwY9vb2WLp0qdb1Dx8+jM6dO2PIkCHw8fFBz549MXjw4HLPkhERERFp88QEr5ycHJw6dQrBwcHSY0qlEsHBwThy5IjWbZ5++mmcOnVKClrXr1/Hjh078Pzzz5e6n+zsbKSnp2ssRERERICRRq6vjJKSkpCfnw8PDw+Nxz08PBATE6N1myFDhiApKQldunSBEAJ5eXl46623yrzUOGvWLEybNk3W2omIiKhqeGLOeBkiMjISM2fOxPfff4/Tp09j48aN2L59O2bMmFHqNpMmTUJaWpq03Lp1y4QVExERUWX2xJzxcnNzg5WVFRISEjQeT0hIgKenp9ZtPvnkE4SGhmLEiBEAgNatWyMjIwNvvPEGJk+eDKWyZG5VqVRVcrJvIiIiqrgn5oyXjY0NOnbsiD179kiPFRQUYM+ePQgMDNS6TWZmZolwZWVlBQAQQhivWCIiIqqSnpgzXgAQERGB8PBw+Pn5wd/fH/Pnz0dGRgaGDx8OAAgLC0OdOnUwa9YsAEDv3r0xb948tG/fHgEBAbh69So++eQT9O7dWwpgRERERLp6ooLXwIEDkZiYiClTpiA+Ph7t2rXDzp07pQ73N2/e1DjD9fHHH0OhUODjjz/GnTt3UKtWLfTu3Ruff/65uZ4CERERWTCF4DUzo0pPT4ezszPS0tLg5ORk7nKIiIhIB8Y6fj8xfbyIiIiIzM3klxofPnyItLQ0FBQUwNPTEzY2NqYugYiIiMgsjB689u7diw0bNuDAgQOIiYlBfn6+9LPdu3fjmWeeKbHNqVOnkJGRAQBwcXFBmzZtjF0mERERkdEZLXgdPXoUb7/9NqKiogCUHH5BoVCUuu3atWsxd+5cAICTkxPu3bsHW1tbY5VKREREZBJG6eP1zTffoFu3boiKitIrcKm99957sLKyghAC6enp2LBhgzHKJCIiIjIp2YPX0qVLMW7cOOTm5kqPWVlZISAgAAMGDNBp4NG6detqXILcunWr3GUSERERmZyswSsuLg6jRo2CQqGQlvHjxyM+Ph5HjhzB2rVrAeh21uvll18GUHiJsuho80RERESWStY+XlOmTEFOTg4AQKlUYtWqVXjllVcMaisoKEi6nZKSgmvXrqFRo0ay1ElERERkDrKd8crJycHGjRulM11vvPGGwaELAJo2bQp7e3vpfnR0tBxlEhEREZmNbMHr0KFDyMzMlPpwjR8/vkLtKZVK1K5dW7p/586dCrVHREREZG6yBa/Y2Fjpdp06ddCgQYMKt+ni4iLdTk9Pr3B7REREROYkW/BKTEwEUNhxvuiZKrkUFBTI3iYRERGRKckWvFQqlXRb3cG+opKTk6XbNWvWlKVNIiIiInORLXi5u7sDKBz+QY7+WKmpqbh586Y09IS6fSIiIiJLJVvwaty4sXQ7OTkZMTExFWpv165dKCgokDrrd+rUqULtEREREZmbbMHLz88PNWrUkM5QLVmypELtffXVV9Ltpk2bGqXfGBEREZEpyRa8lEol+vTpAyEEhBBYuHAhzpw5Y1BbM2bMwKlTpwAUdtYPDQ2Vq0wiIiIis5F1yqApU6bAxsYGCoUCOTk5eO6553Ds2DGdt8/Pz8ekSZPw6aefSmfOXFxc8O6778pZJhEREZFZyBq86tevj48//hhCCCgUCiQmJqJLly4IDQ3FX3/9JX1LUd1vKz8/H0lJSTh69ChmzpyJRo0aYc6cOdJZM4VCgW+++QbVq1eXs0wiIiIis1AIdQqS0bBhw7By5UooFAopQKkV3V3xybLVP1NvFxERodHXyxKlp6fD2dkZaWlpcHJyMnc5REREpANjHb9lPeOltnTpUnzyySclApc6hKkX9WNFfwYUBq9Zs2ZZfOgiIiIiKsoowUupVGLatGnYv38/evbsidJOqqkDmJoQAj169MD+/fsxYcIEY5RGREREZDZGudRYXExMDP78808cOHAA0dHRSE5ORmpqKuzt7eHm5oYGDRqgR48eeO6559ChQwdjl2NSvNRIRERkeYx1/DZJ8HqSMXgRERFZHovq40VEREREJTF4EREREZmIrMFr48aNyM3NlbNJIiIioipD1uDVv39/1K5dG++++y5OnDghZ9NEREREFk/2S40pKSn4/vvv8dRTT8HX1xdz5szB3bt35d4NERERkcUxWh8vIQRiYmIwadIk1K9fHyEhIVi9ejWysrKMtUsiIiKiSk3W4BUeHg4HB4cSU//k5+fj77//xtChQ+Hp6YmRI0fiwIEDcu6aiIiIqNKTfRyvzMxMbNiwAb/88gv27t2LgoICaXT6ooEMAHx8fBAeHo7Q0FA0aNBAzjIqDY7jRUREZHkscgDVO3fu4JdffsEvv/yC6Ojowh2WEsK6dOmCYcOGYcCAAXB0dDRWSSbH4EVERGR5LDJ4FXXy5EksX74ca9euRXJycuHOi4Qw9W07Ozv069cPYWFhCA4O1pjL0RIxeBEREVkeiw9earm5udi+fTtWrlyJ7du3Izc3t9SzYF5eXggNDUVoaChatGhhyjJlw+BFRERkeapM8CrqwYMHWLVqFVauXImTJ08WFqQlhCkUCuTl5ZmrzAph8CIiIrI8VXKuxho1auCdd97B8ePHcenSJXz44YeoU6eOdOlR/a1IzuNNREREVUGlmauxefPmmD17Nm7cuIGFCxdCpVKZuyQiIiIiWVmbuwC1tLQ0rF27FitXrsSRI0fMXQ4RERGR7MwavAoKCvDnn39i5cqV2LZtG7Kzs0t0sCciIiKqKswSvM6ePYuVK1di9erVuH//PgCUGO1eCAFbW1v07dsX4eHh5iiTiIiISFYmC14JCQn49ddfsXLlSly4cAFAyW8uqgNX586dER4ejldeeYXfBCQiIqIqw6jBKzs7G5s2bcLKlSvx999/Iz8/v9SwVb9+fYSFhSEsLAyNGjUyZllEREREZmGU4HXgwAGsXLkSv//+Ox4+fAhA+6VER0dHvPzyywgPD0f37t2NUQoRERFRpSFr8Jo6dSp+/fVXxMXFAdB+KREAnnnmGYSHh+Pll1+Gvb29nCUQERERVVqyjlyvVCqlgFV8BPomTZogPDwcoaGh8Pb2lmuXlR5HriciIrI8xjp+G62PlxACzs7OGDhwIMLDwxEYGGisXRERERFZBNmDl1KpRM+ePREeHo4+ffpwBHoiIiKi/ydr8Pryyy/x6quvwtPTU85miYiIiKoEWYPX+++/L2dzRERERFVKpZkkm4iIiKiqY/AiIiIiMhEGLyIiIiITMclcjdnZ2bhw4QKSkpKQmpqK7OxsvdsICwszQmVEREREpmO04JWZmYlffvkFy5Ytw5kzZ5CXl1eh9hi8iIiIyNIZJXjt27cPQ4cOxd27dwH8b/R6fRUfBZ+IiIjIkskevHbu3InevXujoKCgRGgqert4GCsertQTaRMRERFVFbIGr3v37mHw4MHIz8+XglTDhg0xYMAANGjQAG+++ab0+Pjx49GoUSM8ePAAFy9exL59+3D79m3p576+voiIiICVlZWcJRIRERGZjazBa+7cuUhLS5PC04gRI7Bw4UJUq1YNAPDmm29K64aEhOCZZ56R7gshsGXLFnzwwQe4fv06oqOj8euvv2Lz5s2cXJqIiIiqBNmGkxBCYNmyZVLo8vf3x48//iiFrvIoFAr07dsX586dQ3BwMIQQ2LdvH15++WW5SiQiIiIyK9mC14ULF5CSkiL1y/roo48MasfBwQFbtmxB48aNIYTA3r17sXjxYrnKJCIiIjIb2YLX+fPnpdvW1tYICQkpc/38/PxSf2ZnZ4eZM2cCKDyT9uWXX8pTJBEREZEZyRa8kpOTARReMmzQoAFsbGxKrFP0m4uPHz8us73evXvD3t4eABAXF6cR7IiIiIgskWzB6+HDh9JtV1dXres4ODhIlyLT09PLbE+lUsHHx0e6f/bs2QrXCAALFy6Ej48PbG1tERAQgOPHj5e5fmpqKkaPHo3atWtDpVKhadOm2LFjhyy1EBER0ZNFtm81Ojg4SLdzc3O1rlO9enU8evQIAHDr1q1y23R0dJRux8fHV7BCYO3atYiIiMDixYsREBCA+fPnIyQkBJcvX4a7u3uJ9XNycvDss8/C3d0d69evR506dXDjxg24uLhUuBYiIiJ68sgWvGrVqiXdLu1sVr169XDv3j0AwLlz58ptU70uUHafMF3NmzcPI0eOxPDhwwEAixcvxvbt27F06VJMnDixxPpLly7FgwcPcPjwYenbmUXPwhERERHpQ7ZLjS1atABQ2Bn+1q1bKCgoKLFO27ZtpXUiIyPLnL8xOjoat27dkvqF1axZs0L15eTk4NSpUwgODpYeUyqVCA4OxpEjR7Rus3XrVgQGBmL06NHw8PBAq1atMHPmzDJDYHZ2NtLT0zUWIiIiIkDG4OXr6wuVSgWgMORcvny5xDo9evSQbicmJmLRokVa2xJCYPz48dJtAGjTpk2F6ktKSkJ+fj48PDw0Hvfw8Cj1Mub169exfv165OfnY8eOHfjkk08wd+5cfPbZZ6XuZ9asWXB2dpYWb2/vCtVNREREVYdswUulUiEwMFC6v3v37hLrvPjii6hevbo0+fX48eMxZ84cpKWlSevExMSgT58+2LFjh3S2y9PTE506dZKrVJ0VFBTA3d0dP/74Izp27IiBAwdi8uTJZY4rNmnSJKSlpUmLLn3ZiIiI6MkgW/ACgF69ekm3t2zZUuLndnZ2+Oijj6TJs3NycjBp0iS4ubnBy8sLbm5uaNmyJbZv3w4A0noTJkyAUlmxUt3c3GBlZYWEhASNxxMSEuDp6al1m9q1a6Np06Ya80W2aNEC8fHxyMnJ0bqNSqWCk5OTxkJEREQEyBy8Bg0aJJ3NioyMRHR0dIl13n//ffTo0UMKVUII5OfnIz4+Hg8ePJAuLarPdr3wwgt47733KlybjY0NOnbsiD179kiPFRQUYM+ePRpn6orq3Lkzrl69qtFf7cqVK6hdu7bWccqIiIiIyiJr8KpTpw7Onj2LEydO4Pjx43BzcyuxjrW1NbZv347w8HCNxxUKhRS21KFs1KhRWL9+vWz1RUREYMmSJVixYgWio6Px9ttvIyMjQ/qWY1hYGCZNmiSt//bbb+PBgwcYM2YMrly5gu3bt2PmzJkYPXq0bDURERHRk0O24STUWrduXe46tra2WLZsGcaOHYt169bh6NGjSEhIgBACnp6eePrppzF06FA0a9ZM1toGDhyIxMRETJkyBfHx8WjXrh127twpdbi/efOmxiVNb29v7Nq1C+PGjUObNm1Qp04djBkzBhMmTJC1LiIiInoyKIT62h4ZRXp6OpydnZGWlsb+XkRERBbCWMdvWS81EhEREVHpGLyIiIiITITBi4iIiMhEDOpcv337diQnJ0v3fX194efnV+FiTp48iUuXLkn33d3d8dxzz1W4XSIiIqLKQO/gdfr0abz44ovSfU9PT5w8eVKWYnx8fDBo0CDExsYCAKysrBAVFYXmzZvL0j4RERGROel9qfH999+HEAJCCFhbW2P9+vWoXbu2LMW4ublh7dq1sLa2hhACeXl50pyNRERERJZOr+B1/vx57Nu3TxrsdMSIEaWO+m6ojh07IiIiQrq/Y8cO/Pvvv7Lug4iIiMgc9ApeK1asAFA4sryDgwOmTp1qlKImTZoEZ2dnaST75cuXG2U/RERERKakV/DavHkzgMLpfQYNGgR3d3dj1AQnJycMGjRImrdRzmmDiIiIiMxF5+CVnJyM69evS2ehevfubbSiirYvhMDVq1eRkpJi1P0RERERGZvOwUv9zUUhBJRKJZ599lmjFQUAzzzzjMa8iXJ9c5KIiIjIXHQOXvfu3ZNu16xZE7a2tkYpSM3W1ha1atWS7t+9e9eo+yMiIiIyNp2DV2pqKoDC/l1yDR9RHk9PT+k2LzUSERGRpdM5eGVkZEi3raysjFJMcUX3k5mZaZJ9EhERERmLzsHL3t4eQGEfr/v37xutoKISExOl23Z2dibZJxEREZGx6By8iva3SkxMRF5enlEKUsvNzUVCQoL0LUo3Nzej7o+IiIjI2HQOXo0aNZJu5+TkYP/+/UYpSO3gwYPIycmRxvIqun8iIiIiS6Rz8Grfvj2qVasmnYHaunWr0YoCgC1btki3rays0L59e6Puj4iIiMjYdA5etra2CAoKkibIXrJkCe7cuWOUou7evYslS5ZIc0J26dKFfbyIiIjI4uk1ZdCgQYMAFA4pkZWVhffee88oRb333nt4/PixdJlxyJAhRtkPERERkSnpFbxCQ0Ph4eEBoPDbjZs3b8Y777wja0FjxozBxo0bpUuatWrVQmhoqKz7ICIiIjIHvYKXSqXCrFmzIISAQqGAEAKLFi1C7969KzyyfHx8PPr06YMFCxZIbSsUCsycORMqlapCbRMRERFVBnoFLwAYNmwY+vTpoxG+duzYgZYtW+LDDz/E5cuX9Wrv33//xYQJE9CyZUv88ccf0uVFhUKBF154Aa+99pq+JRIRERFVSgqhTjp6ePToEYKDg3H8+HEpfAGQLg82bdoUfn5+aN++Pdzd3eHi4gIHBwdkZGQgLS0N9+/fx5kzZ3Dy5EkpqBVtQwiBTp06Yc+ePXB0dJTruZpFeno6nJ2dkZaWBicnJ3OXQ0RERDow1vHboOClLmj48OHYtGmTFLiKNqV+rCza1hdCoE+fPli+fDmcnZ0NKa1SYfAiIiKyPMY6fut9qVHNyckJGzZswLfffguVSiVdelQv6mEnylqKr29jY4P58+dj06ZNVSJ0ERERERVlcPBSe+eddxAXF4ePPvoIrq6uUqgCoBGsii8ApHVdXV3x0UcfIS4uzmhDVBARERGZm8GXGrV5/Pgx9u3bhwMHDuDAgQOIiYlBamqqxryOVlZWcHV1RfPmzREUFISgoCB069atyg6QykuNRERElqfS9fHSR3p6Oh4+fIjq1as/ceGDwYuIiMjyGOv4bS1bS2VwcnJi6CAiIqInXoX7eBERERGRbhi8iIiIiEyEwYuIiIjIRBi8iIiIiEyEwYuIiIjIRBi8iIiIiEyEwYuIiIjIRBi8iIiIiEyEwYuIiIjIRBi8iIiIiEyEwYuIiIjIRBi8iIiIiEyEwYuIiIjIRHQKXlZWVrCysoK1tTX27t1r7JqIiIiIqiSdgpcQQlrKwoBGREREVDprXVdUKBTlrlNeMCMiIiJ6kul0xkup/N9q5YUrXQIaERER0ZNIp+Dl7OwsBa6kpCSjFkRERERUVekUvOrWrSvd3rVrl9GKISIiIqrKdApeQUFBAAovM65cuRLTp09HfHy8UQsjIiIiqmoUQoce8VFRUWjXrh0UCgWEEFI/LhcXFzg5OUn34+LipNseHh6wtbWVp0iFAteuXZOlLVNLT0+Hs7Mz0tLS4OTkZO5yiIiISAfGOn7r9K3GNm3aICIiAvPmzZOClRACKSkpSElJ0VhXnePkPCPGDvtERERUFeg8cv2XX36Jzz77DCqVSuObjQqFQlqKKvp4RRYiIiKiqkKnS41FpaSkYN26dThy5AiuXLmC1NRUZGVlQQiBGzduSGHJ3d1dtkuNABAbGytbW6bES41ERESWx1jHb72DV1mUSqUUvHbv3o1nnnlGrqYtFoMXERGR5THW8ZuTZBMRERGZiOzBi9MGEREREWmn81yNupg6dap0u2HDhnI2TURERGTxZO3jRSWxjxcREZHlYR8vIiIiIgsn66XG8uTl5SEhIQEpKSl4+PAhqlevDldXV3h4eMDa2qSlEBEREZmc0dPOtWvX8NNPP2H//v04c+YMsrOzS6yjUqnQoUMHdOvWDSNGjECDBg2MXRYRERGRyRmtj1d8fDxGjRqFrVu3St90LGtX6vG/FAoF+vbtiwULFsDT09MYpZkU+3gRERFZHovq47V79260bt0aW7ZsQUFBgRS4yppaCCgMZgUFBdi0aRNat26Nv//+2xjlYeHChfDx8YGtrS0CAgJw/PhxnbZbs2aNFAyJiIiI9CX7pcZDhw6hb9++ePz4MYDCYCWEgBAC1tbWaN68Odzc3ODg4ICMjAwkJSXh8uXLyM3N1Vg/OTkZffv2xe7duxEYGChbfWvXrkVERAQWL16MgIAAzJ8/HyEhIbh8+TLc3d1L3S4uLg4ffPABgoKCZKuFiIiIniyyXmrMyMhAkyZNEB8fLwUohUKBgQMH4rXXXkPXrl1hY2NTYrucnBwcOHAAP//8M9auXSs9LoSAl5cXrly5Ant7e1lqDAgIQKdOnbBgwQIAQEFBAby9vfHuu+9i4sSJWrfJz89H165d8dprr+HAgQNITU3F5s2bddofLzUSERFZHou41DhnzhyN0FWnTh0cOnQIq1atQnBwsNbQBQA2Njb4z3/+g1WrVuHIkSOoW7eu9LN79+7hyy+/lKW+nJwcnDp1CsHBwdJjSqUSwcHBOHLkSKnbTZ8+He7u7nj99dfL3Ud2djbS09M1FiIiIiJA5uC1dOlSKXTVrFkThw4dwlNPPaVXG/7+/jhw4ABq1qwptfXTTz/JUl9SUhLy8/Ph4eGh8biHhwfi4+O1bnPw4EH8/PPPWLJkiU77mDVrFpydnaXF29u7wnUTERFR1SBb8IqKisKdO3cAFPbT+uKLL1CvXj2D2qpXrx5mzZoldcq/e/cuoqKi5CpVZw8fPkRoaCiWLFkCNzc3nbaZNGkS0tLSpOXWrVtGrpKIiIgshWyd6y9evAigsF+WnZ0dBg0aVKH2Bg8ejPfee0/qpH/x4kW0adOmQm26ubnBysoKCQkJGo8nJCRoHbri2rVriIuLQ+/evaXHCgoKAADW1ta4fPkyGjVqpLGNSqWCSqWqUJ1ERERUNcl2xuv+/fsACs92NWjQoMKd4e3t7TUGUlW3XxE2Njbo2LEj9uzZIz1WUFCAPXv2aP3mZPPmzXH+/HmcPXtWWl588UX06NEDZ8+e5WVEIiIi0otsZ7yysrKk23Z2drK0aWtrK93WNuK9ISIiIhAeHg4/Pz/4+/tj/vz5yMjIwPDhwwEAYWFhqFOnDmbNmgVbW1u0atVKY3sXFxcAKPE4ERERUXlkC161atUCUHip8ebNm7K0WbR/lK59rMozcOBAJCYmYsqUKYiPj0e7du2wc+dOqcP9zZs3oVRy7nAiIiKSn2zjeO3evRshISGFjSoUOHz4MAICAgxu79ixY9LlP4VCgV27dmkMA2EpOI4XERGR5an043h16dIFtra20vQ/pQ1GqqtJkyZJt1UqFbp06VKh9oiIiIjMTbbgZWdnh549e0rTA+3fvx+vv/669C1AXQkh8OabbyIyMlKaxzEkJESjvxcRERGRJZK1M9O0adOgVCqlgU+XL1+OTp064Z9//tFp+8jISPj7++Onn36S2lAqlZg+fbqcZRIRERGZhayTZLdt2xbvv/8+vvzySyk4nTlzBsHBwahXrx569OiBNm3aaEySnZycjHPnziEyMhI3btwAAGmOR4VCgffffx+tW7eWs0wiIiIis5B1kmy18PBw/PLLL1J/L/Uu1Pe1Kb6OEAJhYWFYvny53OWZFDvXExERWZ5K37m+qBUrVuCbb76Bra2txtkrAFIfsKILAGkdIQRsbW3x3XffWXzoIiIiIirKaANWvfvuu7hy5QomTpyIWrVqaYSs4tQ/c3d3x0cffYQrV65g9OjRxiqNiIiIyCyMcqlRm5iYGBw7dgw3btxASkoKHj16BEdHR7i6uqJ+/fp46qmn0KxZM1OUYlK81EhERGR5jHX8lrVzfVmaN2+O5s2bm2p3RERERJUO58YhIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhEGLyIiIiITYfAiIiIiMhFrU+wkJiYGt27dQlpaGh4/fgwhhN5thIWFGaEyIiIiItMxWvDatWsXfvzxR/z111/IzMyscHsMXkRERGTpZA9eqampGDZsGLZt2wYABp3dUlMoFBBCQKFQyFUeERERkdnIGrwyMzMREhKCkydPSoFJHZ4MUZHQRkRERFTZyBq8Zs2ahRMnTmgELltbW/Ts2RPt2rWDu7s7HBwc5NwlERERkcWQLXjl5ORg/vz5Gme4Ro4ciS+++AIuLi5y7YaIiIjIYskWvA4ePIiMjAzpbNewYcPwww8/yNU8ERERkcWTbRyvq1evAoDUt+vzzz+Xq2kiIiKiKkG24JWcnAyg8JuIjRs3hqenp1xNExEREVUJsgUvOzs76barq6tczRIRERFVGbIFr8aNG0u31We/iIiIiOh/ZAteXbt2hY2NDYQQiI2NRUpKilxNExEREVUJsgUvJycnDBkyBABQUFCAX375Ra6miYiIiKoE2YIXAMycORM1atQAAMyYMQNxcXFyNk9ERERk0WQNXp6enti0aRPs7OyQnJyM//znPzhz5oycuyAiIiKyWLIGLwAICgrC/v370bBhQ8TGxiIgIABDhgzB5s2bcfv2beTk5Mi9SyIiIiKLoBA6zERtZWVl8A7UA6pWhEKhQF5eXoXaMJf09HQ4OzsjLS0NTk5O5i6HiIiIdGCs47dOUwbpkM1KUIetonM3EhERET3JdL7UqO9ZKyGEtBiqomfKiIiIiCoTnc54de3alSGIiIiIqIJ0Cl6RkZFGLoOIiIio6pP9W41EREREpB2DFxEREZGJMHgRERERmYhOfbx0NX36dOl2WFgYfHx8DG4rNjZWY77HKVOmVKQ0IiIiIrPTaQBVXSmVSunbj7t378YzzzxjcFt79uzBs88+K7WXn58vS42mxgFUiYiILI+xjt+yX2qUe7BUDr5KREREVYXswYvjfRERERFpV2k71xcUFEi3lcpKWyYRERGRziptoklLS5NuOzg4mLESIiIiInlU2uB16tQp6babm5sZKyEiIiKSh6zDSchl//79+OGHH6T+Yq1atTJzRUREREQVp3fw0nWIiPfffx+urq46tyuEQGZmJuLi4pCUlCQ9plAoEBISom+ZRERERJWO3uN4FR2rq7iiTRny7cbi2wsh4OHhgZiYGDg7O+vdXmXAcbyIiIgsj8WM41URCoVCCmxCCLi5uWHdunUWG7qIiIiIijKoj5cuJ8n0HfhUoVDAwcEBNWrUQMuWLdGzZ0+EhYXpdbmSiIiIqDLTO3gVHV+rODmnDCIiIiKqair9lEHGsHDhQvj4+MDW1hYBAQE4fvx4qesuWbIEQUFBcHV1haurK4KDg8tcn4iIiKg0sgavrl27olu3bujatWulvUS4du1aREREYOrUqTh9+jTatm2LkJAQ3L9/X+v6kZGRGDx4MP755x8cOXIE3t7e6NmzJ+7cuWPiyomIiMjS6f2tRksXEBCATp06YcGCBQAKL516e3vj3XffxcSJE8vdPj8/H66urliwYAHCwsLKXZ/faiQiIrI8T8S3Go0tJycHp06dQnBwsPSYUqlEcHAwjhw5olMbmZmZyM3NRY0aNbT+PDs7G+np6RoLEREREfCEBa+kpCTk5+fDw8ND43EPDw/Ex8fr1MaECRPg5eWlEd6KmjVrFpydnaXF29u7wnUTERFR1WCSKYMuX76Mffv24fjx44iNjUVqaioePXoER0dHuLi4oEGDBvD390e3bt3QrFkzU5RkkNmzZ2PNmjWIjIyEra2t1nUmTZqEiIgI6X56ejrDFxEREQEwcvDasGEDvv766xKX8YqPUB8ZGYlly5YBAJ566imMGzcO/fv3l70eNzc3WFlZISEhQePxhIQEeHp6lrntV199hdmzZ+Pvv/9GmzZtSl1PpVJBpVLJUi8RERFVLUa51BgfH49evXrhlVdewZEjRyCEKBG2io5SD0Ba58iRIxg4cCCef/553L17V9a6bGxs0LFjR+zZs0d6rKCgAHv27EFgYGCp282ZMwczZszAzp074efnJ2tNRERE9OSQPXjduHEDXbp0wc6dO6WwVXQaoNIW9XrqORp37dqFoKAg3LhxQ9b6IiIisGTJEqxYsQLR0dF4++23kZGRgeHDhwMAwsLCMGnSJGn9L774Ap988gmWLl0KHx8fxMfHIz4+Ho8ePZK1LiIiIqr6ZL3UmJ2djZCQEFy/fh3A/ya6dnJywssvv4zu3bujVatWqFmzJhwcHJCRkYHk5GScP38e+/btw4YNG5Ceni5tFxsbi5CQEJw7d062y3cDBw5EYmIipkyZgvj4eLRr1w47d+6UOtzfvHkTSuX/8uiiRYuQk5NT4tLn1KlT8emnn8pSExERET0ZZB3Ha/LkyZg1a5Z0hkupVGL8+PGYPHkyHBwcyt0+IyMDn332Gb766isUFBRACAGFQoGJEyfi888/l6tMk+I4XkRERJbHWMdv2YJXXl4ePD09kZKSAiEErK2tsXbtWvTr10/vtjZt2oRXXnlFCl81atRAQkICrKys5CjVpBi8iIiILE+lH0B1//79ePDgAYDCS4wREREGhS4A6NevHyIiIqS+XykpKYiMjJSrVCIiIiKzkC14qft1CSGgVCoxduzYCrU3btw4KJVK6bKlun0iIiIiSyVb8EpMTARQeLbLx8en3HGxyuPp6YmGDRtKZ72SkpIqXCMRERGROckWvIp2ni9tHkN9ubq6am2fiIiIyBLJFryaNGki3dZ13sPyFB1hvmj7RERERJZItuAVFBQElUoFIQRu376NK1euVKi9K1eu4ObNmwAKp+EJCgqSo0wiIiIis5EteDk6OiI0NFS6P3369Aq1N23aNACFfcZCQ0Ph6OhYofaIiIiIzE3WKYNmzpwJT09PCCGwevVqzJ4926B2Zs+ejdWrV0OhUMDLywszZ86Us0wiIiIis5A1eLm5uWHXrl3w8vKCEAKTJ09G3759cfnyZZ22j4mJQZ8+fTB58mQAgJeXF3bt2oWaNWvKWSYRERGRWcg6ZdD+/fsBFHaunzBhAm7cuCGNw9WxY0eNuRrt7e2RmZmJpKQkXLhwAfv27cOpU6cAFI4F5uPjgy+++EKaQ1EXXbt2leupyIYj1xMREVmeSj9lEACNAU/VijZf/GeGrFcahUKBvLw8vbczNgYvIiIiy2Os47e1bC0VoZ7cGigZorTlPIVCoTVsyZgJiYiIiMxO9uClDkv6hCYGLCIiInoSyBq8pk6dKmdzRERERFWKrH28qCT28SIiIrI8xjp+yzqcBBERERGVjsGLiIiIyEQYvIiIiIhMhMGLiIiIyESMMo5XcUIInDlzBtHR0Xjw4AHS0tJQUFCAsLAw+Pj4mKIEIiIiIrMzavA6d+4c5s6diy1btuDRo0clft6lSxetwWvOnDmIiYkBANSrVw+ffvqpMcskIiIiMgmjBK+cnByMGzcOixcvBlD6aPWl8fT0xMSJE6UR7YcNG8YzY0RERGTxZO/jlZmZiW7dumHx4sV6By61IUOGoFatWhBCQAiB3377Te4yiYiIiExO9uA1ePBgHDt2TLqvUCjQr18/LFq0CH/88YdO0wNZW1ujX79+0v0///xT7jKJiIiITE7WS43btm3Dtm3bpLNaTZo0wYYNG9CqVSuN9XQ569W7d2/8+OOPEELg+PHjePz4Mezs7OQsl4iIiMikZD3jNWPGDACFfbo8PDwQGRlZInTpqlOnTtLt/Px8REdHy1IjERERkbnIFrwSEhJw6tQpqUP8jBkzULt2bYPbc3d3R61ataT7ly9flqNMIiIiIrORLXgdOnRI6gxvbW2NQYMGVbhNNzc36XZSUlKF2yMiIiIyJ9mCV3x8PIDC/luNGzeGg4NDhdssOhu4tnHAiIiIiCyJbMErLS1Nul00MFVERkaGdJsd64mIiMjSyRa8XF1dpdtFQ1hFqM+iAUDNmjVlaZOIiIjIXGQLXh4eHgAKv9EYGxuLnJycCrX377//avTr8vb2rlB7REREROYmW/Dy8/OTbufk5GDv3r0Vaq/oaPU2NjZ46qmnKtQeERERkbnJFry8vb3h6+srDY76xRdfGNzWvXv38N1330lDU3Tp0gW2trZylUpERERkFrIOoDpy5EhpSqD9+/fj888/17uNhw8fon///khJSZHaGjt2rJxlEhEREZmFrMFr1KhR8PHxAVDY12vKlCkYPXq0zp3td+3aBX9/fxw9elQ629WpUyf06tVLzjKJiIiIzELWuRqrVauG1atX45lnnkFWVhaEEFi8eDFWrlyJ3r17o2PHjgAKQ5lCocD27dtx+vRpXL16FXv37sW1a9eknwkhUKNGDaxevVrOEomIiIjMRiHU1/NktG3bNgwaNAhZWVkA/he01LelnReZLFv9uDp0OTs7Y9OmTejevbvc5ZlUeno6nJ2dkZaWJtv4ZkRERGRcxjp+y3qpUa137944fvw4fH19NUIXAOkSojpgFQ1c6sdatmyJY8eOWXzoIiIiIirKKMELAFq2bImzZ89i1apV8Pf3BwApaBUNXEUfb9myJVasWIFz586hadOmxiqNiIiIyCyMcqlRmwcPHuDgwYOIjo5GcnIyUlNTYW9vDzc3NzRo0AA9evSAl5eXKUoxKV5qJCIisjzGOn6bLHg9qRi8iIiILI9F9fEiIiIiopIYvIiIiIhMhMGLiIiIyERkHUBV7datWzhz5gyuX7+Oe/fu4dGjR8jJyYFKpYKjoyO8vLzQqFEjtG/fvkp2qCciIiLSRrbg9e+//+KHH37A5s2bERsbq/N2jRs3xksvvYSRI0eiYcOGcpVDREREVOlU+FuNCQkJGD9+PFatWlVifC6di1AooFQqER4ejtmzZ8PNza0iJVUq/FYjERGR5amU32o8cOAA2rZti99++w0FBQXSKPXaFgCl/kwIgfz8fCxbtgzt2rXD0aNHZXlyRERERJWJwZca9+3bh169eiEzMxMAtM7F6OjoiJo1a8LFxQWOjo54+PAh0tLSkJSUhIyMDGm9otvevXsXzz77LP766y8EBgYaWh4RERFRpWNQ8Lp79y4GDBiAzMxMjdCkVCrx4osv4qWXXkJAQECZ0/7ExMTg+PHjWL9+PXbs2IGCggKprYyMDPTv3x9nzpyBu7u7ISUSERERVToGXWocO3YskpKSNEJXv3798O+//2LTpk0IDQ0td67F5s2bIywsDFu3bsWVK1fQt29fjbNl8fHxiIiIMKQ8IiIiokpJ7+B17tw5rF+/XuqbBQDz5s3Dhg0b0KBBA4OKaNiwITZu3Ii5c+dK/cSEEFi9ejUuXbpkUJtERERElY3eweu7774DACkgjRs3DmPHjpWlmHHjxmHcuHFS20X3R0RERGTp9BpOIi8vD+7u7khLS4MQAr6+voiKioJSKd8A+Pn5+WjTpg1iYmIghEDNmjURHx8PKysr2fZhShxOgoiIyPJUiuEkjh8/jtTUVACF30QcO3asrKELAKysrDB27FjpMuaDBw9w4sQJWfdBREREZA56paZDhw4BKLzMaGdnh9DQUKMUFRYWBnt7e+lyo3q/RERERJZMr+B18eJFAIVnu/z8/KBSqYxSlEqlgp+fn3TW68KFC0bZDxEREZEp6RW8/v33X+m2sQc3feqpp7Tul4iIiMhS6RW84uPjpdv169eXvZiifHx8tO6XiIiIyFLpFbySk5Ol2y4uLnLXokHdvhBCY79ERERElkqv4JWdnS3ddnV1lb2YoooGu6ysLKPui4iIiMgU9A5e6m8aVqtWzSgFqRVtPycnR9a2Fy5cCB8fH9ja2iIgIADHjx8vc/3ff/8dzZs3h62tLVq3bo0dO3bIWg8RERE9GeQdhMsCrF27FhEREZg6dSpOnz6Ntm3bIiQkBPfv39e6/uHDhzF48GC8/vrrOHPmDPr27Yu+ffvym5ZERESktycueM2bNw8jR47E8OHD4evri8WLF8Pe3h5Lly7Vuv4333yD5557DuPHj0eLFi0wY8YMdOjQAQsWLDBx5URERGTprM1dgCnl5OTg1KlTmDRpkvSYUqlEcHAwjhw5onWbI0eOICIiQuOxkJAQbN68Wev62dnZGn3h0tLSABROPUBERESWQX3c1mNmRZ0YHLzOnTsHa2vj5bZz587J3mZSUhLy8/Ph4eGh8biHhwdiYmK0bhMfH691/dKGuJg1axamTZtW4nFvb28DqyYiIiJzSU5OhrOzs2ztGZSchBD44IMPZCuiNAqFQvakaWyTJk3SOEOWmpqK+vXr4+bNm7K+cKS/9PR0eHt749atW5ywvBLg61F58LWoPPhaVB5paWmoV68eatSoIWu7BgUvUwUi9Tco5eLm5gYrKyskJCRoPJ6QkABPT0+t23h6euq1vkql0jqVkrOzM99ElYSTkxNfi0qEr0flwdei8uBrUXkolfJ2hze4NYVCYfRFbjY2NujYsSP27NkjPVZQUIA9e/aUOgVSYGCgxvoAsHv3bqNPmURERERVj15nvOrVq2eUQGRKERERCA8Ph5+fH/z9/TF//nxkZGRg+PDhAICwsDDUqVMHs2bNAgCMGTMG3bp1w9y5c9GrVy+sWbMGJ0+exI8//mjOp0FEREQWSK/gFRcXZ6QyTGfgwIFITEzElClTEB8fj3bt2mHnzp1SB/qbN29qnFZ8+umnsWrVKnz88cf46KOP0KRJE2zevBmtWrXSaX8qlQpTp07VevmRTIuvReXC16Py4GtRefC1qDyM9VoohKX1XiciIiKyUE/cAKpERERE5sLgRURERGQiDF5EREREJsLgRURERGQiDF4yWLhwIXx8fGBra4uAgAAcP368zPV///13NG/eHLa2tmjdujV27NhhokqrPn1eiyVLliAoKAiurq5wdXVFcHBwua8d6Uff94bamjVroFAo0LdvX+MW+ATR97VITU3F6NGjUbt2bahUKjRt2pSfVTLR97WYP38+mjVrBjs7O3h7e2PcuHHIysoyUbVV1/79+9G7d294eXlBoVCUOgdzUZGRkejQoQNUKhUaN26M5cuX679jQRWyZs0aYWNjI5YuXSouXrwoRo4cKVxcXERCQoLW9Q8dOiSsrKzEnDlzxKVLl8THH38sqlWrJs6fP2/iyqsefV+LIUOGiIULF4ozZ86I6OhoMWzYMOHs7Cxu375t4sqrJn1fD7XY2FhRp04dERQUJPr06WOaYqs4fV+L7Oxs4efnJ55//nlx8OBBERsbKyIjI8XZs2dNXHnVo+9r8dtvvwmVSiV+++03ERsbK3bt2iVq164txo0bZ+LKq54dO3aIyZMni40bNwoAYtOmTWWuf/36dWFvby8iIiLEpUuXxHfffSesrKzEzp079dovg1cF+fv7i9GjR0v38/PzhZeXl5g1a5bW9V955RXRq1cvjccCAgLEm2++adQ6nwT6vhbF5eXlierVq4sVK1YYq8QniiGvR15ennj66afFTz/9JMLDwxm8ZKLva7Fo0SLRsGFDkZOTY6oSnxj6vhajR48WzzzzjMZjERERonPnzkat80mjS/D68MMPRcuWLTUeGzhwoAgJCdFrX7zUWAE5OTk4deoUgoODpceUSiWCg4Nx5MgRrdscOXJEY30ACAkJKXV90o0hr0VxmZmZyM3NlX1C1CeRoa/H9OnT4e7ujtdff90UZT4RDHkttm7disDAQIwePRoeHh5o1aoVZs6cifz8fFOVXSUZ8lo8/fTTOHXqlHQ58vr169ixYweef/55k9RM/yPX8dugSbKpUFJSEvLz86VR79U8PDwQExOjdZv4+Hit68fHxxutzieBIa9FcRMmTICXl1eJNxbpz5DX4+DBg/j5559x9uxZE1T45DDktbh+/Tr27t2LV199FTt27MDVq1cxatQo5ObmYurUqaYou0oy5LUYMmQIkpKS0KVLFwghkJeXh7feegsfffSRKUqmIko7fqenp+Px48ews7PTqR2e8SICMHv2bKxZswabNm2Cra2tuct54jx8+BChoaFYsmQJ3NzczF3OE6+goADu7u748ccf0bFjRwwcOBCTJ0/G4sWLzV3aEycyMhIzZ87E999/j9OnT2Pjxo3Yvn07ZsyYYe7SyEA841UBbm5usLKyQkJCgsbjCQkJ8PT01LqNp6enXuuTbgx5LdS++uorzJ49G3///TfatGljzDKfGPq+HteuXUNcXBx69+4tPVZQUAAAsLa2xuXLl9GoUSPjFl1FGfLeqF27NqpVqwYrKyvpsRYtWiA+Ph45OTmwsbExas1VlSGvxSeffILQ0FCMGDECANC6dWtkZGTgjTfewOTJkzXmFibjKu347eTkpPPZLoBnvCrExsYGHTt2xJ49e6THCgoKsGfPHgQGBmrdJjAwUGN9ANi9e3ep65NuDHktAGDOnDmYMWMGdu7cCT8/P1OU+kTQ9/Vo3rw5zp8/j7Nnz0rLiy++iB49euDs2bPw9vY2ZflViiHvjc6dO+Pq1atS+AWAK1euoHbt2gxdFWDIa5GZmVkiXKkDseBUyyYl2/Fbv37/VNyaNWuESqUSy5cvF5cuXRJvvPGGcHFxEfHx8UIIIUJDQ8XEiROl9Q8dOiSsra3FV199JaKjo8XUqVM5nIRM9H0tZs+eLWxsbMT69evFvXv3pOXhw4fmegpVir6vR3H8VqN89H0tbt68KapXry7eeecdcfnyZfHHH38Id3d38dlnn5nrKVQZ+r4WU6dOFdWrVxerV68W169fF3/99Zdo1KiReOWVV8z1FKqMhw8fijNnzogzZ84IAGLevHnizJkz4saNG0IIISZOnChCQ0Ol9dXDSYwfP15ER0eLhQsXcjgJc/nuu+9EvXr1hI2NjfD39xdHjx6VftatWzcRHh6usf66detE06ZNhY2NjWjZsqXYvn27iSuuuvR5LerXry8AlFimTp1q+sKrKH3fG0UxeMlL39fi8OHDIiAgQKhUKtGwYUPx+eefi7y8PBNXXTXp81rk5uaKTz/9VDRq1EjY2toKb29vMWrUKJGSkmL6wquYf/75R+sxQP37Dw8PF926dSuxTbt27YSNjY1o2LChWLZsmd77VQjBc5VEREREpsA+XkREREQmwuBFREREZCIMXkREREQmwuBFREREZCIMXkREREQmwuBFREREZCIMXkREREQmwuBFRERUxYwcORIKhQIKhQIDBgwwdzlGd+PGDahUKigUClhZWeHs2bPmLqlUHEDVwsXGxuLChQu4desW0tPTUVBQAFdXV7i6uqJFixZo1aqVxkS3RERUtZ08eRIBAQEoKCiAtbU1Ll68iKZNm+q0bXR0NObOnYs9e/bg3r17cHJyQkBAAEaMGIE+ffrIWufdu3cRFRWFGzduIC0tDbm5uXBxcYGrqysaN26Mdu3a6TU36JgxY/Dtt98CALp27Yp9+/bJWq9sKjbgPplDVFSUeOedd0SdOnW0TndQdLG3txfPPvusWLFihXj06JG5S38ilfcaybGUNfUOET1ZOnfuLH02vPbaazpvt2DBAmFtbV3q58yLL75Y4ePI9evXxYQJE0Tjxo3L/VyzsbERnTt3Ft9//71ITk4ut+2EhARhZ2cnbf/7779XqFZjYfCyIDdu3BAvvfSSwQdnJycnMXPmTPH48WNzP5UnCoMXVVVF/waLz2lH5rF9+3bpNVEoFCImJkan7ZYtW6bTZ02vXr1Efn6+3nUlJSWJkSNHCisrK4M+41Qqlfjggw9EampqmfsZNWqUtI2vr69BtRobLzVaiD/++ANDhw5FWlqa1p+7urqiVq1acHZ2RlJSEhISEpCZmal1XT8/P5w4ccKY5VIRCoXC6PsIDw/H8uXLjb4foqKK/m1369YNkZGR5iuGABR+vp86dQoA0KdPH2zevLncbZKTk9GwYUOkp6cDAOrXr4+3334bzZo1w/3797Flyxbs2LFDWn/58uUIDw/XuaajR4+if//+uHPnjtafV69eHe7u7qhZsyZSUlJw7949PHr0SOu6bm5uSExMLHVf169fR5MmTVBQUAAA+O233zBkyBCdazUFa3MXQOX77bffEB4ejvz8fI3HO3bsiNdffx3PP/886tevX2K7y5cvY8uWLVi3bp30RgRQ5h8tyW/37t06rXfu3Dl88MEH0n0PDw/8+uuvOm3r5eVlUG1EVHX8/fffGp/1b7/9tk7brVq1SgpdL774ItauXQtbW1vp52+88QZWrFiBYcOGAQAWLlyoc/Dau3cvevfuXeJEQJMmTfDWW2/hv//9L1q0aFFiu5s3b2Lr1q3YsGGDRqBPSkoqc38NGzZEz549sXPnTgDAnDlzKl3w4qXGSu7EiRPCxsZG45Srs7Oz+OWXX0RBQYHO7WzcuFE0a9ZMABD169c3XsFksH/++UfjdebrRJVd0b9XXmo0vxdeeEHj80PXy2yDBg0SAISVlZWIj48vdb3//ve/0iVMXbqsxMXFCVdX1xL9tubPny9ycnJ0fl7//POP6NSpk9RGedavX6+xz8jISJ33ZQocTqISS09Px8CBA5GTkyM95u7ujsjISAwdOlSvS1j9+vVDVFQUXn/9dWOUSkREZnTjxg2Ny4GvvvoqlErdDvHJyckACo8vHh4epa7Xtm1bAIAQAikpKWW2mZeXh8GDB2us5+DggO3bt2PMmDGoVq2aTrUBQPfu3XHs2DF88sknOh33XnzxRTg7O0v3Fy1apPO+TIHBqxL79NNPcf36dem+UqnE5s2b0a5dO4Pas7GxwU8//YR58+bJVCEREVUGq1atkvo1AcBLL72k87bqkJKYmFjmpbxLly5Jt11cXMps8/vvv8eRI0c0Hvv5558RHBysc11FKRQKTJ8+HRs2bCh33WrVquGFF16Q7m/duhUPHz40aL/GwD5elVRqaiqWLFmi8djYsWMRGBhY4bb1eUPevn0bFy9eRGxsrNSxv0aNGqhTpw4CAwPh6upa4XpM6f79+zh69Cji4+ORnJwMR0dHuLu7w9/fHw0aNDB3ebJITU3F4cOHce/ePSQmJsLW1ha1atVC+/bt4evrK/v+Tpw4gX///Rd37tyBUqlEo0aN0KNHD43/OLXJysrCwYMHER0djYcPH8LV1RXNmzdHUFAQrK3l+2i6c+cODh8+jBs3biAvLw+1a9dGq1at0LFjR1naF0IgKioK0dHRuH//PjIyMuDm5oa6desiKCgIjo6OsuxH7dGjRzh06BDu3r2L+Ph42Nraolu3bujQoUOp22RlZeHSpUuIjo5GYmIiMjIyUL16ddSsWROtW7dGq1atdD47UlWdPHkSV69exb1795CVlYX69evr1Dfo5s2bOHnyJBISEpCSkgJnZ2d4enqic+fO8PT0NEHlhVatWiXdrlOnjl5/3/7+/li/fj3y8vLw9ttv47fffisxfta6deuwbds2AIVnvuzs7EptLz8/v8Q/+C+99BIGDhyoc02l6devn07r9enTB7/99hsA4PHjx9i0aRPCwsIqvH9ZmPtaJ2k3e/bsEtfFExMTjb7f3Nxc8eeff4rXX39d1K9fv8yv9yoUChEYGCg2bdpUbn+z7OxsUaNGDWlbe3t7kZ6ernd9sbGxQqFQSO20bNmy3G3y8/PFihUrhJ+fn8a2xZcWLVqIZcuWme3rxxXt47V161bRtWvXMsfhqVevnpg3b57IysoyqKapU6cKIYTIy8sT33zzjWjSpInW/djb24vx48dr7QeSnp4uPvzwQ+Hk5KR121q1aomffvpJ5+fdrVs3je3Vzp49K3r27Fnqa96oUSOxbNkynfdT3P3798W4ceNE7dq1S/1929jYiBdffFGcO3euws/n4sWLYvDgwcLe3r7EfsaMGVOinVu3bokvv/xSdO/eXahUqjLfy66uriIiIkLcuXNH7/p0XdR/O0UV/bm+fcTCw8M1to+NjS113eJDJahf98zMTDF9+nTRoEGDEvU6OzuX2l52draYP3++8PX1LfPz0c/PT2zZskWv52WIuLg4jX0PHTpUr+1v374tbG1tpe0bNmwo5syZIzZv3iyWLFki+vTpo9H+okWLymxvzZo1JX4fUVFRFXmKert//77G/gcMGGDS/ZeFwauS8vf31/ijGThwoEn2+/LLLxv0ofrSSy+VO7Be0fFVAIilS5fqXd+0adM02pgzZ06Z61+5ckW0bdtWr+fy1FNPifv37+tdW0UZGrwSEhJE9+7d9XqOTZs2FVevXtW7pqlTp4pHjx6JZ599Vqf9BAUFiczMTKm9q1evlhrWii9jx47V6flrCyqrVq0S1apV02k/vXv31jmIqv3000+ievXqOv++lUqlmDZtmsHP59dffy3xJZuiS/Hgde7cuTL/yShtcXZ2Fjt27NCrPl2Xyha84uLiygxOpQWvo0ePag1q5f2NGXMA6x9++EFjf0uWLNG7ja+++kqn59K9e3eRm5tbZluvvPKKxjYBAQGGPrUKKfr6urq6iry8PLPUURyDVyX06NGjEmctVq1aZZJ99+rVq8QbrVatWsLX11cEBASItm3bCjc3N61vyP/85z9lni06duxYiTewvho1aiRtb2VlJe7evVvqukePHtVaq5WVlWjcuLHw9/cXvr6+Gv/pqZdGjRqZPHwZEryuXLmi9SCgUCiEj4+P8PPzE61btxaOjo5aX9fLly/rVdOUKVM0vjkFQHh5eQk/Pz/h6+urdXDEkSNHCiEKA2K9evU0amzYsKHo1KmTaNiwoda/qV9//bXc30HxILB3716N94/69fbz8xNeXl5a99OrV69yDyZqH3/8sdY2nJycRMuWLYW/v7/w8fHRus57772n9/PZvn27UCqV0n2lUikaNWokOnXqJOrXry+srKxKBK8TJ06U2LeNjY1o1KiRaN++vfD39xdNmjTRenZUqVSKvXv36lyfrktlCl7ffPONaNq0qcZj7u7uon379sLX11c4ODhoDV5bt27VGBm96O+2WbNmwt/fXzRv3lzr79Xf399og1cPHTpUY19nzpwxqJ0pU6aU+Ro+++yzIiUlpdx2ip8FnjlzpkH1VFRoaKgsvxe5MXhVQn///XeJP/grV66YZN+9evUSbm5uYtSoUWL79u2lXt78999/xaRJk0qElnnz5pXZfvPmzTUOvHFxcTrXdvDgQY19Pffcc6Wue+/ePeHu7q6xfps2bcTq1avFw4cPNdZ9/PixWLt2rUaoAyCef/55vYbsqCh9g1dGRoZo0aKFxjYNGjQQP/zwg3jw4IHGuupLyB06dNBYv127dmWe7SleU9FAMXjwYHHp0iWN9ZOSkkqc2VQoFCIqKkqEhIQIAMLW1lZMmTJF3Lt3T2PbmJgY0bVrV41tPT09y/3aefEgoL5EbmNjIz799NMSAfrcuXMlwiMAMXv27DL3I4QQS5cuLfHcwsLCxIkTJ0r803Hnzh0xadKkEmfe1q5dq9fz8fDwEEDhGZi5c+eWeE/Gx8eLY8eOaTymDl7dunUTX3/9tbhw4YLWYPn48WOxefPmEmfYvby8SrxP1E6ePCl2794tdu/eXeL9pX5c23Lt2rUSbZkreKl/p0Dh1YTil4JzcnJKnPm7cOFCidAVFBQk/vjjjxKBKj09Xfz4448a+wEg3nrrLb2eo66Kfg5YWVnpfQa3qOPHj4shQ4aIOnXqiGrVqomaNWuKnj17itWrV+v0eXj16tUS762//vrL4HoqYs6cORp1GHIm0BgYvCqhBQsWaPyxODo6miwAHD58WK//ys6cOaPRd6tOnTplnjmYNWuWxnObMWOGzvsaOXKkxrarV68udd3nnntOY9033nij3AN4SkqKePrppzW227hxo871VZS+weutt97SWL93796lHizVsrKyRL9+/XQOy8VrUi9fffVVmfsZPny4xvrqA4Ojo6PYv39/qdtpC5ObNm0qc1/azsCoVCqxZ8+eMrcbN26cxjZ2dnbixo0bpa5/7do1jf5VdnZ25V6WE0KIffv2aRyw3d3dy3yPaXs+np6eIjo6utx9qSUkJIgLFy7ovH5+fr4YMWKExj6///77crerSHCq6PYVCV7qZf78+TrtKzc3V7Rq1Upj22nTppX7uXz79u0Sl9ZPnz6tz9MsV1ZWlsYZ0YYNG8ravr7++OOPEr9nU/RP1mbr1q0adbzzzjtmqaM4Bq9KaPr06Rp/LA0aNDB3SWX66aefNOrdvn17qeveunVL40OiadOmOu3j8ePHwsXFRdrO2dm51IPXkSNHNOr573//q3NwvXfvnkbfnc6dO+u0nRz0CV43b97UuJzRpk0bnf/LzcjI0DhzVb9+/VL7PmgLXrr0N7xz547G66xefvzxx3K3XbVqVYnQXBZtQaW8YCiEEAUFBSIwMFBju0mTJpW6/ptvvqlz8C9u4cKFGtuW9Z+3tuezc+dOnfdlqOzsbI2zvp06dSp3G0sOXoMGDdJ5X6tXr9bY9s0339R526ioKI33wquvvqrztrq4cuWKRm1du3aVtX19rVy5UqMeKysrk145KOrkyZMatbzwwgtmqaO4J/v7w5XUgwcPNO6XN16KuQ0aNAhWVlbS/cOHD5e6bt26dfGf//xHun/lyhUcPXq03H1s2bIFqamp0v1XXnlFY0qLoubPn69x/+uvv9Z5sFlPT0+MGDFCun/o0CEkJCTotK0pLVy4EHl5edL9L7/8EiqVSqdt7e3tMW7cOOn+jRs3cPLkSZ22VY+lUx4vLy/4+flpPFa/fn289tpr5W7bu3dvjaENzpw5o1NtanXq1MF7771X7noKhQJffPGFxmPLli2D0DJ97YMHD7By5UrpfmBgIAYNGqRzTSNHjoS7u7t0X5exiNS6dOmCkJAQndc3lI2NDQYMGCDdP3PmDB4/fmz0/ZrLjBkzdF636GeKvb09Zs2apfO2rVu3Rp8+faT7W7ZsKTH9W0XcunVL437t2rVla9sQxY9fTk5OJpmvVpviv4vivytzYfCqhIoP9Obg4GCmSnTj4OCgcVAp70BZfI6vFStWlLuPogc9bW2oFRQUSHN0AYXj0zRr1qzc9ovq2bOnxv0DBw7otb0pFB2h2tPTU+9BCQ19jm3atEHTpk11WrdVq1Ya9/v166cR0Evj6OgIHx8f6f7Nmzd12p/aoEGDdB4VOygoCA0bNpTux8fH4/LlyyXWi4yM1AghoaGhetVUrVo19OjRQ7p/+PBhjcEuyzJ48GC99lURRceyy8vLw4ULF0y2b1Pq1KkTGjdurNO6ycnJOH78uHT/hRde0Hv8wqLvt0ePHun9z0RZ1OMrqsk9bpy+KtPxq/jvovjvylwYvCqh6tWra9zPyMgwSx0XL17EtGnT0KdPHzRp0gRubm6wsbGBQqEosdy7d0/arrxJTF966SU4OTlJ99euXasxLVJxCQkJ2LVrl3S/cePG6Ny5s9Z1z58/r/HmKn7WRRf16tXTuB8dHa13G8aUkpKicUDs0KGD3oNfGvoc9RmUsWbNmhr3yxrgs6xt1ZP36qp79+56rd+tWzeN+0UPsmrFg2lF/67S09Nx584dnbbz9/fXe19FZWZmYs2aNXjzzTfx1FNPwcvLC9WrV4dSqSzxPn7zzTc1ti3vvWyp9PmdHjx4UOMsaGX7TCk++XRZA5uaQmU5fgGFZyeLMmctRXHk+kqoRo0aGvdNndLPnz+Pd955B/v37zdo+6KXBLWxs7PDgAED8PPPPwMoDBLbtm3Dyy+/rHX93377TePUfFmjDxf/QPv+++/x/fff61i5dsVPnZvb5cuXNQ4EO3bsqPCpfF2fY61atXRus/iHnqHb6nu5q/iZNn3Xj42NLbFO8b+rioYhoPB37u3tXe56hs6okJubi3nz5uHzzz83eLqU8t7Llkqf32nx1/7DDz/Ehx9+WKH9G/MzRdulclMqfvzS9x8nOZn7d1EanvGqhIr/4SYmJpps33/88Qf8/PwMDl0AkJ2dXe46+lxuLPozhUJR5mUe9WSvcqosp6fVzPkcS+tXZ+xt9VH8TJu+62sLG+b8nRc9O6yrx48f47nnnsPEiRMrNEedLu9lS6TP77Syf6YU/wcnKytLtrYNUfz4lZ+fb5TfoS6K/9NWWbrt8IxXJdS8eXON+w8fPsTVq1d17pNgqCtXrqB///4al/0UCgX8/f3x9NNPo2HDhvD09IStrW2Jg+jQoUP16oTepUsXNGzYUJoEfOfOnUhMTCxxVuTcuXOIioqS7nfr1k2j/09xxvgPXde+OKbyJDzHiih+ICpP8Q/jR48elVjHnL9zXfurFTVq1Cjs3btX47FatWqhe/fuaNu2Lby9veHk5AQ7OzuNfnd//fUXvvzyS733Z2n0+Z1W9vdb8S9fmXsy6OLHL6Cw36+hk2NXRPH3cnnzx5oKg1cl9NRTT8Ha2lrjW2snT540evCaOHGixn+4/v7+WLFihdY3UnH6XupSKBQICwvDp59+CqDwssjq1atLfBut+Jmw0jrVqxU/6A4ePFinb9KVxcvLq0Lby634c+zRowc++uijCrVpaZOdlyUzM7NEP5OyFO/3oa1zcvHf+bJly1C3bl3DCvx/bdu2rdD2pTl79qzG+6ZatWqYM2cORo0aVWLi4+KuXbtmlJosWfHXfuzYsejVq1eF2iz6hY6KKn65umh/W3No1KgRateurVHHyZMnzRK87t69q3G/eF87c2HwqoQcHBzQoUMHjU6+W7du1evr6/p69OgRtm/fLt338PDAzp07dT4gp6Sk6L3PsLAwTJs2TboOv2LFCo3glZeXh1WrVkn3HRwc0L9//zLbdHNz07jv4uJilje8MRV/jra2tlXuOVZEUlKSXsGr+GUQbcO3FP+d+/r6ytLPyxjWrVun0bdl2rRpGDt2rE7bVrb+jGUp3qncWIq/9rVr165U7zdvb28olUrpLNrt27fNXFHht4XXrVsn3d+6dSsmTpxo8jqKB6+yrpaYEvt4VVL9+vXTuL9x40ajXic/ffq0xiXGwYMH6xy6rl69alBfkAYNGiAoKEijhosXL0r3d+3apXH58qWXXir3q9LFO81evXpV77oquyfhOVaEvkMgnD9/XuO+to7XlvQ7LzounlKpxFtvvaXztkXff6ZQtMuCvl+iMFXf18r+2qtUKo0hc27evGn2fl7Fj19Hjhwx+d8WAMTExGjcb9Omjclr0IbBq5J68803NUJGdnZ2icEe5VS8f5Y+Y18V70uij+KXDouO16Xr2F1F+fv7a1waOHz4sNk/hORWt25djcvO//77b6UZGLAy2Ldvn17rF/8iibYzWUXH4AIq9jdvbEXfy7Vq1dL5H6iCggK9f3dFuxgY8g2yop3c9ekjWlBQgNOnT+u9P0NYwmtfdJiX/Px8XLp0yYzVAP3790f9+vU1Hps2bZrJ6yj+T5UhQ4EYA4NXJeXq6orXX39d47F58+bh2LFjFW676OCbasU/NMsaV6v4dosWLTK4lgEDBmgEpV9//RUFBQVITU3F1q1bpce9vb1LfABqY2Njg2eeeUa6n5GRgWXLlhlcX2X13HPPadxfsGCBmSqpfNasWYPc3Fyd1j1w4ID0BQ+gcDBabf90BAcHw9r6fz0z1qxZY7ZvapWn6HtZ1/cxUHg5SN/LVEW/mGDIpb+iB+ebN2/qfKnzzz//NNkwBXXq1NEYcuTatWv4888/TbJvXRW9cgAAp06dMlMlhaytrUtc3v7999+xfv36Cret7fhVmqK/BxcXF7Ru3brC+5cDg1cl9umnn2pck87Pz0ffvn1LpHhd5ebm4oMPPsDo0aNL/MzT01Pj/sGDB3Vqc9GiRTh79qxB9QCFg+299NJL0v27d+/i77//xrp16zTOVIWGhuo8SOj48eM17k+dOlXv0c8ru3HjxmkEge+++85kZwAquzt37uDbb78tdz0hBCZMmKDx2LBhw7R+UcTDw0NjGJOMjAyt76PKoOh7OSUlRaezH48ePcL777+v976KDh0QFxen9/ZFB9UVQuD3338vd5vc3FxMnTpV731VRPHPlLFjx1aqYWaKTylVkeGA5DJ69OgSZ4+HDx+Of/75x6D2hBCYO3euxvRLZUlMTNQYgy04OFinmTNMwhwTRJLujh07JqpVq6Yx0aerq6tYtWqVXhOPRkZGijZt2pQ6+fKjR4+EjY2NxsSmhw4dKrPNbdu2CZVKVWLy2bImd9Zm9+7dGtu/+uqr4umnn9Z47PLly3q1GRISorF9s2bNRHR0tM7b5+fni02bNokPP/xQr/1WhD6TZAtRctLm2rVri8OHD+u1zz179oiRI0fqXNPUqVN1bnvq1Kka2/7zzz86b1t8omh91gUgVCqV2Lt3b5nbjRs3TmMbW1tbERcXV+r6165dE/b29iUm8M7Oztb5eSUnJ4sZM2aIrVu36vx89DV58mSN7Xv16iXy8/NLXT8jI0M8++yzJX6HAMSyZcvK3Nd///tfg19jIYTYsmWLxvZeXl7i/v37pa6fm5srhg0bprVWfSbJLu95FZeXlydatmyp0UZgYKC4c+eOzm3k5OSI5cuXi9mzZ+u1b10Vra9OnTpG2Ye+rl+/LpydnUu8N7/77juRm5urcztnz57VeF/oYt26dRV6zY2JwcsCLF++XGN2e/XSqVMnsXjxYnHjxg2t2125ckXMnTtXBAYG6nRAHzx4sMZ6Tk5O4ocffhCPHz8u0e7bb78t1eTu7i5q1qxpcPDKz88XdevW1XhjFq3jqaee0qs9IYRISEgQ3t7eGu3Y29uLMWPGiLNnz2oNrQ8ePBC7d+8WY8eOlbbt1q2b3vs2lL7BKzMzU7Rv315jG2trazFs2DBx5MgRrR9sDx8+FAcOHBAfffSRaNasWbn7scTgVb9+fQFA2NjYiE8//bTEgTwqKkr07t27xPtp5syZ5da1evXqEts1bdpU/PjjjyI+Pr7E+gUFBeLq1ati5cqVol+/fsLOzq7cg0BFg1d0dHSJz4vnn39eXLx4UWO9x48fi99//100btxYWq9FixZ6Hay+/vprjfVdXFzEhAkTxLp168SuXbvE7t27peXatWslts/NzRV16tTRaKNFixbin3/+0XiP5ubmir/++ksEBARI6zVo0MBkwUsIIWJiYkqECFdXVzFlypRS/zGMj48X27ZtE2+88YaoVauWACDCw8P13rcuPv/8c43aTpw4YZT96Ouvv/6S/u6LLs2aNRNff/21iImJ0brdrVu3xKJFi0TPnj2FQqHQ+z3x6quvSuvb2tqKtLQ0OZ9WhTB4WYhNmzYJJycnrf/pARA1atQQzZo1E/7+/qJRo0Yl/jPXJchcvXpV6z5sbW1FmzZtRKdOnTQCElB4ZmzHjh3Swc6Q4CWEEJMmTSq13kWLFhn0O4uKiioRvtSLs7Oz8PX1FQEBAaJly5aidu3aWterzMFLiMIPp9atW2ut3cHBQTRv3lwEBASI1q1bi7p165b4AKuKwWvv3r3C2tpaI4w2adJE+Pn5lTjIq5eQkBCRk5OjU21z587V+o8QAOHt7S3at28vOnXqJJo0aSKqV6+udT1jBi8hhBg1alSp9fn7+wtfX98SnxFdu3YVS5Ys0SugJCcnCzc3t1Lfu7r87axfv17r+u7u7sLPz0+0bt26xO9x4sSJIjw8XOMxYwcvIYTYu3evcHV11Vqvm5ubaNWqlQgICBAtWrSQglbxxVjBKy4uTuP9PWnSJKPsxxAHDx4s9TNW/XncpEkT4e/vL5o2bVrq+waA8PT0LHd/OTk5wsXFRdpmwIABJniWumPwsiCxsbGiT58+On3IaVtq1qwpvv766zIPMLt27RKOjo46tWdrayvWrFkjhBAVDl4xMTFa96FSqcSDBw8M/ZWJ+/fvl7jsqM8SGhpq8L71ZUjwEqLwMvHQoUO1hipdlqCgIJ1rsoTgJUThmamil87LWp5//nmRmZmpc21CCLFz584yDyRlLSqVSmzfvl2W516a7Oxs8cILL+hcU48ePURKSopBAWXfvn3C3d293H2U9bczffp0nWv94IMPREFBgVmClxCF/6B26tTJoNdeoVCIjz/+2OB9l6dXr14anx9lXWI2tcTERDF8+PBS/2kpb3FwcBBTpkwRjx49KndfGzZsMPizxxQYvCzQmTNnxKhRo4Snp6dOf6z//e9/xZo1a0RWVpZO7UdHR2u9FKNerK2tRf/+/TVOr1c0eAkhNC4jqJf+/fsb1FZx+/fvF7179xYODg7lfjC2b99eTJw4UURFRcmyb10ZGrzUzp07JwYPHqzxn15pS/PmzcWYMWPK7RNmqcFLiMJ+IaX1XQIgGjZsKJYuXapzTcU9fvxYfPvtt6JNmzblhl5HR0fRq1cvsWjRonL/kZAjeAlReAn/66+/LvNzwsfHRyxYsEA6QBsaUB48eCAWLFggevfuLRo0aCCqV69e4gBb3t/Otm3bSvSjKrq0bdtW7NixQ1rfXMFLbevWreKZZ54pN+BbWVmJwMBAMX36dK2XW+VUvL/szp07jbo/Q1y9elWMHz++xKVibYtKpRLdunUTS5YsEenp6Trvo2jfwzZt2hjx2RhGIUQlnb6bdHLt2jVcuHABt27dwsOHDyGEgIuLC2rUqAFfX1+0bNnS4G9y3Lt3DwcOHMDt27eRmZkJJycnNG7cGE8//bTW0b0tQW5uLo4fP47Y2FgkJSUhIyMDDg4OcHV1RdOmTeHr61tp5vMylHqMoytXriApKQnp6emwt7eHi4sLGjVqBF9f3xJzYlqy7t27a4w/Vfwj7fbt2zh06BBu3ryJvLw81K5dG61atZJ1TJ/ExEQcO3YM8fHxSE5ORkFBAZycnODp6YkWLVqgSZMmBs25KIe8vDycOHECUVFRSE5OhpWVFTw9PdGuXTujTVtUEdHR0Th+/Dju378vvV7+/v7w9fU1d2laZWZm4ujRo7h16xaSk5Px+PFjODo6ws3NDc2aNUOLFi1MOjmzn5+fNIzCiy++iC1btphs3/q6ffs2oqKicOPGDaSlpSE/Px/Ozs6oUaMGmjRpgrZt25Y7zVVxsbGxaNy4sTSS/y+//IKhQ4cao3yDMXgRkUUrL3gRPUl27NghzSWpUCgQHR2t14DYlu6dd97BwoULAQAtWrTAhQsXdB6KyFQqVzVERERksOeffx6dO3cGUPhPyJw5c8xckekkJiZqDJg9bdq0She6AAYvIiKiKmX+/PlS4Fi5ciWuXLli5opM4/PPP5dmUOjSpQsGDBhg5oq0Y/AiIiKqQvz8/PDaa68BKOzjN3nyZDNXZHw3btzA4sWLARRODq/L7BXmwj5eRGTR2MeLiCwJz3gRERERmQiDFxEREZGJMHgRERERmQj7eBERERGZCM94EREREZkIgxcRERGRiTB4EREREZkIgxcRERGRiTB4EREREZkIgxcRERGRiTB4EREREZkIgxcRERGRiTB4EREREZnI/wE0pyWFg0w2GQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction: x=8, Y=>{predict(8, w,b)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyXje8gq-kSd",
        "outputId": "1a38e7d8-7777-40f4-90ce-e1167d67ced8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: x=8, Y=>50.09999999999933\n"
          ]
        }
      ]
    }
  ]
}